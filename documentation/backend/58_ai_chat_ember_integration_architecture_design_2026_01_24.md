# AI Chat Assistant - Ember é›†æˆå®Œæ•´æ¶æ„è®¾è®¡

**æ–‡æ¡£ç¼–å·**: 58
**åˆ›å»ºæ—¥æœŸ**: 2026-01-24
**ä½œè€…**: Claude Code Assistant
**ç±»å‹**: æ¶æ„è®¾è®¡ (æ·±åº¦æ€è€ƒ)
**çŠ¶æ€**: ğŸ¨ è®¾è®¡é˜¶æ®µ

---

## ğŸ“‹ ç›®å½•

1. [ç°çŠ¶åˆ†æ](#1-ç°çŠ¶åˆ†æ)
2. [Ember èƒ½åŠ›å…¨æ™¯](#2-ember-èƒ½åŠ›å…¨æ™¯)
3. [æ ¸å¿ƒæ¶æ„è®¾è®¡](#3-æ ¸å¿ƒæ¶æ„è®¾è®¡)
4. [å¤šç”¨æˆ·åœºæ™¯è®¾è®¡](#4-å¤šç”¨æˆ·åœºæ™¯è®¾è®¡)
5. [API æ¥å£è®¾è®¡](#5-api-æ¥å£è®¾è®¡)
6. [å®‰å…¨æ€§æ¶æ„](#6-å®‰å…¨æ€§æ¶æ„)
7. [æ€§èƒ½ä¼˜åŒ–ç­–ç•¥](#7-æ€§èƒ½ä¼˜åŒ–ç­–ç•¥)
8. [æˆæœ¬ç®¡ç†æ–¹æ¡ˆ](#8-æˆæœ¬ç®¡ç†æ–¹æ¡ˆ)
9. [å®æ–½è·¯çº¿å›¾](#9-å®æ–½è·¯çº¿å›¾)

---

## 1. ç°çŠ¶åˆ†æ

### 1.1 å½“å‰æ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         å‰ç«¯å±‚                               â”‚
â”‚  components/ai-chat/                                        â”‚
â”‚  â”œâ”€â”€ AIChatSidebar.tsx       (ä¸»èŠå¤©ç•Œé¢)                    â”‚
â”‚  â”œâ”€â”€ ProviderSelector.tsx    (LLM æä¾›å•†é€‰æ‹©)                â”‚
â”‚  â””â”€â”€ ChatBubble.tsx          (æ¶ˆæ¯æ˜¾ç¤º)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    æœåŠ¡å±‚ (TypeScript)                       â”‚
â”‚  services/llm/                                              â”‚
â”‚  â”œâ”€â”€ llmService.ts           (LLM æœåŠ¡å•ä¾‹)                  â”‚
â”‚  â”œâ”€â”€ llmProvider.ts          (åŸºç¡€æ¥å£)                      â”‚
â”‚  â””â”€â”€ providers/                                             â”‚
â”‚      â”œâ”€â”€ GeminiProvider.ts   (âœ… é€šè¿‡ API ä»£ç†)             â”‚
â”‚      â”œâ”€â”€ ChatGPTProvider.ts  (âš ï¸ éœ€ç”¨æˆ·æä¾› API key)        â”‚
â”‚      â”œâ”€â”€ ClaudeProvider.ts   (âš ï¸ éœ€ç”¨æˆ·æä¾› API key)        â”‚
â”‚      â””â”€â”€ LocalProvider.ts    (âš ï¸ æœ¬åœ°æ¨¡å‹)                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    å¤–éƒ¨ API                                  â”‚
â”‚  - Gemini API (é€šè¿‡ /api/gemini ä»£ç†)                       â”‚
â”‚  - OpenAI API (ç”¨æˆ·è‡ªå¸¦ key)                                â”‚
â”‚  - Anthropic API (ç”¨æˆ·è‡ªå¸¦ key)                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.2 ç°æœ‰é—®é¢˜

| é—®é¢˜ç±»åˆ« | å…·ä½“é—®é¢˜ | å½±å“ |
|---------|---------|------|
| **åŠŸèƒ½å±€é™** | ä»…æ”¯æŒå•æ¨¡å‹å•æ¬¡å¯¹è¯ | æ— æ³•åˆ©ç”¨å¤šæ¨¡å‹ä¼˜åŠ¿ |
| **æ€§èƒ½** | æ— å¹¶è¡Œå¤„ç†èƒ½åŠ› | å“åº”æ…¢,æ— æ³•æ‰¹é‡å¤„ç† |
| **æˆæœ¬** | æ— æˆæœ¬è¿½è¸ªå’Œä¼˜åŒ– | æ— æ³•æ§åˆ¶è´¹ç”¨ |
| **å®‰å…¨** | API keys åœ¨ç¯å¢ƒå˜é‡ | å®‰å…¨æ€§ä¸è¶³ |
| **æ‰©å±•æ€§** | ç´§è€¦åˆå‰ç«¯å®ç° | éš¾ä»¥æ·»åŠ é«˜çº§åŠŸèƒ½ |
| **ç”¨æˆ·ä½“éªŒ** | å•ä¸€å¯¹è¯æ¨¡å¼ | æ— æ³•æ»¡è¶³å¤šæ ·åŒ–éœ€æ±‚ |

### 1.3 ç”¨æˆ·éœ€æ±‚åœºæ™¯åˆ†æ

åŸºäºç°æœ‰ AI Chat Assistant çš„ä½¿ç”¨åœºæ™¯,ç”¨æˆ·éœ€æ±‚å¯åˆ†ä¸º:

#### åœºæ™¯ 1: å¿«é€Ÿé—®ç­” (70% ç”¨æˆ·)
- **éœ€æ±‚**: å¿«é€Ÿè·å¾—ç­”æ¡ˆ
- **ç‰¹ç‚¹**: çŸ­é—®é¢˜,ç®€å•å›ç­”
- **å½“å‰æ–¹æ¡ˆ**: âœ… Gemini Flash (å¿«é€Ÿ+ä¾¿å®œ)
- **Ember å¢å¼º**: è‡ªåŠ¨é€‰æ‹©æœ€å¿«æ¨¡å‹

#### åœºæ™¯ 2: æ·±åº¦åˆ†æ (20% ç”¨æˆ·)
- **éœ€æ±‚**: è·å¾—é«˜è´¨é‡ã€æ·±åº¦çš„å›ç­”
- **ç‰¹ç‚¹**: å¤æ‚é—®é¢˜,éœ€è¦æ¨ç†
- **å½“å‰æ–¹æ¡ˆ**: âš ï¸ å•æ¨¡å‹,è´¨é‡ä¸ç¨³å®š
- **Ember å¢å¼º**: Ensemble (å¤šæ¨¡å‹æŠ•ç¥¨)

#### åœºæ™¯ 3: å¤šè¯­è¨€ç¿»è¯‘ (5% ç”¨æˆ·)
- **éœ€æ±‚**: å‡†ç¡®çš„å¤šè¯­è¨€ç¿»è¯‘
- **ç‰¹ç‚¹**: ä¸“ä¸šæœ¯è¯­,ä¸Šä¸‹æ–‡ç†è§£
- **å½“å‰æ–¹æ¡ˆ**: âš ï¸ å•æ¨¡å‹,å¯èƒ½ä¸å‡†ç¡®
- **Ember å¢å¼º**: å¤šæ¨¡å‹å¯¹æ¯” + ä¸“å®¶è¯„åˆ¤

#### åœºæ™¯ 4: æ‰¹é‡å¤„ç† (3% ç”¨æˆ·)
- **éœ€æ±‚**: å¤„ç†å¤šä¸ªç›¸ä¼¼é—®é¢˜
- **ç‰¹ç‚¹**: é‡å¤æ€§ä»»åŠ¡
- **å½“å‰æ–¹æ¡ˆ**: âŒ ä¸æ”¯æŒ
- **Ember å¢å¼º**: XCS å¹¶è¡Œ + Data API

#### åœºæ™¯ 5: ä¸ªæ€§åŒ–æ¨è (2% ç”¨æˆ·)
- **éœ€æ±‚**: åŸºäºç”¨æˆ· profile çš„æ¨è
- **ç‰¹ç‚¹**: éœ€è¦ç†è§£ç”¨æˆ·æ”¿æ²»å€¾å‘
- **å½“å‰æ–¹æ¡ˆ**: âš ï¸ ç®€å• context ä¼ é€’
- **Ember å¢å¼º**: Operators ç®¡é“ + ä¸Šä¸‹æ–‡å¢å¼º

---

## 2. Ember èƒ½åŠ›å…¨æ™¯

åŸºäºæµ‹è¯•æŠ¥å‘Š,Ember æä¾› 9 å¤§æ ¸å¿ƒèƒ½åŠ›:

### 2.1 Models API - ç›´æ¥ LLM è®¿é—® âœ…

**èƒ½åŠ›**:
- ç»Ÿä¸€æ¥å£è®¿é—®å¤šä¸ª LLM æä¾›å•†
- è‡ªåŠ¨æˆæœ¬è¿½è¸ª (Token ä½¿ç”¨ + ä»·æ ¼)
- å¯å¤ç”¨å®ä¾‹é…ç½® (temperature, max_tokens)
- è¯¦ç»†å“åº”å…ƒæ•°æ®

**ä½¿ç”¨åœºæ™¯**:
```python
# åœºæ™¯ 1: å¿«é€Ÿé—®ç­”
response = models("gemini-2.5-flash", user_question)

# åœºæ™¯ 2: é«˜è´¨é‡å›ç­”
response = models("gpt-5", complex_question)

# åœºæ™¯ 3: è·å–è¯¦ç»†ä¿¡æ¯
response_obj = models.response("gpt-4o", question)
print(f"æˆæœ¬: ${response_obj.usage['cost']}")
```

**AI Chat åº”ç”¨**:
- æ›¿ä»£ç°æœ‰ GeminiProvider
- è‡ªåŠ¨é€‰æ‹©æœ€ä½³æ¨¡å‹
- å®æ—¶æˆæœ¬è¿½è¸ª

### 2.2 Operators API - å¯ç»„åˆæ„å»ºå— âœ…

**èƒ½åŠ›**:
- `@op` è£…é¥°å™¨åˆ›å»ºå¯å¤ç”¨æ“ä½œ
- `operators.chain()` ç»„åˆå¤šä¸ªæ­¥éª¤
- å‡½æ•°è°ƒç”¨ç»„åˆ (æ¨èæ–¹å¼)

**ä½¿ç”¨åœºæ™¯**:
```python
@op
def analyze_question(text: str) -> str:
    """åˆ†æé—®é¢˜ç±»å‹"""
    return models("gemini-2.5-flash", f"åˆ†æé—®é¢˜ç±»å‹: {text}")

@op
def generate_answer(analysis: str, question: str) -> str:
    """æ ¹æ®åˆ†æç”Ÿæˆç­”æ¡ˆ"""
    return models("gpt-5", f"åŸºäºåˆ†æ: {analysis}\nå›ç­”: {question}")

@op
def user_aware_pipeline(question: str, user_profile: dict) -> str:
    """ä¸ªæ€§åŒ–é—®ç­”ç®¡é“"""
    # æ­¥éª¤ 1: åˆ†æé—®é¢˜
    analysis = analyze_question(question)

    # æ­¥éª¤ 2: ç”ŸæˆåŸºç¡€ç­”æ¡ˆ
    base_answer = generate_answer(analysis, question)

    # æ­¥éª¤ 3: æ ¹æ®ç”¨æˆ· profile è°ƒæ•´
    context = format_user_profile(user_profile)
    final_answer = models(
        "claude-4-sonnet",
        f"è°ƒæ•´ç­”æ¡ˆä»¥åŒ¹é…ç”¨æˆ·ç”»åƒ:\n{context}\nåŸç­”æ¡ˆ:{base_answer}"
    )

    return final_answer
```

**AI Chat åº”ç”¨**:
- ä¸ªæ€§åŒ–é—®ç­”ç®¡é“
- å¤šæ­¥éª¤å¤„ç† (åˆ†æ â†’ å›ç­” â†’ ä¼˜åŒ–)
- å¯å¤ç”¨çš„å¤„ç†é€»è¾‘

### 2.3 Data API - æµå¼ç®¡é“ âœ…

**èƒ½åŠ›**:
- æ‰¹é‡åŠ è½½æ•°æ®é›† (42 ä¸ªå†…ç½®æ•°æ®é›†)
- æµå¼å¤„ç†å¤§é‡æ•°æ®
- é«˜æ•ˆçš„æ•°æ®ç®¡é“

**ä½¿ç”¨åœºæ™¯**:
```python
# æ‰¹é‡å¤„ç†ç”¨æˆ·é—®é¢˜
questions = [
    "ä»€ä¹ˆæ˜¯ AI?",
    "ä»€ä¹ˆæ˜¯é‡å­è®¡ç®—?",
    "ä»€ä¹ˆæ˜¯åŒºå—é“¾?"
]

# æ‰¹é‡å¤„ç†
for q in questions:
    answer = models("gemini-2.5-flash", q)
    save_to_cache(q, answer)
```

**AI Chat åº”ç”¨**:
- æ‰¹é‡é—®ç­”æ¨¡å¼
- FAQ è‡ªåŠ¨ç”Ÿæˆ
- çŸ¥è¯†åº“é¢„å¡«å……

### 2.4 XCS API - è‡ªåŠ¨ä¼˜åŒ– âœ…

**èƒ½åŠ›**:
- `@xcs.jit` JIT ç¼–è¯‘ä¼˜åŒ–
- `xcs.vmap()` å‘é‡åŒ–å¹¶è¡Œå¤„ç†
- è‡ªåŠ¨æ£€æµ‹å¹¶è¡Œæœºä¼š

**ä½¿ç”¨åœºæ™¯**:
```python
@xcs.jit
def batch_process_questions(questions: list) -> list:
    """JIT ä¼˜åŒ–çš„æ‰¹é‡å¤„ç†"""
    return [models("gemini-2.5-flash", q) for q in questions]

# å‘é‡åŒ–å¤„ç†
vmapped_chat = xcs.vmap(lambda q: models("gemini-2.5-flash", q))
answers = vmapped_chat(questions)  # è‡ªåŠ¨å¹¶è¡Œ
```

**AI Chat åº”ç”¨**:
- é«˜å¹¶å‘ç”¨æˆ·è¯·æ±‚å¤„ç†
- æ‰¹é‡é—®ç­”åŠ é€Ÿ
- è‡ªåŠ¨æ€§èƒ½ä¼˜åŒ–

### 2.5 NON - Compound AI ç³»ç»Ÿ âœ…

**èƒ½åŠ›**:
- æ„å»º"ç½‘ç»œçš„ç½‘ç»œ"(NON)
- Ensemble (é›†æˆå¤šä¸ªæ¨¡å‹)
- Judge (è¯„åˆ¤å™¨)
- Verifier (éªŒè¯å™¨)

**ä½¿ç”¨åœºæ™¯**:
```python
from ember.non import build_graph

# 5 ä¸ª GPT-4o + Claude è¯„åˆ¤
system = build_graph([
    "5E@openai/gpt-4o(temp=0.7)",     # 5 ä¸ªé›†æˆå€™é€‰
    "1J@anthropic/claude-4-sonnet"    # Claude è¯„åˆ¤ç»¼åˆ
])

# å¤æ‚é—®é¢˜è·å¾—é«˜è´¨é‡ç­”æ¡ˆ
result = system(query="AI çš„æœªæ¥å‘å±•æ–¹å‘?")
```

**AI Chat åº”ç”¨**:
- é«˜è´¨é‡é—®ç­”æ¨¡å¼
- äº‹å®æ ¸æŸ¥
- å¤šè§†è§’åˆ†æ

### 2.6 å¤šæ¨¡å‹å¯¹æ¯” âœ…

**èƒ½åŠ›**:
- åŒæ—¶è°ƒç”¨å¤šä¸ªæ¨¡å‹
- å¯¹æ¯”ä¸åŒæ¨¡å‹çš„å›ç­”
- è®©ç”¨æˆ·é€‰æ‹©æœ€ä½³ç­”æ¡ˆ

**ä½¿ç”¨åœºæ™¯**:
```python
models_to_compare = ["gpt-5", "gemini-2.5-flash", "claude-4-sonnet"]

responses = {}
for model in models_to_compare:
    responses[model] = models(model, user_question)

# è¿”å›æ‰€æœ‰ç­”æ¡ˆä¾›ç”¨æˆ·é€‰æ‹©
return responses
```

**AI Chat åº”ç”¨**:
- "ä¸“å®¶ä¼šè¯Š"æ¨¡å¼
- å¯¹æ¯”ä¸åŒ LLM çš„è§‚ç‚¹
- å¢å¼ºç”¨æˆ·ä¿¡ä»»

### 2.7 æ‰¹é‡å¤„ç† âœ…

**èƒ½åŠ›**:
- é«˜æ•ˆå¤„ç†å¤šä¸ªé—®é¢˜
- è‡ªåŠ¨å¹¶è¡ŒåŒ–
- æˆæœ¬ä¼˜åŒ– (ä½¿ç”¨ä¾¿å®œæ¨¡å‹)

**ä½¿ç”¨åœºæ™¯**:
```python
from concurrent.futures import ThreadPoolExecutor

def batch_chat(questions: list, model: str = "gemini-2.5-flash"):
    with ThreadPoolExecutor(max_workers=5) as executor:
        futures = [executor.submit(models, model, q) for q in questions]
        return [f.result() for f in futures]
```

**AI Chat åº”ç”¨**:
- FAQ æ‰¹é‡ç”Ÿæˆ
- çŸ¥è¯†åº“æ„å»º
- æ•°æ®é¢„å¤„ç†

### 2.8 å†…å®¹å¤„ç†ç®¡é“ âœ…

**èƒ½åŠ›**:
- æ€»ç»“ â†’ ç¿»è¯‘ â†’ ä¼˜åŒ– å¤šæ­¥éª¤ç®¡é“
- å¯å¤ç”¨çš„å¤„ç†æµç¨‹
- è‡ªåŠ¨é”™è¯¯å¤„ç†

**ä½¿ç”¨åœºæ™¯**:
```python
@op
def summarize(text: str) -> str:
    return models("gpt-4o", f"æ€»ç»“: {text}")

@op
def translate(text: str, target_lang: str) -> str:
    return models("gemini-2.5-flash", f"ç¿»è¯‘æˆ{target_lang}: {text}")

@op
def content_pipeline(text: str, target_lang: str) -> str:
    summary = summarize(text)
    translated = translate(summary, target_lang)
    return translated
```

**AI Chat åº”ç”¨**:
- é•¿æ–‡æœ¬æ€»ç»“
- å¤šè¯­è¨€ç¿»è¯‘
- å†…å®¹ä¼˜åŒ–

### 2.9 æ€§èƒ½å’Œæˆæœ¬è¿½è¸ª âœ…

**èƒ½åŠ›**:
- å®æ—¶ Token ä½¿ç”¨ç»Ÿè®¡
- ç²¾ç¡®æˆæœ¬è®¡ç®—
- æä¾›å•†æˆæœ¬å¯¹æ¯”

**ä½¿ç”¨åœºæ™¯**:
```python
response = models.response("gpt-5", question)

# è·å–è¯¦ç»†æˆæœ¬ä¿¡æ¯
print(f"Prompt Tokens: {response.usage['prompt_tokens']}")
print(f"Completion Tokens: {response.usage['completion_tokens']}")
print(f"Total Cost: ${response.usage['cost']:.6f}")

# å†³ç­–: å¦‚æœæˆæœ¬è¿‡é«˜,åˆ‡æ¢åˆ°ä¾¿å®œæ¨¡å‹
if response.usage['cost'] > 0.01:
    response = models("gemini-2.5-flash", question)
```

**AI Chat åº”ç”¨**:
- ç”¨æˆ·æˆæœ¬é€æ˜åŒ–
- è‡ªåŠ¨æˆæœ¬ä¼˜åŒ–
- é¢„ç®—æ§åˆ¶

### 2.10 Ensemble æ‰§è¡Œ âœ…

**èƒ½åŠ›**:
- å¹¶è¡Œè°ƒç”¨å¤šä¸ªæ¨¡å‹å®ä¾‹
- è¯„åˆ¤å™¨ç»¼åˆå¤šä¸ªç­”æ¡ˆ
- è·å¾—æœ€ä½³è´¨é‡ç»“æœ

**ä½¿ç”¨åœºæ™¯**:
```python
from concurrent.futures import ThreadPoolExecutor

question = "AI çš„æœ€å¤§æŒ‘æˆ˜æ˜¯ä»€ä¹ˆ?"

# å¹¶è¡Œè°ƒç”¨ 5 ä¸ªæ¨¡å‹
with ThreadPoolExecutor(max_workers=5) as executor:
    model_calls = [
        ("gpt-5", question),
        ("gpt-5", question),
        ("gpt-5", question),
        ("gemini-2.5-flash", question),
        ("claude-4-sonnet", question),
    ]
    futures = [executor.submit(models, m, q) for m, q in model_calls]
    candidates = [f.result() for f in futures]

# Claude è¯„åˆ¤ç»¼åˆ
judge_prompt = f"""ç»¼åˆä»¥ä¸‹ 5 ä¸ªç­”æ¡ˆ,ç»™å‡ºæœ€ä½³å›ç­”:

é—®é¢˜: {question}

ç­”æ¡ˆ:
1. (GPT-5) {candidates[0]}
2. (GPT-5) {candidates[1]}
3. (GPT-5) {candidates[2]}
4. (Gemini) {candidates[3]}
5. (Claude) {candidates[4]}

è¯·ç»¼åˆåç»™å‡ºç­”æ¡ˆ:"""

final_answer = models("claude-4-sonnet", judge_prompt)
```

**AI Chat åº”ç”¨**:
- "ç»ˆæé—®ç­”"æ¨¡å¼
- é«˜è´¨é‡ã€é«˜å¯ä¿¡åº¦å›ç­”
- é‡è¦å†³ç­–è¾…åŠ©

---

## 3. æ ¸å¿ƒæ¶æ„è®¾è®¡

### 3.1 æ•´ä½“æ¶æ„å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          å‰ç«¯å±‚ (React/TypeScript)                â”‚
â”‚                                                                  â”‚
â”‚  components/ai-chat/                                             â”‚
â”‚  â”œâ”€â”€ AIChatSidebar.tsx                                          â”‚
â”‚  â”‚   â”œâ”€â”€ åŸºç¡€èŠå¤©æ¨¡å¼ (default)                                  â”‚
â”‚  â”‚   â”œâ”€â”€ ä¸“å®¶ä¼šè¯Šæ¨¡å¼ (multi-model)                              â”‚
â”‚  â”‚   â”œâ”€â”€ æ·±åº¦åˆ†ææ¨¡å¼ (ensemble)                                 â”‚
â”‚  â”‚   â”œâ”€â”€ æ‰¹é‡é—®ç­”æ¨¡å¼ (batch)                                    â”‚
â”‚  â”‚   â””â”€â”€ æˆæœ¬è¿½è¸ªæ˜¾ç¤º                                            â”‚
â”‚  â”‚                                                               â”‚
â”‚  â”œâ”€â”€ ChatModeSelector.tsx (NEW)                                 â”‚
â”‚  â”‚   â””â”€â”€ è®©ç”¨æˆ·é€‰æ‹©èŠå¤©æ¨¡å¼                                      â”‚
â”‚  â”‚                                                               â”‚
â”‚  â””â”€â”€ CostTracker.tsx (NEW)                                      â”‚
â”‚      â””â”€â”€ å®æ—¶æ˜¾ç¤ºæˆæœ¬å’Œ token ä½¿ç”¨                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â”‚ HTTP/HTTPS
                      â”‚
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Ember API å±‚ (Python/Cloud Run)               â”‚
â”‚                                                                  â”‚
â”‚  functions/ember-api/                                           â”‚
â”‚  â”œâ”€â”€ main.py                      (Flask/FastAPI å…¥å£)          â”‚
â”‚  â”œâ”€â”€ routes/                                                    â”‚
â”‚  â”‚   â”œâ”€â”€ chat.py                 (åŸºç¡€èŠå¤© API)                 â”‚
â”‚  â”‚   â”œâ”€â”€ multi_model.py          (å¤šæ¨¡å‹å¯¹æ¯” API)               â”‚
â”‚  â”‚   â”œâ”€â”€ ensemble.py             (Ensemble API)                â”‚
â”‚  â”‚   â”œâ”€â”€ batch.py                (æ‰¹é‡å¤„ç† API)                 â”‚
â”‚  â”‚   â””â”€â”€ cost.py                 (æˆæœ¬ç»Ÿè®¡ API)                 â”‚
â”‚  â”‚                                                               â”‚
â”‚  â”œâ”€â”€ services/                                                  â”‚
â”‚  â”‚   â”œâ”€â”€ ember_service.py        (Ember æ ¸å¿ƒæœåŠ¡)               â”‚
â”‚  â”‚   â”œâ”€â”€ chat_service.py         (èŠå¤©é€»è¾‘)                     â”‚
â”‚  â”‚   â”œâ”€â”€ ensemble_service.py     (Ensemble é€»è¾‘)               â”‚
â”‚  â”‚   â””â”€â”€ cost_service.py         (æˆæœ¬è¿½è¸ª)                     â”‚
â”‚  â”‚                                                               â”‚
â”‚  â””â”€â”€ utils/                                                     â”‚
â”‚      â”œâ”€â”€ secret_manager.py       (Secret Manager é›†æˆ)          â”‚
â”‚      â”œâ”€â”€ user_context.py         (ç”¨æˆ·ä¸Šä¸‹æ–‡ç®¡ç†)               â”‚
â”‚      â””â”€â”€ cache.py                (Redis ç¼“å­˜)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â”‚ Secret Manager API
                      â”‚
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Google Cloud Secret Manager                         â”‚
â”‚                                                                  â”‚
â”‚  Secrets (gen-lang-client-0960644135):                         â”‚
â”‚  â”œâ”€â”€ ember-openai-api-key      â†’ OpenAI GPT-5                  â”‚
â”‚  â”œâ”€â”€ ember-google-api-key      â†’ Google Gemini                 â”‚
â”‚  â””â”€â”€ ember-anthropic-api-key   â†’ Anthropic Claude              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â”‚ LLM API Calls
                      â”‚
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Ember Framework                             â”‚
â”‚                                                                  â”‚
â”‚  â”œâ”€â”€ Models API       â†’ ç»Ÿä¸€ LLM è®¿é—®                            â”‚
â”‚  â”œâ”€â”€ Operators API    â†’ å¯ç»„åˆç®¡é“                              â”‚
â”‚  â”œâ”€â”€ Data API         â†’ æ‰¹é‡å¤„ç†                                â”‚
â”‚  â”œâ”€â”€ XCS API          â†’ è‡ªåŠ¨ä¼˜åŒ–                                â”‚
â”‚  â””â”€â”€ NON API          â†’ Compound AI                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    å¤–éƒ¨ LLM æä¾›å•†                                â”‚
â”‚                                                                  â”‚
â”‚  â”œâ”€â”€ OpenAI API       (gpt-5, gpt-4o)                          â”‚
â”‚  â”œâ”€â”€ Google AI API    (gemini-2.5-flash, gemini-2.5-pro)      â”‚
â”‚  â””â”€â”€ Anthropic API    (claude-4-sonnet, claude-opus-4)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.2 æ•°æ®æµè®¾è®¡

#### 3.2.1 åŸºç¡€èŠå¤©æµç¨‹

```
ç”¨æˆ·è¾“å…¥é—®é¢˜
    â”‚
    â–¼
å‰ç«¯ AIChatSidebar
    â”‚
    â”œâ”€ æ·»åŠ ç”¨æˆ·ç”»åƒ context
    â”œâ”€ é€‰æ‹©èŠå¤©æ¨¡å¼ (default/multi/ensemble/batch)
    â”‚
    â–¼
POST /api/ember/chat
    â”‚
    â”œâ”€ è¯·æ±‚ä½“:
    â”‚   {
    â”‚     "message": "ç”¨æˆ·é—®é¢˜",
    â”‚     "mode": "default",  // default | multi | ensemble | batch
    â”‚     "user_context": {
    â”‚       "economic": -2.5,
    â”‚       "social": 3.1,
    â”‚       "diplomatic": 1.2,
    â”‚       "label": "Moderate Liberal"
    â”‚     },
    â”‚     "language": "ZH",
    â”‚     "model_preference": "auto"  // auto | fast | quality | balanced
    â”‚   }
    â”‚
    â–¼
Ember API (Python)
    â”‚
    â”œâ”€ ä» Secret Manager è·å– API keys
    â”œâ”€ æ ¹æ® mode é€‰æ‹©å¤„ç†ç­–ç•¥:
    â”‚
    â”œâ”€ Mode: default (70% ç”¨æˆ·)
    â”‚   â”‚
    â”‚   â”œâ”€ è‡ªåŠ¨é€‰æ‹©æ¨¡å‹:
    â”‚   â”‚   â€¢ çŸ­é—®é¢˜ (<50å­—) â†’ gemini-2.5-flash (å¿«é€Ÿ)
    â”‚   â”‚   â€¢ é•¿é—®é¢˜ (>50å­—) â†’ gpt-4o (å¹³è¡¡)
    â”‚   â”‚   â€¢ å¤æ‚é—®é¢˜ (åŒ…å«"åˆ†æ"/"ä¸ºä»€ä¹ˆ") â†’ gpt-5 (æ·±åº¦)
    â”‚   â”‚
    â”‚   â”œâ”€ æ„å»º prompt (åŒ…å«ç”¨æˆ· context)
    â”‚   â”œâ”€ è°ƒç”¨ Ember Models API
    â”‚   â””â”€ è¿”å›ç­”æ¡ˆ + æˆæœ¬ä¿¡æ¯
    â”‚
    â”œâ”€ Mode: multi (20% ç”¨æˆ·)
    â”‚   â”‚
    â”‚   â”œâ”€ å¹¶è¡Œè°ƒç”¨ 3 ä¸ªæ¨¡å‹:
    â”‚   â”‚   â€¢ gpt-5 (æœ€å¼ºæ¨ç†)
    â”‚   â”‚   â€¢ gemini-2.5-flash (å¿«é€Ÿ)
    â”‚   â”‚   â€¢ claude-4-sonnet (ç¼–ç¨‹/åˆ†æ)
    â”‚   â”‚
    â”‚   â”œâ”€ ä½¿ç”¨ ThreadPoolExecutor å¹¶è¡Œ
    â”‚   â””â”€ è¿”å› 3 ä¸ªç­”æ¡ˆä¾›ç”¨æˆ·é€‰æ‹©
    â”‚
    â”œâ”€ Mode: ensemble (5% ç”¨æˆ·)
    â”‚   â”‚
    â”‚   â”œâ”€ Ensemble é…ç½®:
    â”‚   â”‚   â€¢ 3x gpt-5 (é«˜è´¨é‡å€™é€‰)
    â”‚   â”‚   â€¢ 2x gemini-2.5-flash (å¿«é€Ÿå€™é€‰)
    â”‚   â”‚   â€¢ 1x claude-4-sonnet (è¯„åˆ¤)
    â”‚   â”‚
    â”‚   â”œâ”€ å¹¶è¡Œè°ƒç”¨æ‰€æœ‰å€™é€‰æ¨¡å‹
    â”‚   â”œâ”€ Claude è¯„åˆ¤ç»¼åˆç­”æ¡ˆ
    â”‚   â””â”€ è¿”å›æœ€ç»ˆç­”æ¡ˆ + å€™é€‰ç­”æ¡ˆ
    â”‚
    â””â”€ Mode: batch (3% ç”¨æˆ·)
        â”‚
        â”œâ”€ ä½¿ç”¨ XCS vmap å¹¶è¡Œå¤„ç†
        â”œâ”€ æ‰¹é‡è°ƒç”¨ gemini-2.5-flash
        â””â”€ è¿”å›æ‰€æœ‰ç­”æ¡ˆ
```

#### 3.2.2 æˆæœ¬è¿½è¸ªæµç¨‹

```
æ¯æ¬¡ LLM è°ƒç”¨
    â”‚
    â–¼
models.response() è¿”å›è¯¦ç»†ä¿¡æ¯
    â”‚
    â”œâ”€ response.text          (ç­”æ¡ˆæ–‡æœ¬)
    â”œâ”€ response.model_id      (å®é™…ä½¿ç”¨çš„æ¨¡å‹)
    â”œâ”€ response.usage         (ä½¿ç”¨ç»Ÿè®¡)
    â”‚   â”œâ”€ prompt_tokens      (è¾“å…¥ token æ•°)
    â”‚   â”œâ”€ completion_tokens  (è¾“å‡º token æ•°)
    â”‚   â”œâ”€ total_tokens       (æ€» token æ•°)
    â”‚   â””â”€ cost               (æœ¬æ¬¡æˆæœ¬ $)
    â”‚
    â–¼
å­˜å‚¨åˆ° Firestore
    â”‚
    â”œâ”€ é›†åˆ: user_chat_costs/{userId}/sessions/{sessionId}
    â”œâ”€ å­—æ®µ:
    â”‚   {
    â”‚     "timestamp": "2026-01-24T21:00:00Z",
    â”‚     "model": "gpt-5",
    â”‚     "prompt_tokens": 150,
    â”‚     "completion_tokens": 300,
    â”‚     "total_tokens": 450,
    â”‚     "cost": 0.00315,
    â”‚     "mode": "ensemble",
    â”‚     "question": "AIçš„æœªæ¥å‘å±•?",
    â”‚     "answer_length": 1200
    â”‚   }
    â”‚
    â–¼
è¿”å›ç»™å‰ç«¯
    â”‚
    â”œâ”€ å®æ—¶æ˜¾ç¤ºæœ¬æ¬¡æˆæœ¬
    â”œâ”€ ç´¯è®¡æˆæœ¬ç»Ÿè®¡
    â””â”€ æˆæœ¬è¶‹åŠ¿å›¾è¡¨
```

### 3.3 ç»„ä»¶è®¾è®¡

#### 3.3.1 å‰ç«¯æ–°å¢ç»„ä»¶

##### ChatModeSelector.tsx

```typescript
interface ChatMode {
  id: 'default' | 'multi' | 'ensemble' | 'batch';
  name: string;
  description: string;
  icon: React.ReactNode;
  costLevel: 'low' | 'medium' | 'high';
  speed: 'fast' | 'medium' | 'slow';
  quality: 'good' | 'better' | 'best';
}

const CHAT_MODES: ChatMode[] = [
  {
    id: 'default',
    name: 'å¿«é€Ÿé—®ç­”',
    description: 'æœ€å¿«é€Ÿ,é€‚åˆç®€å•é—®é¢˜',
    icon: <Zap />,
    costLevel: 'low',
    speed: 'fast',
    quality: 'good'
  },
  {
    id: 'multi',
    name: 'ä¸“å®¶ä¼šè¯Š',
    description: '3ä¸ªAIåŒæ—¶å›ç­”,å¯¹æ¯”è§‚ç‚¹',
    icon: <Users />,
    costLevel: 'medium',
    speed: 'medium',
    quality: 'better'
  },
  {
    id: 'ensemble',
    name: 'æ·±åº¦åˆ†æ',
    description: '6ä¸ªAIåä½œ,æœ€é«˜è´¨é‡',
    icon: <Brain />,
    costLevel: 'high',
    speed: 'slow',
    quality: 'best'
  },
  {
    id: 'batch',
    name: 'æ‰¹é‡å¤„ç†',
    description: 'åŒæ—¶å¤„ç†å¤šä¸ªé—®é¢˜',
    icon: <List />,
    costLevel: 'medium',
    speed: 'fast',
    quality: 'good'
  }
];
```

##### CostTracker.tsx

```typescript
interface CostInfo {
  currentSessionCost: number;    // æœ¬æ¬¡ä¼šè¯æˆæœ¬
  todayCost: number;              // ä»Šæ—¥æ€»æˆæœ¬
  monthCost: number;              // æœ¬æœˆæ€»æˆæœ¬
  tokenUsage: {
    prompt: number;
    completion: number;
    total: number;
  };
  modelUsage: {
    [model: string]: {
      calls: number;
      cost: number;
    };
  };
}

// æ˜¾ç¤º:
// ğŸ’° æœ¬æ¬¡: $0.0032 | ä»Šæ—¥: $0.12 | æœ¬æœˆ: $3.45
// ğŸ“Š Tokens: 450 (150 in + 300 out)
// ğŸ¤– GPT-5: 5æ¬¡ ($0.08) | Gemini: 12æ¬¡ ($0.04)
```

#### 3.3.2 åç«¯æœåŠ¡è®¾è®¡

##### ember_service.py

```python
"""
Ember æ ¸å¿ƒæœåŠ¡
è´Ÿè´£æ‰€æœ‰ Ember ç›¸å…³çš„æ“ä½œ
"""

from ember.api import models, op, operators, data, xcs
from ember.non import build_graph
from ember.core.secret_manager import get_provider_api_key
import os

class EmberService:
    """Ember æ¡†æ¶å°è£…æœåŠ¡"""

    def __init__(self):
        # ç¡®ä¿ API keys ä» Secret Manager åŠ è½½
        self._ensure_api_keys()

    def _ensure_api_keys(self):
        """ä» Secret Manager åŠ è½½ API keys åˆ°ç¯å¢ƒå˜é‡"""
        # Ember ä¼šè‡ªåŠ¨ä» Secret Manager è¯»å–
        # æ— éœ€é¢å¤–æ“ä½œ,credentials.py å·²å®ç°
        pass

    def chat(
        self,
        message: str,
        mode: str = "default",
        user_context: dict = None,
        language: str = "ZH",
        model_preference: str = "auto"
    ) -> dict:
        """
        ç»Ÿä¸€èŠå¤©æ¥å£

        Args:
            message: ç”¨æˆ·æ¶ˆæ¯
            mode: æ¨¡å¼ (default/multi/ensemble/batch)
            user_context: ç”¨æˆ·ç”»åƒ
            language: è¯­è¨€
            model_preference: æ¨¡å‹åå¥½ (auto/fast/quality/balanced)

        Returns:
            {
                "success": bool,
                "answer": stræˆ–list,
                "cost": float,
                "tokens": {...},
                "model_used": str,
                "mode": str
            }
        """

        if mode == "default":
            return self._default_chat(message, user_context, language, model_preference)
        elif mode == "multi":
            return self._multi_model_chat(message, user_context, language)
        elif mode == "ensemble":
            return self._ensemble_chat(message, user_context, language)
        elif mode == "batch":
            return self._batch_chat(message, user_context, language)
        else:
            raise ValueError(f"Unknown mode: {mode}")

    def _default_chat(self, message, user_context, language, model_preference):
        """é»˜è®¤èŠå¤©æ¨¡å¼ - è‡ªåŠ¨é€‰æ‹©æœ€ä½³æ¨¡å‹"""

        # è‡ªåŠ¨é€‰æ‹©æ¨¡å‹
        model = self._select_model(message, model_preference)

        # æ„å»º prompt
        prompt = self._build_prompt(message, user_context, language)

        # è°ƒç”¨ Ember
        response = models.response(model, prompt)

        return {
            "success": True,
            "answer": response.text,
            "cost": response.usage['cost'],
            "tokens": {
                "prompt": response.usage['prompt_tokens'],
                "completion": response.usage['completion_tokens'],
                "total": response.usage['total_tokens']
            },
            "model_used": response.model_id,
            "mode": "default"
        }

    def _multi_model_chat(self, message, user_context, language):
        """å¤šæ¨¡å‹å¯¹æ¯”æ¨¡å¼"""
        from concurrent.futures import ThreadPoolExecutor

        models_to_use = [
            "gpt-5",
            "gemini-2.5-flash",
            "claude-4-sonnet"
        ]

        prompt = self._build_prompt(message, user_context, language)

        def call_model(model_name):
            response = models.response(model_name, prompt)
            return {
                "model": response.model_id,
                "answer": response.text,
                "cost": response.usage['cost'],
                "tokens": response.usage['total_tokens']
            }

        with ThreadPoolExecutor(max_workers=3) as executor:
            futures = [executor.submit(call_model, m) for m in models_to_use]
            results = [f.result() for f in futures]

        total_cost = sum(r['cost'] for r in results)

        return {
            "success": True,
            "answer": results,  # è¿”å›å¤šä¸ªç­”æ¡ˆ
            "cost": total_cost,
            "tokens": {"total": sum(r['tokens'] for r in results)},
            "model_used": "multi",
            "mode": "multi"
        }

    def _ensemble_chat(self, message, user_context, language):
        """Ensemble æ¨¡å¼ - æœ€é«˜è´¨é‡"""
        from concurrent.futures import ThreadPoolExecutor

        prompt = self._build_prompt(message, user_context, language)

        # 5 ä¸ªå€™é€‰æ¨¡å‹
        model_calls = [
            ("gpt-5", prompt),
            ("gpt-5", prompt),
            ("gpt-5", prompt),
            ("gemini-2.5-flash", prompt),
            ("gemini-2.5-flash", prompt),
        ]

        def call_model(model_name, prompt_text):
            return models(model_name, prompt_text)

        # å¹¶è¡Œè°ƒç”¨
        with ThreadPoolExecutor(max_workers=5) as executor:
            futures = [executor.submit(call_model, m, p) for m, p in model_calls]
            candidates = [f.result() for f in futures]

        # Claude è¯„åˆ¤
        judge_prompt = f"""ç»¼åˆä»¥ä¸‹ 5 ä¸ª AI çš„ç­”æ¡ˆ,ç»™å‡ºæœ€ä½³å›ç­”:

é—®é¢˜: {message}

ç­”æ¡ˆ:
1. (GPT-5) {candidates[0]}
2. (GPT-5) {candidates[1]}
3. (GPT-5) {candidates[2]}
4. (Gemini) {candidates[3]}
5. (Gemini) {candidates[4]}

è¯·ç»¼åˆåç»™å‡ºæœ€ä½³ç­”æ¡ˆ:"""

        final_response = models.response("claude-4-sonnet", judge_prompt)

        # è®¡ç®—æ€»æˆæœ¬ (5æ¬¡å€™é€‰ + 1æ¬¡è¯„åˆ¤)
        total_cost = final_response.usage['cost']  # ç®€åŒ–,å®é™…éœ€ç´¯åŠ 

        return {
            "success": True,
            "answer": final_response.text,
            "candidates": candidates,  # ä¹Ÿè¿”å›å€™é€‰ç­”æ¡ˆ
            "cost": total_cost,
            "tokens": {"total": final_response.usage['total_tokens']},
            "model_used": "ensemble (3xGPT-5 + 2xGemini + Claude)",
            "mode": "ensemble"
        }

    def _select_model(self, message: str, preference: str) -> str:
        """æ™ºèƒ½é€‰æ‹©æ¨¡å‹"""

        if preference == "fast":
            return "gemini-2.5-flash"
        elif preference == "quality":
            return "gpt-5"
        elif preference == "balanced":
            return "gpt-4o"

        # auto - æ ¹æ®é—®é¢˜è‡ªåŠ¨é€‰æ‹©
        msg_len = len(message)

        # çŸ­é—®é¢˜ (<50å­—) - å¿«é€Ÿæ¨¡å‹
        if msg_len < 50:
            return "gemini-2.5-flash"

        # åŒ…å«æ·±åº¦å…³é”®è¯ - é«˜è´¨é‡æ¨¡å‹
        deep_keywords = ["ä¸ºä»€ä¹ˆ", "åˆ†æ", "è§£é‡Š", "åŸå› ", "å¦‚ä½•", "è¯„ä»·"]
        if any(kw in message for kw in deep_keywords):
            return "gpt-5"

        # é»˜è®¤ - å¹³è¡¡æ¨¡å‹
        return "gpt-4o"

    def _build_prompt(self, message: str, user_context: dict, language: str) -> str:
        """æ„å»ºåŒ…å«ç”¨æˆ·ä¸Šä¸‹æ–‡çš„ prompt"""

        if not user_context:
            return message

        context_text = f"""ç”¨æˆ·æ”¿æ²»ç”»åƒ:
- ç»æµè§‚ç‚¹: {user_context.get('economic', 0)} ({'å·¦å€¾' if user_context.get('economic', 0) < 0 else 'å³å€¾'})
- ç¤¾ä¼šè§‚ç‚¹: {user_context.get('social', 0)} ({'å¨æƒ' if user_context.get('social', 0) < 0 else 'è‡ªç”±'})
- å¤–äº¤è§‚ç‚¹: {user_context.get('diplomatic', 0)} ({'æ°‘æ—' if user_context.get('diplomatic', 0) < 0 else 'å›½é™…'})
- æ ‡ç­¾: {user_context.get('label', 'Unknown')}

è¯·åŸºäºç”¨æˆ·çš„æ”¿æ²»å€¾å‘,æä¾›å¹³è¡¡ã€å°Šé‡çš„å›ç­”ã€‚

ç”¨æˆ·é—®é¢˜: {message}"""

        return context_text
```

---

## 4. å¤šç”¨æˆ·åœºæ™¯è®¾è®¡

### 4.1 åœºæ™¯çŸ©é˜µ

| ç”¨æˆ·éœ€æ±‚ | æ¨èæ¨¡å¼ | Ember èƒ½åŠ› | é¢„æœŸæˆæœ¬ | å“åº”æ—¶é—´ |
|---------|---------|-----------|---------|---------|
| **å¿«é€Ÿé—®ç­”** | default (auto) | Models API | $0.0001-0.001 | <2ç§’ |
| **æ·±åº¦åˆ†æ** | ensemble | NON + Ensemble | $0.005-0.02 | 5-10ç§’ |
| **å¤šè§†è§’å¯¹æ¯”** | multi | Models API + å¹¶è¡Œ | $0.002-0.005 | 3-5ç§’ |
| **æ‰¹é‡å¤„ç†** | batch | XCS + vmap | $0.001-0.01 | 2-5ç§’ |
| **ä¸ªæ€§åŒ–æ¨è** | default + operators | Operatorsç®¡é“ | $0.001-0.003 | 2-4ç§’ |
| **äº‹å®æ ¸æŸ¥** | ensemble | EnsembleéªŒè¯ | $0.01-0.03 | 8-12ç§’ |
| **å¤šè¯­è¨€ç¿»è¯‘** | multi | å¤šæ¨¡å‹å¯¹æ¯” | $0.002-0.005 | 3-5ç§’ |

### 4.2 åœºæ™¯è¯¦ç»†è®¾è®¡

#### åœºæ™¯ 1: æ”¿æ²»è§‚ç‚¹é—®ç­” (æ ¸å¿ƒåœºæ™¯)

**ç”¨æˆ·è¾“å…¥**: "ä½ å¯¹è‡ªç”±è´¸æ˜“çš„çœ‹æ³•æ˜¯ä»€ä¹ˆ?"

**å¤„ç†æµç¨‹**:

```python
# æ­¥éª¤ 1: åˆ†æç”¨æˆ·ç”»åƒ
user_context = {
    "economic": -2.5,  # åå·¦ç»æµè§‚
    "social": 3.1,     # è‡ªç”±ç¤¾ä¼šè§‚
    "diplomatic": 1.2, # åå›½é™…ä¸»ä¹‰
    "label": "Social Democrat"
}

# æ­¥éª¤ 2: é€‰æ‹©æ¨¡å¼
# æ”¿æ²»ç›¸å…³ â†’ ensemble (é«˜è´¨é‡,å¤šè§†è§’)
mode = "ensemble"

# æ­¥éª¤ 3: æ„å»ºä¸ªæ€§åŒ– prompt
@op
def build_political_prompt(question, user_profile):
    """æ„å»ºæ”¿æ²»ç›¸å…³é—®é¢˜çš„ prompt"""
    return f"""ç”¨æˆ·ç”»åƒ: {user_profile['label']}

ç»æµç«‹åœº: {user_profile['economic']} (å{get_tendency(user_profile['economic'], 'economic')})

è¯·å›ç­”ä»¥ä¸‹é—®é¢˜,æä¾›å¹³è¡¡ã€å¤šè§’åº¦çš„åˆ†æ:
{question}

è¦æ±‚:
1. åˆ—ä¸¾ä¸åŒæ”¿æ²»ç«‹åœºçš„è§‚ç‚¹
2. åˆ†æå„è§‚ç‚¹çš„ä¼˜ç¼ºç‚¹
3. é¿å…æ”¿æ²»åè§
4. æä¾›äº‹å®ä¾æ®"""

# æ­¥éª¤ 4: Ensemble æ‰§è¡Œ
response = ember_service.chat(
    message="ä½ å¯¹è‡ªç”±è´¸æ˜“çš„çœ‹æ³•æ˜¯ä»€ä¹ˆ?",
    mode="ensemble",
    user_context=user_context,
    language="ZH"
)

# è¿”å›ç»“æœ:
{
    "answer": "å…³äºè‡ªç”±è´¸æ˜“,å­˜åœ¨å¤šç§è§‚ç‚¹:\n\n1. è‡ªç”±å¸‚åœºæ´¾...\n2. ä¿æŠ¤ä¸»ä¹‰æ´¾...\n3. ä¸­é—´è·¯çº¿...",
    "candidates": [...],  # 5ä¸ªå€™é€‰ç­”æ¡ˆ
    "cost": 0.015,
    "model_used": "ensemble",
    "quality_score": 0.95
}
```

#### åœºæ™¯ 2: å“ç‰Œæ¨è (ä¸ªæ€§åŒ–)

**ç”¨æˆ·è¾“å…¥**: "æ¨èå‡ ä¸ªç¬¦åˆæˆ‘ä»·å€¼è§‚çš„å’–å•¡å“ç‰Œ"

**å¤„ç†æµç¨‹**:

```python
# ä½¿ç”¨ Operators ç®¡é“
@op
def analyze_user_values(user_profile):
    """åˆ†æç”¨æˆ·ä»·å€¼è§‚"""
    prompt = f"åŸºäºç”¨æˆ·ç”»åƒ {user_profile},æ€»ç»“å…¶æ ¸å¿ƒä»·å€¼è§‚"
    return models("gpt-4o", prompt)

@op
def find_matching_brands(values, category):
    """æŸ¥æ‰¾åŒ¹é…å“ç‰Œ"""
    prompt = f"åŸºäºä»·å€¼è§‚ {values},æ¨è{category}å“ç‰Œ"
    return models("gemini-2.5-flash", prompt)

@op
def explain_recommendations(brands, user_profile):
    """è§£é‡Šæ¨èç†ç”±"""
    prompt = f"è§£é‡Šä¸ºä½•æ¨èè¿™äº›å“ç‰Œç»™ {user_profile['label']} ç”¨æˆ·: {brands}"
    return models("claude-4-sonnet", prompt)

@op
def brand_recommendation_pipeline(user_profile, category):
    """å®Œæ•´æ¨èç®¡é“"""
    values = analyze_user_values(user_profile)
    brands = find_matching_brands(values, category)
    explanation = explain_recommendations(brands, user_profile)
    return {
        "brands": brands,
        "explanation": explanation,
        "values_matched": values
    }

# æ‰§è¡Œ
result = brand_recommendation_pipeline(user_context, "å’–å•¡")
```

#### åœºæ™¯ 3: æ‰¹é‡ FAQ ç”Ÿæˆ

**ç”¨æˆ·è¾“å…¥**: "ç”Ÿæˆ10ä¸ªå…³äºæ”¿æ²»å…‰è°±çš„å¸¸è§é—®é¢˜å’Œç­”æ¡ˆ"

**å¤„ç†æµç¨‹**:

```python
# ä½¿ç”¨ Data API + XCS vmap
questions = [
    "ä»€ä¹ˆæ˜¯æ”¿æ²»å…‰è°±?",
    "å·¦ç¿¼å’Œå³ç¿¼çš„åŒºåˆ«?",
    "å¦‚ä½•ç¡®å®šè‡ªå·±çš„æ”¿æ²»ç«‹åœº?",
    # ... 10ä¸ªé—®é¢˜
]

# æ‰¹é‡å¤„ç†
@xcs.jit
def batch_generate_answers(questions):
    """JIT ä¼˜åŒ–çš„æ‰¹é‡é—®ç­”"""
    return [models("gemini-2.5-flash", q) for q in questions]

# æˆ–ä½¿ç”¨ vmap å¹¶è¡Œ
vmapped_chat = xcs.vmap(lambda q: models("gemini-2.5-flash", q))
answers = vmapped_chat(questions)

# æˆæœ¬: ~$0.01 (ä½¿ç”¨ä¾¿å®œçš„ Gemini)
# æ—¶é—´: ~3ç§’ (å¹¶è¡Œæ‰§è¡Œ)
```

#### åœºæ™¯ 4: å¤šè¯­è¨€æ”¯æŒ

**ç”¨æˆ·è¾“å…¥**: "Translate this political statement to English, French, and Spanish"

**å¤„ç†æµç¨‹**:

```python
# å¤šæ¨¡å‹å¹¶è¡Œç¿»è¯‘
languages = ["English", "French", "Spanish"]

def translate_to_language(text, target_lang):
    prompt = f"Translate to {target_lang}: {text}"
    return models("gemini-2.5-flash", prompt)

# å¹¶è¡Œç¿»è¯‘
from concurrent.futures import ThreadPoolExecutor

with ThreadPoolExecutor(max_workers=3) as executor:
    futures = [
        executor.submit(translate_to_language, original_text, lang)
        for lang in languages
    ]
    translations = [f.result() for f in futures]

# è¿”å› 3 ç§è¯­è¨€çš„ç¿»è¯‘
# æˆæœ¬: ~$0.003
# æ—¶é—´: ~2ç§’ (å¹¶è¡Œ)
```

### 4.3 ç”¨æˆ·åˆ†å±‚ç­–ç•¥

```python
class UserTier:
    """ç”¨æˆ·ç­‰çº§å®šä¹‰"""

    FREE = "free"           # å…è´¹ç”¨æˆ·
    BASIC = "basic"         # åŸºç¡€ä»˜è´¹
    PREMIUM = "premium"     # é«˜çº§ä»˜è´¹
    ENTERPRISE = "enterprise"  # ä¼ä¸šç”¨æˆ·

# ä¸åŒç­‰çº§çš„åŠŸèƒ½æƒé™
TIER_LIMITS = {
    UserTier.FREE: {
        "modes": ["default"],           # ä»…åŸºç¡€æ¨¡å¼
        "daily_requests": 10,            # æ¯æ—¥10æ¬¡
        "max_tokens": 1000,              # æœ€å¤š1000 tokens
        "models": ["gemini-2.5-flash"],  # ä»… Gemini
        "daily_budget": 0.10             # æ¯æ—¥$0.10é¢„ç®—
    },
    UserTier.BASIC: {
        "modes": ["default", "multi"],   # åŸºç¡€+å¤šæ¨¡å‹
        "daily_requests": 100,
        "max_tokens": 5000,
        "models": ["gemini-2.5-flash", "gpt-4o"],
        "daily_budget": 1.00
    },
    UserTier.PREMIUM: {
        "modes": ["default", "multi", "ensemble"],
        "daily_requests": 500,
        "max_tokens": 20000,
        "models": ["all"],               # æ‰€æœ‰æ¨¡å‹
        "daily_budget": 10.00
    },
    UserTier.ENTERPRISE: {
        "modes": ["all"],
        "daily_requests": -1,            # æ— é™åˆ¶
        "max_tokens": -1,
        "models": ["all"],
        "daily_budget": -1               # æ— é™åˆ¶
    }
}

def check_user_permission(user_tier, mode, daily_usage):
    """æ£€æŸ¥ç”¨æˆ·æƒé™"""
    limits = TIER_LIMITS[user_tier]

    # æ£€æŸ¥æ¨¡å¼æƒé™
    if mode not in limits["modes"] and "all" not in limits["modes"]:
        return False, "æ­¤æ¨¡å¼éœ€è¦å‡çº§ä¼šå‘˜"

    # æ£€æŸ¥è¯·æ±‚æ¬¡æ•°
    if limits["daily_requests"] != -1 and daily_usage >= limits["daily_requests"]:
        return False, "ä»Šæ—¥è¯·æ±‚æ¬¡æ•°å·²ç”¨å®Œ"

    return True, None
```

---

## 5. API æ¥å£è®¾è®¡

### 5.1 RESTful API è§„èŒƒ

#### 5.1.1 åŸºç¡€èŠå¤© API

**ç«¯ç‚¹**: `POST /api/ember/chat`

**è¯·æ±‚ä½“**:
```json
{
  "message": "ä½ å¯¹å…¨çƒåŒ–çš„çœ‹æ³•?",
  "mode": "ensemble",
  "user_context": {
    "economic": -2.5,
    "social": 3.1,
    "diplomatic": 1.2,
    "label": "Social Democrat"
  },
  "language": "ZH",
  "model_preference": "auto",
  "options": {
    "include_candidates": true,
    "include_cost": true,
    "stream": false
  }
}
```

**å“åº”**:
```json
{
  "success": true,
  "data": {
    "answer": "å…³äºå…¨çƒåŒ–,æœ‰å¤šç§è§‚ç‚¹...",
    "candidates": [
      {
        "model": "gpt-5",
        "answer": "...",
        "confidence": 0.92
      },
      {
        "model": "gemini-2.5-flash",
        "answer": "...",
        "confidence": 0.88
      },
      {
        "model": "claude-4-sonnet",
        "answer": "...",
        "confidence": 0.95
      }
    ],
    "metadata": {
      "mode": "ensemble",
      "models_used": ["gpt-5", "gpt-5", "gpt-5", "gemini-2.5-flash", "gemini-2.5-flash", "claude-4-sonnet"],
      "execution_time": 8.5,
      "tokens": {
        "prompt": 450,
        "completion": 1200,
        "total": 1650
      },
      "cost": {
        "total": 0.0185,
        "breakdown": {
          "gpt-5": 0.012,
          "gemini-2.5-flash": 0.002,
          "claude-4-sonnet": 0.0045
        }
      }
    }
  },
  "timestamp": "2026-01-24T21:30:00Z"
}
```

#### 5.1.2 å¤šæ¨¡å‹å¯¹æ¯” API

**ç«¯ç‚¹**: `POST /api/ember/multi-model`

**è¯·æ±‚ä½“**:
```json
{
  "message": "ä»€ä¹ˆæ˜¯é‡å­è®¡ç®—?",
  "models": ["gpt-5", "gemini-2.5-flash", "claude-4-sonnet"],
  "user_context": {...},
  "language": "ZH"
}
```

**å“åº”**:
```json
{
  "success": true,
  "data": {
    "responses": [
      {
        "model": "gpt-5",
        "model_version": "gpt-5-2025-08-07",
        "answer": "é‡å­è®¡ç®—æ˜¯...",
        "tokens": 450,
        "cost": 0.00315,
        "execution_time": 2.3
      },
      {
        "model": "gemini-2.5-flash",
        "model_version": "gemini-2.5-flash",
        "answer": "é‡å­è®¡ç®—åˆ©ç”¨...",
        "tokens": 380,
        "cost": 0.00076,
        "execution_time": 1.8
      },
      {
        "model": "claude-4-sonnet",
        "model_version": "claude-4-sonnet-20250514",
        "answer": "é‡å­è®¡ç®—æ˜¯ä¸€ç§...",
        "tokens": 420,
        "cost": 0.00252,
        "execution_time": 2.1
      }
    ],
    "total_cost": 0.00643,
    "total_time": 2.5,
    "comparison": {
      "fastest": "gemini-2.5-flash",
      "cheapest": "gemini-2.5-flash",
      "most_detailed": "gpt-5"
    }
  }
}
```

#### 5.1.3 æ‰¹é‡å¤„ç† API

**ç«¯ç‚¹**: `POST /api/ember/batch`

**è¯·æ±‚ä½“**:
```json
{
  "questions": [
    "ä»€ä¹ˆæ˜¯AI?",
    "ä»€ä¹ˆæ˜¯åŒºå—é“¾?",
    "ä»€ä¹ˆæ˜¯é‡å­è®¡ç®—?"
  ],
  "model": "gemini-2.5-flash",
  "user_context": {...},
  "parallel": true
}
```

**å“åº”**:
```json
{
  "success": true,
  "data": {
    "results": [
      {
        "question": "ä»€ä¹ˆæ˜¯AI?",
        "answer": "...",
        "cost": 0.0008,
        "tokens": 320
      },
      {
        "question": "ä»€ä¹ˆæ˜¯åŒºå—é“¾?",
        "answer": "...",
        "cost": 0.0009,
        "tokens": 350
      },
      {
        "question": "ä»€ä¹ˆæ˜¯é‡å­è®¡ç®—?",
        "answer": "...",
        "cost": 0.0011,
        "tokens": 420
      }
    ],
    "total_cost": 0.0028,
    "total_time": 2.1,
    "parallel": true
  }
}
```

#### 5.1.4 æˆæœ¬ç»Ÿè®¡ API

**ç«¯ç‚¹**: `GET /api/ember/cost/stats?user_id={userId}&period=today`

**å“åº”**:
```json
{
  "success": true,
  "data": {
    "period": "today",
    "date_range": {
      "start": "2026-01-24T00:00:00Z",
      "end": "2026-01-24T23:59:59Z"
    },
    "summary": {
      "total_cost": 3.45,
      "total_requests": 127,
      "total_tokens": 145000,
      "avg_cost_per_request": 0.0272
    },
    "by_mode": {
      "default": {
        "requests": 89,
        "cost": 0.89,
        "tokens": 35000
      },
      "multi": {
        "requests": 25,
        "cost": 1.25,
        "tokens": 62000
      },
      "ensemble": {
        "requests": 13,
        "cost": 1.31,
        "tokens": 48000
      }
    },
    "by_model": {
      "gpt-5": {
        "calls": 45,
        "cost": 1.89,
        "tokens": 67000
      },
      "gemini-2.5-flash": {
        "calls": 98,
        "cost": 0.78,
        "tokens": 52000
      },
      "claude-4-sonnet": {
        "calls": 28,
        "cost": 0.78,
        "tokens": 26000
      }
    },
    "trend": [
      {"hour": "00:00", "cost": 0.12, "requests": 5},
      {"hour": "01:00", "cost": 0.08, "requests": 3},
      // ...
    ]
  }
}
```

### 5.2 WebSocket å®æ—¶ API (æµå¼å“åº”)

**è¿æ¥**: `ws://api.stanse.com/ember/stream`

**å®¢æˆ·ç«¯å‘é€**:
```json
{
  "action": "chat",
  "payload": {
    "message": "è§£é‡Šé‡å­çº ç¼ ",
    "mode": "default",
    "stream": true
  }
}
```

**æœåŠ¡å™¨æ¨é€** (æµå¼):
```json
// æ¶ˆæ¯ 1: å¼€å§‹
{"type": "start", "session_id": "abc123"}

// æ¶ˆæ¯ 2-N: å†…å®¹æµ
{"type": "content", "chunk": "é‡å­"}
{"type": "content", "chunk": "çº ç¼ "}
{"type": "content", "chunk": "æ˜¯ä¸€ç§"}
// ...

// æ¶ˆæ¯ N+1: å…ƒæ•°æ®
{"type": "metadata", "tokens": 450, "cost": 0.0032}

// æ¶ˆæ¯ N+2: ç»“æŸ
{"type": "end", "session_id": "abc123"}
```

---

## 6. å®‰å…¨æ€§æ¶æ„

### 6.1 API Key å®‰å…¨ç®¡ç†

#### 6.1.1 Secret Manager æ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         åº”ç”¨å±‚ (Cloud Run/Cloud Functions)              â”‚
â”‚                                                         â”‚
â”‚  âŒ æ—  API Keys                                         â”‚
â”‚  âŒ æ— ç¡¬ç¼–ç                                             â”‚
â”‚  âŒ æ— ç¯å¢ƒå˜é‡ä¸­çš„æ˜æ–‡ keys                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â”‚ 1. è¯·æ±‚ API Key
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Ember Core (credentials.py)                â”‚
â”‚                                                         â”‚
â”‚  æŸ¥æ‰¾é¡ºåº:                                               â”‚
â”‚  1. Secret Manager (æœ€é«˜ä¼˜å…ˆçº§)  â† ç”Ÿäº§ç¯å¢ƒ              â”‚
â”‚  2. ç¯å¢ƒå˜é‡ (åå¤‡)             â† å¼€å‘ç¯å¢ƒ              â”‚
â”‚  3. é…ç½®æ–‡ä»¶ (é™çº§)             â† æœ¬åœ°æµ‹è¯•              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â”‚ 2. è°ƒç”¨ Secret Manager API
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Google Cloud Secret Manager                     â”‚
â”‚                                                         â”‚
â”‚  é¡¹ç›®: gen-lang-client-0960644135                       â”‚
â”‚                                                         â”‚
â”‚  Secrets:                                               â”‚
â”‚  â”œâ”€ ember-openai-api-key                               â”‚
â”‚  â”‚  â”œâ”€ Version 1 (latest)                              â”‚
â”‚  â”‚  â”œâ”€ Created: 2026-01-25T01:44:31Z                   â”‚
â”‚  â”‚  â”œâ”€ Replciation: automatic                          â”‚
â”‚  â”‚  â””â”€ IAM: serviceAccount@... (accessor)              â”‚
â”‚  â”‚                                                      â”‚
â”‚  â”œâ”€ ember-google-api-key                               â”‚
â”‚  â”‚  â””â”€ ...                                             â”‚
â”‚  â”‚                                                      â”‚
â”‚  â””â”€ ember-anthropic-api-key                            â”‚
â”‚     â””â”€ ...                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â”‚ 3. è¿”å›åŠ å¯†çš„ API Key
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Ember Framework                            â”‚
â”‚                                                         â”‚
â”‚  âœ… API Key åœ¨å†…å­˜ä¸­                                    â”‚
â”‚  âœ… ä»…åœ¨ LLM API è°ƒç”¨æ—¶ä½¿ç”¨                             â”‚
â”‚  âœ… ä¸è®°å½•æ—¥å¿—                                          â”‚
â”‚  âœ… ä¸å­˜å‚¨åˆ°æ•°æ®åº“                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â”‚ 4. HTTPS åŠ å¯†ä¼ è¾“
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              å¤–éƒ¨ LLM API                                â”‚
â”‚  (OpenAI / Google AI / Anthropic)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### 6.1.2 è®¿é—®æ§åˆ¶

```python
# IAM ç­–ç•¥é…ç½®
ALLOWED_SERVICE_ACCOUNTS = [
    "ember-api@gen-lang-client-0960644135.iam.gserviceaccount.com",
    "cloud-functions@gen-lang-client-0960644135.iam.gserviceaccount.com"
]

# Secret Manager æƒé™
# roles/secretmanager.secretAccessor - ä»…è¯»å–æƒé™
# ç»ä¸æˆäºˆ secretmanager.secretCreator æˆ– secretmanager.admin

# å®¡è®¡æ—¥å¿—
# å¯ç”¨ Secret Manager è®¿é—®æ—¥å¿—
# ç›‘æ§å¼‚å¸¸è®¿é—®æ¨¡å¼
# è®¾ç½®è­¦æŠ¥: æ¯æ—¥è®¿é—®æ¬¡æ•° > 1000 æ¬¡
```

### 6.2 ç”¨æˆ·æ•°æ®éšç§

#### 6.2.1 æ•°æ®æµè½¬

```
ç”¨æˆ·è¾“å…¥ (å‰ç«¯)
    â”‚
    â”‚ âœ… HTTPS åŠ å¯†ä¼ è¾“
    â”‚
    â–¼
Cloud Run API
    â”‚
    â”œâ”€ âœ… ç”¨æˆ· context ä»…ç”¨äºæœ¬æ¬¡è¯·æ±‚
    â”œâ”€ âœ… ä¸å­˜å‚¨ç”¨æˆ·æ¶ˆæ¯å†…å®¹
    â”œâ”€ âœ… ä»…å­˜å‚¨å…ƒæ•°æ® (æˆæœ¬/tokens)
    â”‚
    â–¼
Ember Processing
    â”‚
    â”œâ”€ âœ… ä¸´æ—¶å†…å­˜å¤„ç†
    â”œâ”€ âœ… è¯·æ±‚ç»“æŸåæ¸…é™¤
    â”‚
    â–¼
LLM API
    â”‚
    â”œâ”€ âš ï¸ ç”¨æˆ·æ¶ˆæ¯å‘é€åˆ°ç¬¬ä¸‰æ–¹
    â”œâ”€ âœ… éµå®ˆå„æä¾›å•†éšç§æ”¿ç­–
    â”‚
    â–¼
å“åº”è¿”å› (å‰ç«¯)
    â”‚
    âœ… HTTPS åŠ å¯†ä¼ è¾“
```

#### 6.2.2 æ•°æ®ä¿ç•™ç­–ç•¥

```python
DATA_RETENTION_POLICY = {
    "chat_messages": {
        "storage": "firestore",
        "retention": "5æ¡æœ€è¿‘æ¶ˆæ¯",  # è¶…è¿‡è‡ªåŠ¨åˆ é™¤
        "encryption": "at_rest",
        "backup": False  # ä¸å¤‡ä»½èŠå¤©å†…å®¹
    },
    "cost_metadata": {
        "storage": "firestore",
        "retention": "90å¤©",
        "fields": [
            "timestamp",
            "model_used",
            "tokens",
            "cost",
            "mode"
        ],
        "excluded_fields": [
            "message_content",  # âŒ ä¸å­˜å‚¨æ¶ˆæ¯å†…å®¹
            "response_content"  # âŒ ä¸å­˜å‚¨å›å¤å†…å®¹
        ]
    },
    "user_profile": {
        "storage": "firestore",
        "retention": "æ°¸ä¹… (ç”¨æˆ·å¯åˆ é™¤)",
        "encryption": "field_level",
        "fields": [
            "economic",
            "social",
            "diplomatic",
            "label"
        ]
    }
}
```

### 6.3 é€Ÿç‡é™åˆ¶å’Œ DDoS é˜²æŠ¤

```python
RATE_LIMITS = {
    "by_user": {
        "free": {
            "requests_per_minute": 10,
            "requests_per_hour": 100,
            "requests_per_day": 500
        },
        "basic": {
            "requests_per_minute": 30,
            "requests_per_hour": 500,
            "requests_per_day": 5000
        },
        "premium": {
            "requests_per_minute": 100,
            "requests_per_hour": 2000,
            "requests_per_day": 20000
        }
    },
    "by_ip": {
        "requests_per_minute": 50,
        "requests_per_hour": 500
    },
    "global": {
        "max_concurrent_requests": 1000,
        "queue_size": 5000
    }
}

# ä½¿ç”¨ Cloud Armor é˜²æŠ¤
CLOUD_ARMOR_RULES = [
    {
        "priority": 1000,
        "action": "deny(403)",
        "match": "origin.region_code in ['CN', 'RU']",  # æŒ‰éœ€è°ƒæ•´
        "description": "Block high-risk regions"
    },
    {
        "priority": 2000,
        "action": "rate_based_ban",
        "match": "true",
        "rate_limit_options": {
            "conform_action": "allow",
            "exceed_action": "deny(429)",
            "rate_limit_threshold": {
                "count": 100,
                "interval_sec": 60
            }
        }
    }
]
```

---

## 7. æ€§èƒ½ä¼˜åŒ–ç­–ç•¥

### 7.1 ç¼“å­˜æ¶æ„

```python
"""
ä¸‰çº§ç¼“å­˜ç­–ç•¥
"""

# Level 1: Redis ç¼“å­˜ (çƒ­æ•°æ®)
REDIS_CONFIG = {
    "host": "redis.cloud.google.com",
    "port": 6379,
    "db": 0,
    "ttl": {
        "common_questions": 3600,      # 1å°æ—¶
        "user_context": 1800,          # 30åˆ†é’Ÿ
        "model_responses": 600,        # 10åˆ†é’Ÿ
        "cost_stats": 300              # 5åˆ†é’Ÿ
    }
}

# Level 2: Firestore ç¼“å­˜ (æ¸©æ•°æ®)
FIRESTORE_CACHE = {
    "collection": "ember_cache",
    "ttl": 86400,  # 24å°æ—¶
    "structure": {
        "question_hash": "md5(question + user_context)",
        "answer": "cached_response",
        "metadata": {...},
        "expires_at": "timestamp"
    }
}

# Level 3: CDN ç¼“å­˜ (é™æ€å†…å®¹)
CDN_CONFIG = {
    "provider": "Cloud CDN",
    "cache_rules": [
        {
            "path": "/api/ember/models/list",
            "ttl": 3600  # æ¨¡å‹åˆ—è¡¨ç¼“å­˜1å°æ—¶
        },
        {
            "path": "/api/ember/cost/pricing",
            "ttl": 86400  # å®šä»·ä¿¡æ¯ç¼“å­˜24å°æ—¶
        }
    ]
}

# ç¼“å­˜é”®ç”Ÿæˆ
def generate_cache_key(message: str, mode: str, user_context: dict) -> str:
    """ç”Ÿæˆç¼“å­˜é”®"""
    import hashlib
    import json

    # æ ‡å‡†åŒ– user_context (ç§»é™¤ä¸å½±å“ç­”æ¡ˆçš„å­—æ®µ)
    normalized_context = {
        "economic": round(user_context.get("economic", 0), 1),
        "social": round(user_context.get("social", 0), 1),
        "diplomatic": round(user_context.get("diplomatic", 0), 1),
        "label": user_context.get("label", "")
    }

    # ç»„åˆé”®
    key_data = {
        "message": message.lower().strip(),
        "mode": mode,
        "context": normalized_context
    }

    # MD5 å“ˆå¸Œ
    key_str = json.dumps(key_data, sort_keys=True)
    return hashlib.md5(key_str.encode()).hexdigest()

# ç¼“å­˜ä½¿ç”¨ç¤ºä¾‹
async def cached_chat(message, mode, user_context):
    """å¸¦ç¼“å­˜çš„èŠå¤©"""
    cache_key = generate_cache_key(message, mode, user_context)

    # å°è¯•ä» Redis è·å–
    cached = await redis_client.get(cache_key)
    if cached:
        return json.loads(cached)

    # å°è¯•ä» Firestore è·å–
    doc = await firestore.collection("ember_cache").document(cache_key).get()
    if doc.exists and not is_expired(doc.get("expires_at")):
        result = doc.to_dict()
        # å›å†™åˆ° Redis
        await redis_client.setex(
            cache_key,
            REDIS_CONFIG["ttl"]["model_responses"],
            json.dumps(result)
        )
        return result

    # ç¼“å­˜æœªå‘½ä¸­,è°ƒç”¨ Ember
    result = await ember_service.chat(message, mode, user_context)

    # å†™å…¥ä¸¤çº§ç¼“å­˜
    await redis_client.setex(
        cache_key,
        REDIS_CONFIG["ttl"]["model_responses"],
        json.dumps(result)
    )
    await firestore.collection("ember_cache").document(cache_key).set({
        **result,
        "expires_at": datetime.now() + timedelta(seconds=FIRESTORE_CACHE["ttl"])
    })

    return result
```

### 7.2 å¹¶å‘å¤„ç†

```python
"""
é«˜å¹¶å‘å¤„ç†æ¶æ„
"""

# ä½¿ç”¨ asyncio + concurrent.futures
import asyncio
from concurrent.futures import ThreadPoolExecutor

class ConcurrentEmberService:
    def __init__(self, max_workers=20):
        self.executor = ThreadPoolExecutor(max_workers=max_workers)
        self.semaphore = asyncio.Semaphore(100)  # æœ€å¤š100ä¸ªå¹¶å‘è¯·æ±‚

    async def chat_async(self, message, mode, user_context):
        """å¼‚æ­¥èŠå¤©æ¥å£"""
        async with self.semaphore:
            loop = asyncio.get_event_loop()
            result = await loop.run_in_executor(
                self.executor,
                self._sync_chat,
                message,
                mode,
                user_context
            )
            return result

    def _sync_chat(self, message, mode, user_context):
        """åŒæ­¥èŠå¤© (è°ƒç”¨ Ember)"""
        return ember_service.chat(message, mode, user_context)

# æ‰¹é‡è¯·æ±‚å¤„ç†
async def handle_batch_requests(requests: list):
    """æ‰¹é‡å¤„ç†å¤šä¸ªè¯·æ±‚"""
    service = ConcurrentEmberService(max_workers=50)

    tasks = [
        service.chat_async(req["message"], req["mode"], req["user_context"])
        for req in requests
    ]

    results = await asyncio.gather(*tasks, return_exceptions=True)

    # å¤„ç†å¼‚å¸¸
    for i, result in enumerate(results):
        if isinstance(result, Exception):
            print(f"Request {i} failed: {result}")
            results[i] = {"success": False, "error": str(result)}

    return results
```

### 7.3 æ™ºèƒ½è´Ÿè½½å‡è¡¡

```python
"""
æ¨¡å‹è´Ÿè½½å‡è¡¡ç­–ç•¥
"""

class ModelLoadBalancer:
    """æ™ºèƒ½æ¨¡å‹è´Ÿè½½å‡è¡¡"""

    def __init__(self):
        self.model_pools = {
            "fast": ["gemini-2.5-flash"],
            "balanced": ["gpt-4o", "gemini-2.5-pro"],
            "quality": ["gpt-5", "claude-4-sonnet"]
        }
        self.model_stats = {}  # æ¨¡å‹ç»Ÿè®¡ä¿¡æ¯

    def select_model(self, preference: str, current_load: dict) -> str:
        """åŸºäºè´Ÿè½½é€‰æ‹©æ¨¡å‹"""
        pool = self.model_pools.get(preference, self.model_pools["balanced"])

        # è®¡ç®—æ¯ä¸ªæ¨¡å‹çš„è´Ÿè½½åˆ†æ•°
        scores = {}
        for model in pool:
            load = current_load.get(model, 0)
            capacity = self._get_model_capacity(model)

            # è´Ÿè½½åˆ†æ•° = (1 - load/capacity) * æ¨¡å‹è´¨é‡æƒé‡
            load_score = (1 - load / capacity) * self._get_quality_weight(model)
            scores[model] = load_score

        # é€‰æ‹©è´Ÿè½½æœ€ä½çš„æ¨¡å‹
        return max(scores.items(), key=lambda x: x[1])[0]

    def _get_model_capacity(self, model: str) -> int:
        """è·å–æ¨¡å‹å®¹é‡ (æ¯åˆ†é’Ÿè¯·æ±‚æ•°)"""
        capacities = {
            "gemini-2.5-flash": 1000,
            "gpt-4o": 500,
            "gpt-5": 200,
            "claude-4-sonnet": 300
        }
        return capacities.get(model, 100)

    def _get_quality_weight(self, model: str) -> float:
        """è·å–æ¨¡å‹è´¨é‡æƒé‡"""
        weights = {
            "gpt-5": 1.0,
            "claude-4-sonnet": 0.95,
            "gpt-4o": 0.90,
            "gemini-2.5-pro": 0.88,
            "gemini-2.5-flash": 0.85
        }
        return weights.get(model, 0.80)

# ä½¿ç”¨ç¤ºä¾‹
balancer = ModelLoadBalancer()

async def balanced_chat(message, preference="balanced"):
    """è´Ÿè½½å‡è¡¡çš„èŠå¤©"""
    current_load = await get_current_model_load()
    model = balancer.select_model(preference, current_load)

    result = models.response(model, message)
    return result
```

### 7.4 é¢„çƒ­å’Œé¢„åŠ è½½

```python
"""
ç³»ç»Ÿé¢„çƒ­ç­–ç•¥
"""

class SystemWarmer:
    """ç³»ç»Ÿé¢„çƒ­å™¨"""

    async def warmup(self):
        """é¢„çƒ­å…³é”®è·¯å¾„"""
        tasks = [
            self._warmup_models(),
            self._warmup_cache(),
            self._warmup_connections()
        ]
        await asyncio.gather(*tasks)

    async def _warmup_models(self):
        """é¢„çƒ­æ¨¡å‹è¿æ¥"""
        test_message = "Hello"

        for model in ["gpt-5", "gemini-2.5-flash", "claude-4-sonnet"]:
            try:
                _ = models(model, test_message)
                print(f"âœ“ Warmed up {model}")
            except Exception as e:
                print(f"âœ— Failed to warm up {model}: {e}")

    async def _warmup_cache(self):
        """é¢„åŠ è½½å¸¸è§é—®é¢˜ç¼“å­˜"""
        common_questions = await self._get_common_questions()

        for question in common_questions[:100]:
            cache_key = generate_cache_key(question["text"], "default", {})
            if not await redis_client.exists(cache_key):
                # ç¼“å­˜æœªå‘½ä¸­,é¢„ç”Ÿæˆç­”æ¡ˆ
                result = await ember_service.chat(
                    question["text"],
                    "default",
                    {}
                )
                await redis_client.setex(
                    cache_key,
                    3600,
                    json.dumps(result)
                )

    async def _warmup_connections(self):
        """é¢„çƒ­æ•°æ®åº“è¿æ¥"""
        await firestore.collection("users").limit(1).get()
        await redis_client.ping()
        print("âœ“ Database connections warmed up")

# Cloud Run å¯åŠ¨æ—¶æ‰§è¡Œ
@app.on_event("startup")
async def startup_event():
    warmer = SystemWarmer()
    await warmer.warmup()
```

---

## 8. æˆæœ¬ç®¡ç†æ–¹æ¡ˆ

### 8.1 æˆæœ¬è®¡ç®—æ¨¡å‹

```python
"""
ç²¾ç¡®æˆæœ¬è®¡ç®—
"""

# æ¨¡å‹å®šä»· (2026å¹´1æœˆä»·æ ¼,å¯èƒ½å˜åŒ–)
MODEL_PRICING = {
    "gpt-5": {
        "prompt": 0.000007,      # $7 / 1M tokens
        "completion": 0.000021   # $21 / 1M tokens
    },
    "gpt-4o": {
        "prompt": 0.0000025,     # $2.5 / 1M tokens
        "completion": 0.00001    # $10 / 1M tokens
    },
    "gemini-2.5-flash": {
        "prompt": 0.0000001,     # $0.1 / 1M tokens
        "completion": 0.0000003  # $0.3 / 1M tokens
    },
    "claude-4-sonnet": {
        "prompt": 0.000003,      # $3 / 1M tokens
        "completion": 0.000015   # $15 / 1M tokens
    }
}

def calculate_cost(model: str, prompt_tokens: int, completion_tokens: int) -> float:
    """è®¡ç®—è¯·æ±‚æˆæœ¬"""
    pricing = MODEL_PRICING.get(model)
    if not pricing:
        return 0.0

    prompt_cost = (prompt_tokens / 1_000_000) * pricing["prompt"]
    completion_cost = (completion_tokens / 1_000_000) * pricing["completion"]

    return prompt_cost + completion_cost

# æ¨¡å¼æˆæœ¬ä¼°ç®—
MODE_COST_ESTIMATES = {
    "default": {
        "model": "auto-selected",
        "avg_tokens": 500,
        "estimated_cost": 0.0015,  # $0.0015 å¹³å‡
        "range": (0.0001, 0.005)
    },
    "multi": {
        "models": 3,
        "avg_tokens_per_model": 450,
        "estimated_cost": 0.0045,  # $0.0045 å¹³å‡
        "range": (0.002, 0.01)
    },
    "ensemble": {
        "models": 6,  # 5 å€™é€‰ + 1 è¯„åˆ¤
        "avg_tokens_total": 2000,
        "estimated_cost": 0.018,   # $0.018 å¹³å‡
        "range": (0.01, 0.03)
    },
    "batch": {
        "model": "gemini-2.5-flash",
        "cost_per_question": 0.0002,
        "estimated_cost": "0.0002 * N"  # N = é—®é¢˜æ•°
    }
}
```

### 8.2 é¢„ç®—æ§åˆ¶

```python
"""
ç”¨æˆ·é¢„ç®—ç®¡ç†
"""

class BudgetManager:
    """é¢„ç®—ç®¡ç†å™¨"""

    def __init__(self, firestore_client):
        self.db = firestore_client

    async def check_budget(self, user_id: str, estimated_cost: float) -> tuple[bool, str]:
        """æ£€æŸ¥ç”¨æˆ·é¢„ç®—"""
        # è·å–ç”¨æˆ·é¢„ç®—è®¾ç½®
        budget_doc = await self.db.collection("user_budgets").document(user_id).get()

        if not budget_doc.exists:
            # æ— é¢„ç®—é™åˆ¶
            return True, None

        budget_data = budget_doc.to_dict()
        daily_limit = budget_data.get("daily_limit", 1.0)  # é»˜è®¤ $1/å¤©

        # è·å–ä»Šæ—¥å·²ç”¨
        today_usage = await self._get_today_usage(user_id)

        # æ£€æŸ¥æ˜¯å¦è¶…é¢„ç®—
        if today_usage + estimated_cost > daily_limit:
            remaining = daily_limit - today_usage
            return False, f"é¢„ç®—ä¸è¶³ã€‚ä»Šæ—¥é™é¢: ${daily_limit}, å·²ç”¨: ${today_usage:.4f}, å‰©ä½™: ${remaining:.4f}"

        return True, None

    async def _get_today_usage(self, user_id: str) -> float:
        """è·å–ä»Šæ—¥ä½¿ç”¨é‡"""
        today = datetime.now().date()

        usage_docs = await self.db.collection("user_chat_costs") \
            .document(user_id) \
            .collection("sessions") \
            .where("date", "==", today) \
            .get()

        total = sum(doc.get("cost", 0.0) for doc in usage_docs)
        return total

    async def record_usage(self, user_id: str, cost: float, metadata: dict):
        """è®°å½•ä½¿ç”¨"""
        await self.db.collection("user_chat_costs") \
            .document(user_id) \
            .collection("sessions") \
            .add({
                "timestamp": datetime.now(),
                "date": datetime.now().date(),
                "cost": cost,
                "model": metadata.get("model"),
                "mode": metadata.get("mode"),
                "tokens": metadata.get("tokens"),
            })

# ä½¿ç”¨ç¤ºä¾‹
budget_manager = BudgetManager(firestore_client)

async def budget_aware_chat(user_id, message, mode):
    """å¸¦é¢„ç®—æ£€æŸ¥çš„èŠå¤©"""
    # ä¼°ç®—æˆæœ¬
    estimated_cost = MODE_COST_ESTIMATES[mode]["estimated_cost"]

    # æ£€æŸ¥é¢„ç®—
    can_proceed, error_msg = await budget_manager.check_budget(user_id, estimated_cost)

    if not can_proceed:
        return {
            "success": False,
            "error": error_msg,
            "suggestion": "è¯·å‡çº§å¥—é¤æˆ–æ˜å¤©å†è¯•"
        }

    # æ‰§è¡ŒèŠå¤©
    result = await ember_service.chat(message, mode, {})

    # è®°å½•å®é™…æˆæœ¬
    await budget_manager.record_usage(
        user_id,
        result["cost"],
        {
            "model": result["model_used"],
            "mode": mode,
            "tokens": result["tokens"]
        }
    )

    return result
```

### 8.3 æˆæœ¬ä¼˜åŒ–ç­–ç•¥

```python
"""
æ™ºèƒ½æˆæœ¬ä¼˜åŒ–
"""

class CostOptimizer:
    """æˆæœ¬ä¼˜åŒ–å™¨"""

    def optimize_model_selection(
        self,
        message: str,
        user_context: dict,
        quality_requirement: str = "balanced"
    ) -> str:
        """åŸºäºæˆæœ¬å’Œè´¨é‡éœ€æ±‚é€‰æ‹©æœ€ä¼˜æ¨¡å‹"""

        # åˆ†æé—®é¢˜å¤æ‚åº¦
        complexity = self._analyze_complexity(message)

        # è´¨é‡éœ€æ±‚æ˜ å°„
        quality_map = {
            "minimum": 0.7,
            "balanced": 0.85,
            "maximum": 0.95
        }
        required_quality = quality_map.get(quality_requirement, 0.85)

        # æ¨¡å‹è´¨é‡å’Œæˆæœ¬
        model_options = [
            {
                "model": "gemini-2.5-flash",
                "quality": 0.80,
                "cost_per_token": 0.0000002,  # å¹³å‡
                "speed": "fast"
            },
            {
                "model": "gpt-4o",
                "quality": 0.90,
                "cost_per_token": 0.000006,
                "speed": "medium"
            },
            {
                "model": "gpt-5",
                "quality": 0.95,
                "cost_per_token": 0.000014,
                "speed": "slow"
            }
        ]

        # ç­›é€‰æ»¡è¶³è´¨é‡è¦æ±‚çš„æ¨¡å‹
        qualified = [m for m in model_options if m["quality"] >= required_quality]

        if not qualified:
            # å¦‚æœæ— æ³•æ»¡è¶³,é€‰æ‹©æœ€é«˜è´¨é‡æ¨¡å‹
            return max(model_options, key=lambda x: x["quality"])["model"]

        # åœ¨æ»¡è¶³è´¨é‡çš„å‰æä¸‹,é€‰æ‹©æˆæœ¬æœ€ä½çš„
        return min(qualified, key=lambda x: x["cost_per_token"])["model"]

    def _analyze_complexity(self, message: str) -> float:
        """åˆ†æé—®é¢˜å¤æ‚åº¦ (0-1)"""
        factors = []

        # é•¿åº¦å› ç´ 
        length_score = min(len(message) / 500, 1.0)
        factors.append(length_score * 0.3)

        # å…³é”®è¯å› ç´ 
        complex_keywords = [
            "ä¸ºä»€ä¹ˆ", "å¦‚ä½•", "åˆ†æ", "è§£é‡Š", "æ¯”è¾ƒ",
            "è¯„ä»·", "æ·±å…¥", "è¯¦ç»†", "åŸå› ", "å½±å“"
        ]
        keyword_count = sum(1 for kw in complex_keywords if kw in message)
        keyword_score = min(keyword_count / 3, 1.0)
        factors.append(keyword_score * 0.4)

        # ä¸“ä¸šæ€§å› ç´ 
        professional_terms = ["æ”¿æ²»", "ç»æµ", "å“²å­¦", "ç§‘æŠ€", "é‡å­", "AI"]
        professional_count = sum(1 for term in professional_terms if term in message)
        professional_score = min(professional_count / 2, 1.0)
        factors.append(professional_score * 0.3)

        return sum(factors)

    def suggest_mode_downgrade(self, mode: str, question_type: str) -> str:
        """å»ºè®®é™çº§æ¨¡å¼ä»¥èŠ‚çœæˆæœ¬"""

        # ç®€å•é—®ç­”ä¸éœ€è¦ ensemble
        if mode == "ensemble" and question_type == "simple":
            return "default"

        # äº‹å®æŸ¥è¯¢ä¸éœ€è¦å¤šæ¨¡å‹
        if mode == "multi" and question_type == "factual":
            return "default"

        return mode

# ä½¿ç”¨ç¤ºä¾‹
optimizer = CostOptimizer()

async def cost_optimized_chat(user_id, message, mode="default"):
    """æˆæœ¬ä¼˜åŒ–çš„èŠå¤©"""

    # åˆ†æé—®é¢˜ç±»å‹
    question_type = classify_question(message)  # simple/complex/factual/opinion

    # å»ºè®®æ¨¡å¼é™çº§
    suggested_mode = optimizer.suggest_mode_downgrade(mode, question_type)

    if suggested_mode != mode:
        # é€šçŸ¥ç”¨æˆ·å¯èŠ‚çœæˆæœ¬
        print(f"å»ºè®®ä½¿ç”¨ {suggested_mode} æ¨¡å¼,å¯èŠ‚çœçº¦ {calculate_savings(mode, suggested_mode)}%")

    # é€‰æ‹©æœ€ä¼˜æ¨¡å‹
    model = optimizer.optimize_model_selection(
        message,
        {},
        quality_requirement="balanced"
    )

    result = await ember_service.chat(message, suggested_mode, {})
    return result
```

---

## 9. å®æ–½è·¯çº¿å›¾

### 9.1 Phase 1: åŸºç¡€é›†æˆ (Week 1-2)

**ç›®æ ‡**: å®ç°åŸºæœ¬çš„ Ember é›†æˆ,æ›¿ä»£ç°æœ‰ Gemini Provider

#### ä»»åŠ¡åˆ—è¡¨

| ä»»åŠ¡ | ä¼˜å…ˆçº§ | é¢„è®¡æ—¶é—´ | è´Ÿè´£æ¨¡å— |
|-----|--------|---------|---------|
| 1.1 åˆ›å»º Ember API Cloud Function | P0 | 2å¤© | Backend |
| 1.2 å®ç° /api/ember/chat ç«¯ç‚¹ | P0 | 1å¤© | Backend |
| 1.3 é›†æˆ Secret Manager | P0 | 0.5å¤© | Backend |
| 1.4 åŸºç¡€é”™è¯¯å¤„ç† | P0 | 0.5å¤© | Backend |
| 1.5 å‰ç«¯è°ƒç”¨ Ember API | P0 | 1å¤© | Frontend |
| 1.6 æˆæœ¬è¿½è¸ªåŸºç¡€ç‰ˆ | P1 | 1å¤© | Backend |
| 1.7 å•å…ƒæµ‹è¯• | P1 | 1å¤© | Testing |
| 1.8 é›†æˆæµ‹è¯• | P1 | 1å¤© | Testing |
| 1.9 æ€§èƒ½æµ‹è¯• | P2 | 0.5å¤© | Testing |
| 1.10 æ–‡æ¡£æ›´æ–° | P2 | 0.5å¤© | Docs |

**äº¤ä»˜ç‰©**:
- âœ… Ember API å¯ç”¨
- âœ… å‰ç«¯æˆåŠŸè°ƒç”¨
- âœ… åŸºç¡€æˆæœ¬è¿½è¸ª
- âœ… æµ‹è¯•è¦†ç›–ç‡ > 80%

**æˆåŠŸæŒ‡æ ‡**:
- API å“åº”æ—¶é—´ < 3ç§’
- æˆåŠŸç‡ > 99%
- æˆæœ¬å‡†ç¡®ç‡ 100%

### 9.2 Phase 2: å¤šæ¨¡å¼æ”¯æŒ (Week 3-4)

**ç›®æ ‡**: æ·»åŠ å¤šæ¨¡å‹å¯¹æ¯”å’Œ Ensemble æ¨¡å¼

#### ä»»åŠ¡åˆ—è¡¨

| ä»»åŠ¡ | ä¼˜å…ˆçº§ | é¢„è®¡æ—¶é—´ | è´Ÿè´£æ¨¡å— |
|-----|--------|---------|---------|
| 2.1 å®ç° multi-model æ¨¡å¼ | P0 | 2å¤© | Backend |
| 2.2 å®ç° ensemble æ¨¡å¼ | P0 | 2å¤© | Backend |
| 2.3 å‰ç«¯æ¨¡å¼é€‰æ‹©å™¨ | P0 | 1å¤© | Frontend |
| 2.4 å¹¶å‘å¤„ç†ä¼˜åŒ– | P1 | 1å¤© | Backend |
| 2.5 ç¼“å­˜ç³»ç»Ÿ (Redis) | P1 | 1å¤© | Backend |
| 2.6 æˆæœ¬å±•ç¤º UI | P1 | 1å¤© | Frontend |
| 2.7 æ€§èƒ½ç›‘æ§ | P2 | 0.5å¤© | DevOps |
| 2.8 A/B æµ‹è¯• | P2 | 0.5å¤© | Testing |

**äº¤ä»˜ç‰©**:
- âœ… 3ç§èŠå¤©æ¨¡å¼å¯ç”¨
- âœ… Redis ç¼“å­˜é›†æˆ
- âœ… æˆæœ¬å®æ—¶æ˜¾ç¤º

**æˆåŠŸæŒ‡æ ‡**:
- Multi-model å“åº”æ—¶é—´ < 5ç§’
- Ensemble å“åº”æ—¶é—´ < 10ç§’
- ç¼“å­˜å‘½ä¸­ç‡ > 30%

### 9.3 Phase 3: é«˜çº§åŠŸèƒ½ (Week 5-6)

**ç›®æ ‡**: æ‰¹é‡å¤„ç†ã€æ™ºèƒ½ä¼˜åŒ–ã€ç”¨æˆ·åˆ†å±‚

#### ä»»åŠ¡åˆ—è¡¨

| ä»»åŠ¡ | ä¼˜å…ˆçº§ | é¢„è®¡æ—¶é—´ | è´Ÿè´£æ¨¡å— |
|-----|--------|---------|---------|
| 3.1 æ‰¹é‡å¤„ç†æ¨¡å¼ | P1 | 2å¤© | Backend |
| 3.2 æ™ºèƒ½æ¨¡å‹é€‰æ‹© | P1 | 1å¤© | Backend |
| 3.3 ç”¨æˆ·é¢„ç®—ç®¡ç† | P0 | 2å¤© | Backend |
| 3.4 ç”¨æˆ·ç­‰çº§ç³»ç»Ÿ | P0 | 1å¤© | Backend |
| 3.5 æˆæœ¬ç»Ÿè®¡ä»ªè¡¨æ¿ | P1 | 2å¤© | Frontend |
| 3.6 è‡ªåŠ¨æˆæœ¬ä¼˜åŒ– | P2 | 1å¤© | Backend |

**äº¤ä»˜ç‰©**:
- âœ… æ‰¹é‡å¤„ç†å¯ç”¨
- âœ… ç”¨æˆ·é¢„ç®—æ§åˆ¶
- âœ… 4ä¸ªç”¨æˆ·ç­‰çº§

**æˆåŠŸæŒ‡æ ‡**:
- æ‰¹é‡å¤„ç†ååé‡ > 100 req/min
- é¢„ç®—è¶…æ”¯ç‡ = 0%
- ç”¨æˆ·æ»¡æ„åº¦ > 4.5/5

### 9.4 Phase 4: ä¼˜åŒ–å’Œæ‰©å±• (Week 7-8)

**ç›®æ ‡**: æ€§èƒ½ä¼˜åŒ–ã€ç›‘æ§å®Œå–„ã€æ–‡æ¡£å®Œå–„

#### ä»»åŠ¡åˆ—è¡¨

| ä»»åŠ¡ | ä¼˜å…ˆçº§ | é¢„è®¡æ—¶é—´ | è´Ÿè´£æ¨¡å— |
|-----|--------|---------|---------|
| 4.1 è´Ÿè½½å‡è¡¡ä¼˜åŒ– | P1 | 1å¤© | Backend |
| 4.2 ç³»ç»Ÿé¢„çƒ­ | P2 | 0.5å¤© | Backend |
| 4.3 å®Œæ•´ç›‘æ§ | P0 | 2å¤© | DevOps |
| 4.4 å‘Šè­¦ç³»ç»Ÿ | P0 | 1å¤© | DevOps |
| 4.5 ç”¨æˆ·æ–‡æ¡£ | P1 | 1å¤© | Docs |
| 4.6 API æ–‡æ¡£ | P1 | 1å¤© | Docs |
| 4.7 æ€§èƒ½å‹æµ‹ | P1 | 1å¤© | Testing |
| 4.8 å®‰å…¨å®¡è®¡ | P0 | 1å¤© | Security |

**äº¤ä»˜ç‰©**:
- âœ… å®Œæ•´ç›‘æ§ç³»ç»Ÿ
- âœ… å‘Šè­¦æœºåˆ¶
- âœ… å®Œæ•´æ–‡æ¡£
- âœ… å®‰å…¨å®¡è®¡æŠ¥å‘Š

**æˆåŠŸæŒ‡æ ‡**:
- P99 å»¶è¿Ÿ < 5ç§’
- å¯ç”¨æ€§ > 99.9%
- æ–‡æ¡£å®Œæ•´åº¦ 100%

### 9.5 é˜¶æ®µæ€§é‡Œç¨‹ç¢‘

```
Week 1-2: Phase 1 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 100%
â”œâ”€ Day 1-2:   Ember API å¼€å‘
â”œâ”€ Day 3-4:   å‰ç«¯é›†æˆ
â”œâ”€ Day 5-6:   æµ‹è¯•å’Œä¼˜åŒ–
â””â”€ Day 7-10:  æ–‡æ¡£å’Œéƒ¨ç½²

Week 3-4: Phase 2 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 100%
â”œâ”€ Day 11-14: å¤šæ¨¡å¼å®ç°
â”œâ”€ Day 15-17: ç¼“å­˜å’Œä¼˜åŒ–
â””â”€ Day 18-20: UI å’Œæµ‹è¯•

Week 5-6: Phase 3 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 100%
â”œâ”€ Day 21-24: é«˜çº§åŠŸèƒ½
â”œâ”€ Day 25-28: ç”¨æˆ·ç³»ç»Ÿ
â””â”€ Day 29-30: é›†æˆæµ‹è¯•

Week 7-8: Phase 4 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 100%
â”œâ”€ Day 31-35: ä¼˜åŒ–å’Œç›‘æ§
â”œâ”€ Day 36-38: æ–‡æ¡£å®Œå–„
â””â”€ Day 39-40: æœ€ç»ˆéªŒæ”¶

ğŸ¯ æœ€ç»ˆäº¤ä»˜: Week 8 ç»“æŸ
```

### 9.6 é£é™©å’Œç¼“è§£

| é£é™© | æ¦‚ç‡ | å½±å“ | ç¼“è§£æªæ–½ |
|------|------|------|---------|
| **Ember API é™é€Ÿ** | ä¸­ | é«˜ | å®æ–½å¤šæä¾›å•†é™çº§ç­–ç•¥ |
| **æˆæœ¬è¶…é¢„ç®—** | ä¸­ | ä¸­ | ä¸¥æ ¼é¢„ç®—æ§åˆ¶ + ç”¨æˆ·é™é¢ |
| **æ€§èƒ½ä¸è¾¾æ ‡** | ä½ | é«˜ | æå‰å‹æµ‹ + Redis ç¼“å­˜ |
| **å®‰å…¨æ¼æ´** | ä½ | é«˜ | å®‰å…¨å®¡è®¡ + Secret Manager |
| **ç”¨æˆ·ä½“éªŒä¸‹é™** | ä¸­ | ä¸­ | A/B æµ‹è¯• + æ¸è¿›å¼å‘å¸ƒ |

---

## 10. é™„å½•

### 10.1 æŠ€æœ¯æ ˆæ¸…å•

#### åç«¯
- **è¯­è¨€**: Python 3.12+
- **æ¡†æ¶**: FastAPI / Flask
- **éƒ¨ç½²**: Cloud Run
- **Ember**: æœ€æ–°ç‰ˆæœ¬ (0.1.0+)
- **æ•°æ®åº“**: Firestore
- **ç¼“å­˜**: Redis (Cloud Memorystore)
- **Secret ç®¡ç†**: Google Secret Manager
- **ç›‘æ§**: Cloud Logging + Cloud Monitoring

#### å‰ç«¯
- **è¯­è¨€**: TypeScript
- **æ¡†æ¶**: React
- **UI**: Tailwind CSS
- **çŠ¶æ€ç®¡ç†**: Context API
- **HTTP**: Axios / Fetch API

#### DevOps
- **CI/CD**: Cloud Build
- **ç‰ˆæœ¬æ§åˆ¶**: Git
- **å®¹å™¨**: Docker
- **ç¼–æ’**: Cloud Run (serverless)

### 10.2 æ€§èƒ½åŸºå‡†

| æŒ‡æ ‡ | ç›®æ ‡å€¼ | å½“å‰å€¼ | å¤‡æ³¨ |
|------|--------|--------|------|
| **API å“åº”æ—¶é—´** (P50) | < 2ç§’ | TBD | Default æ¨¡å¼ |
| **API å“åº”æ—¶é—´** (P99) | < 5ç§’ | TBD | Default æ¨¡å¼ |
| **Multi æ¨¡å¼å“åº”** | < 5ç§’ | TBD | 3ä¸ªæ¨¡å‹å¹¶è¡Œ |
| **Ensemble å“åº”** | < 10ç§’ | TBD | 6ä¸ªæ¨¡å‹ |
| **ååé‡** | > 100 req/s | TBD | å•å®ä¾‹ |
| **ç¼“å­˜å‘½ä¸­ç‡** | > 40% | TBD | çƒ­ç‚¹é—®é¢˜ |
| **æˆæœ¬å‡†ç¡®ç‡** | 100% | TBD | Token è®¡æ•° |
| **å¯ç”¨æ€§** | > 99.9% | TBD | æœˆåº¦ |

### 10.3 æˆæœ¬ä¼°ç®—

#### åŸºç¡€è®¾æ–½æˆæœ¬ (æœˆåº¦)
```
Cloud Run:
  - å®ä¾‹: n1-standard-1
  - å¹¶å‘: 100
  - ä¼°ç®—: $50-150/æœˆ

Cloud Memorystore (Redis):
  - å®ä¾‹: Basic, 1GB
  - ä¼°ç®—: $30/æœˆ

Firestore:
  - è¯»å–: 1M/æœˆ
  - å†™å…¥: 100K/æœˆ
  - å­˜å‚¨: 10GB
  - ä¼°ç®—: $10-20/æœˆ

Secret Manager:
  - è®¿é—®: 100K/æœˆ
  - ä¼°ç®—: $0.06/æœˆ

æ€»è®¡: ~$90-200/æœˆ
```

#### LLM API æˆæœ¬ (ç”¨æˆ·è§„æ¨¡)
```
å‡è®¾:
- æ´»è·ƒç”¨æˆ·: 1000äºº
- å¹³å‡æ¯äººæ¯å¤©: 10æ¬¡è¯·æ±‚
- å¹³å‡æ¨¡å¼åˆ†å¸ƒ:
  â€¢ default: 70% â†’ $0.0015/æ¬¡
  â€¢ multi: 20% â†’ $0.0045/æ¬¡
  â€¢ ensemble: 10% â†’ $0.018/æ¬¡

æ—¥å‡æˆæœ¬:
= 1000 * 10 * (0.70 * 0.0015 + 0.20 * 0.0045 + 0.10 * 0.018)
= 1000 * 10 * (0.00105 + 0.0009 + 0.0018)
= 1000 * 10 * 0.00375
= $37.50/å¤©

æœˆåº¦æˆæœ¬: $37.50 * 30 = $1125/æœˆ

æ€»æˆæœ¬: $90 (åŸºç¡€è®¾æ–½) + $1125 (LLM) = $1215/æœˆ
```

### 10.4 ç›¸å…³æ–‡æ¡£é“¾æ¥

- [57_ember_secret_manager_integration_2026_01_24.md](57_ember_secret_manager_integration_2026_01_24.md)
- [28_api_key_security_guide.md](28_api_key_security_guide.md)
- [Ember ä¸­æ–‡å®Œæ•´æŒ‡å—](../../ember-main/Emberä¸­æ–‡å®Œæ•´æŒ‡å—.md)

---

**æ–‡æ¡£çŠ¶æ€**: âœ… è®¾è®¡å®Œæˆ
**ä¸‹ä¸€æ­¥**: å¼€å§‹ Phase 1 å®æ–½
**æœ€åæ›´æ–°**: 2026-01-24 22:30
**å®¡é˜…çŠ¶æ€**: å¾…å®¡é˜…
