#!/usr/bin/env python3
"""
éªŒè¯ fec_company_consolidated æ•°æ®å®Œæ•´æ€§

æ£€æŸ¥é¡¹:
1. æ‰€æœ‰linkageå…¬å¸éƒ½è¢«åŒ…å«
2. æ‰€æœ‰PACå…¬å¸éƒ½è¢«åŒ…å«
3. é‡‘é¢æ­£ç¡®ç´¯åŠ 
4. æ²¡æœ‰æ•°æ®ä¸¢å¤±
"""

import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '../../..')))

import firebase_admin
from firebase_admin import credentials, firestore

# åˆå§‹åŒ–Firebase
if not firebase_admin._apps:
    cred = credentials.ApplicationDefault()
    firebase_admin.initialize_app(cred, {'projectId': 'stanseproject'})

db = firestore.client()


def verify_completeness(year: int = 2024):
    """éªŒè¯consolidatedæ•°æ®å®Œæ•´æ€§"""
    print('=' * 70)
    print(f'ğŸ” éªŒè¯ fec_company_consolidated æ•°æ®å®Œæ•´æ€§ (Year: {year})')
    print('=' * 70)

    # 1. æ”¶é›†æ‰€æœ‰å…¬å¸
    print('\nğŸ“‚ æ­¥éª¤1: æ”¶é›†æ‰€æœ‰æºæ•°æ®å…¬å¸...')

    linkage_companies = set()
    linkage_query = db.collection('fec_company_party_summary').where(
        filter=firestore.FieldFilter('data_year', '==', year)
    )
    for doc in linkage_query.stream():
        data = doc.to_dict()
        linkage_companies.add(data.get('normalized_name'))

    print(f'  âœ… Linkageå…¬å¸: {len(linkage_companies)}')

    pac_companies = set()
    pac_query = db.collection('fec_company_pac_transfers_summary').where(
        filter=firestore.FieldFilter('data_year', '==', year)
    )
    for doc in pac_query.stream():
        data = doc.to_dict()
        pac_companies.add(data.get('normalized_name'))

    print(f'  âœ… PACå…¬å¸: {len(pac_companies)}')

    all_source_companies = linkage_companies | pac_companies
    print(f'  ğŸ“Š æ€»è®¡uniqueå…¬å¸: {len(all_source_companies)}')
    print(f'  ğŸ“Š ä¸¤è€…é‡å : {len(linkage_companies & pac_companies)}')

    # 2. æ£€æŸ¥consolidated
    print('\nğŸ“‚ æ­¥éª¤2: æ£€æŸ¥consolidated collection...')

    consolidated_companies = set()
    consolidated_query = db.collection('fec_company_consolidated').where(
        filter=firestore.FieldFilter('data_year', '==', year)
    )
    for doc in consolidated_query.stream():
        data = doc.to_dict()
        consolidated_companies.add(data.get('normalized_name'))

    print(f'  âœ… Consolidatedå…¬å¸: {len(consolidated_companies)}')

    # 3. éªŒè¯å®Œæ•´æ€§
    print('\nğŸ“Š æ­¥éª¤3: éªŒè¯æ•°æ®å®Œæ•´æ€§...')

    missing_in_consolidated = all_source_companies - consolidated_companies
    extra_in_consolidated = consolidated_companies - all_source_companies

    if missing_in_consolidated:
        print(f'\nâŒ ç¼ºå¤±å…¬å¸: {len(missing_in_consolidated)}')
        for company in list(missing_in_consolidated)[:10]:
            print(f'  - {company}')
        if len(missing_in_consolidated) > 10:
            print(f'  ... è¿˜æœ‰ {len(missing_in_consolidated) - 10} ä¸ª')
    else:
        print('\nâœ… æ²¡æœ‰ç¼ºå¤±å…¬å¸')

    if extra_in_consolidated:
        print(f'\nâš ï¸  å¤šä½™å…¬å¸: {len(extra_in_consolidated)}')
        for company in list(extra_in_consolidated)[:10]:
            print(f'  - {company}')
    else:
        print('\nâœ… æ²¡æœ‰å¤šä½™å…¬å¸')

    # 4. æŠ½æ ·éªŒè¯é‡‘é¢ç´¯åŠ æ­£ç¡®æ€§
    print('\nğŸ“Š æ­¥éª¤4: æŠ½æ ·éªŒè¯é‡‘é¢ç´¯åŠ ...')

    overlap_companies = list(linkage_companies & pac_companies)
    if overlap_companies:
        sample_size = min(5, len(overlap_companies))
        print(f'  æ£€æŸ¥ {sample_size} ä¸ªé‡å å…¬å¸çš„é‡‘é¢ç´¯åŠ ...')

        errors = []
        for company in overlap_companies[:sample_size]:
            # è·å–linkageæ•°æ®
            linkage_doc = db.collection('fec_company_party_summary').document(
                f'{company}_{year}'
            ).get()
            linkage_total = linkage_doc.to_dict().get('total_contributed', 0) if linkage_doc.exists else 0

            # è·å–PACæ•°æ®
            pac_doc = db.collection('fec_company_pac_transfers_summary').document(
                f'{company}_{year}'
            ).get()
            pac_total = pac_doc.to_dict().get('total_contributed', 0) if pac_doc.exists else 0

            # è·å–consolidatedæ•°æ®
            cons_doc = db.collection('fec_company_consolidated').document(
                f'{company}_{year}'
            ).get()

            if cons_doc.exists:
                cons_data = cons_doc.to_dict()
                cons_total = cons_data.get('total_contributed', 0)
                cons_linkage = cons_data.get('linkage_total', 0)
                cons_pac = cons_data.get('pac_transfer_total', 0)

                expected_total = linkage_total + pac_total

                if cons_total != expected_total:
                    errors.append({
                        'company': company,
                        'expected': expected_total,
                        'actual': cons_total,
                        'linkage': linkage_total,
                        'pac': pac_total
                    })
                else:
                    print(f'  âœ… {company}: ${cons_total/100:.2f} = ${linkage_total/100:.2f} + ${pac_total/100:.2f}')
            else:
                errors.append({'company': company, 'error': 'missing consolidated record'})

        if errors:
            print(f'\nâŒ å‘ç° {len(errors)} ä¸ªç´¯åŠ é”™è¯¯:')
            for err in errors:
                print(f'  - {err}')
        else:
            print(f'\nâœ… æ‰€æœ‰æŠ½æ ·å…¬å¸é‡‘é¢ç´¯åŠ æ­£ç¡®')

    # 5. æ€»ç»“
    print('\n' + '=' * 70)
    print('ğŸ“‹ éªŒè¯æ€»ç»“')
    print('=' * 70)
    print(f'æºæ•°æ®å…¬å¸æ€»æ•°: {len(all_source_companies)}')
    print(f'Consolidatedå…¬å¸æ€»æ•°: {len(consolidated_companies)}')
    print(f'ç¼ºå¤±å…¬å¸: {len(missing_in_consolidated)}')
    print(f'å¤šä½™å…¬å¸: {len(extra_in_consolidated)}')

    if not missing_in_consolidated and not extra_in_consolidated:
        print('\nâœ… æ•°æ®å®Œæ•´æ€§éªŒè¯é€šè¿‡ï¼')
        return True
    else:
        print('\nâŒ æ•°æ®å®Œæ•´æ€§éªŒè¯å¤±è´¥ï¼')
        return False


if __name__ == '__main__':
    import argparse
    parser = argparse.ArgumentParser(description='éªŒè¯consolidatedæ•°æ®å®Œæ•´æ€§')
    parser.add_argument('--year', type=int, default=2024, help='æ•°æ®å¹´ä»½')
    args = parser.parse_args()

    success = verify_completeness(args.year)
    sys.exit(0 if success else 1)
