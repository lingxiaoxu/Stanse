#!/usr/bin/env python3
"""
å¢é‡å¼FECæ•°æ®ä¸Šä¼  - å¸¦è‡ªåŠ¨é‡è¯•å’ŒæŒ‡æ•°é€€é¿

ç‰¹ç‚¹ï¼š
1. æ£€æŸ¥å¹¶è·³è¿‡å·²ä¸Šä¼ çš„è®°å½•
2. é‡åˆ°é…é¢é”™è¯¯æ—¶è‡ªåŠ¨ç­‰å¾…å¹¶é‡è¯•ï¼ˆæŒ‡æ•°é€€é¿ï¼‰
3. ä¿å­˜è¿›åº¦ï¼Œå¯ä»¥ä¸­æ–­åç»§ç»­
4. è¯¦ç»†è¿›åº¦æ˜¾ç¤º
5. å¯ä»¥æ— äººå€¼å®ˆè¿è¡Œç›´åˆ°å®Œæˆ
"""

import sys
import re
import time
import json
import os
from pathlib import Path
from datetime import datetime
from collections import defaultdict
import subprocess
import random

try:
    import firebase_admin
    from firebase_admin import credentials, firestore
    from google.api_core.exceptions import ResourceExhausted, DeadlineExceeded
except ImportError:
    print('âŒ Firebaseåº“æœªå®‰è£…')
    sys.exit(1)

# é…ç½®
DATA_DIR = Path(__file__).parent / 'raw_data'
PROJECT_ID = 'stanseproject'
PROGRESS_FILE = Path(__file__).parent / 'upload_progress.json'

# æ‰¹æ¬¡é…ç½®
BATCH_SIZE = 50  # æ›´å°çš„æ‰¹æ¬¡ä»¥é¿å…è¶…æ—¶
MIN_DELAY = 3.0  # æœ€å°å»¶è¿Ÿï¼ˆç§’ï¼‰
MAX_DELAY = 300.0  # æœ€å¤§å»¶è¿Ÿï¼ˆç§’ï¼‰
INITIAL_RETRY_DELAY = 30.0  # åˆå§‹é‡è¯•å»¶è¿Ÿ

db = None

def save_progress(data):
    """ä¿å­˜ä¸Šä¼ è¿›åº¦"""
    with open(PROGRESS_FILE, 'w') as f:
        json.dump(data, f, indent=2)

def load_progress():
    """åŠ è½½ä¸Šä¼ è¿›åº¦"""
    if PROGRESS_FILE.exists():
        with open(PROGRESS_FILE, 'r') as f:
            return json.load(f)
    return {
        'committees_last_line': 0,
        'committees_uploaded': 0,
        'committees_skipped': 0,
        'candidates_last_line': 0,
        'candidates_uploaded': 0,
        'last_updated': None
    }

def init_firestore():
    """åˆå§‹åŒ–Firestore"""
    global db
    print('\nğŸ”§ åˆå§‹åŒ–Firestoreè¿æ¥...')

    try:
        if not firebase_admin._apps:
            # ä¼˜å…ˆä½¿ç”¨ç¯å¢ƒå˜é‡ä¸­çš„access tokenï¼ˆé¿å…subprocessæŒ‚èµ·ï¼‰
            access_token = os.environ.get('GCLOUD_ACCESS_TOKEN')

            if not access_token:
                # å¦‚æœç¯å¢ƒå˜é‡ä¸å­˜åœ¨ï¼Œæ‰è°ƒç”¨gcloud
                print('  â„¹ï¸  ä»gcloudè·å–access token...')
                result = subprocess.run(
                    ['gcloud', 'auth', 'print-access-token'],
                    capture_output=True, text=True, check=True
                )
                access_token = result.stdout.strip()
            else:
                print('  âœ“ ä½¿ç”¨ç¯å¢ƒå˜é‡ä¸­çš„access token')

            from google.oauth2 import credentials as oauth_creds
            cred = oauth_creds.Credentials(access_token)
            firebase_admin.initialize_app(cred, options={'projectId': PROJECT_ID})

        db = firestore.client()
        print(f'âœ… Firestoreå·²è¿æ¥ (é¡¹ç›®: {PROJECT_ID})')
        return db
    except Exception as e:
        print(f'âŒ å¤±è´¥: {e}')
        sys.exit(1)

def commit_with_retry(batch, retry_count=0, max_retries=10):
    """
    æäº¤æ‰¹æ¬¡ï¼Œå¸¦æŒ‡æ•°é€€é¿é‡è¯•

    Args:
        batch: Firestore batch
        retry_count: å½“å‰é‡è¯•æ¬¡æ•°
        max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°

    Returns:
        True if successful, False if max retries exceeded
    """
    try:
        batch.commit()
        return True
    except (ResourceExhausted, DeadlineExceeded) as e:
        if retry_count >= max_retries:
            print(f'  âŒ è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•° ({max_retries})')
            return False

        # æŒ‡æ•°é€€é¿ï¼šåˆå§‹å»¶è¿Ÿ * (2 ^ retry_count) + éšæœºæŠ–åŠ¨
        delay = min(
            INITIAL_RETRY_DELAY * (2 ** retry_count) + random.uniform(0, 5),
            MAX_DELAY
        )

        print(f'  âš ï¸  é…é¢é™åˆ¶ï¼Œç­‰å¾… {delay:.1f} ç§’åé‡è¯•ï¼ˆç¬¬ {retry_count + 1}/{max_retries} æ¬¡ï¼‰...')
        time.sleep(delay)

        # é€’å½’é‡è¯•
        return commit_with_retry(batch, retry_count + 1, max_retries)
    except Exception as e:
        print(f'  âŒ æœªçŸ¥é”™è¯¯: {e}')
        return False

def upload_committees_incremental(year, year_suffix, progress):
    """å¢é‡ä¸Šä¼ å§”å‘˜ä¼šæ•°æ®"""
    collection_name = 'fec_raw_committees'
    file_path = DATA_DIR / 'committees' / 'cm.txt'

    if not file_path.exists():
        print(f'âš ï¸  æ–‡ä»¶ä¸å­˜åœ¨: {file_path}')
        return 0

    print(f'\nğŸ“¤ å¢é‡ä¸Šä¼ å§”å‘˜ä¼šæ•°æ® ({year})...')

    start_line = progress.get('committees_last_line', 0)
    uploaded = progress.get('committees_uploaded', 0)
    skipped = progress.get('committees_skipped', 0)

    if start_line > 0:
        print(f'  ğŸ“ ä»ç¬¬ {start_line} è¡Œç»§ç»­ï¼ˆå·²ä¸Šä¼  {uploaded} æ¡ï¼Œå·²è·³è¿‡ {skipped} æ¡ï¼‰')

    batch = db.batch()
    batch_count = 0
    current_line = 0
    total_processed = 0

    with open(file_path, 'r', encoding='latin-1') as f:
        for line_num, line in enumerate(f, 1):
            # è·³è¿‡å·²å¤„ç†çš„è¡Œ
            if line_num <= start_line:
                continue

            current_line = line_num
            fields = line.strip().split('|')
            if len(fields) < 15:
                continue

            committee_id = fields[0]
            if not committee_id:
                continue

            doc_id = f'{committee_id}_{year}'
            doc_ref = db.collection(collection_name).document(doc_id)

            # æ·»åŠ åˆ°æ‰¹æ¬¡
            doc_data = {
                'committee_id': fields[0],
                'committee_name': fields[1],
                'treasurer_name': fields[2],
                'street_1': fields[3],
                'street_2': fields[4],
                'city': fields[5],
                'state': fields[6],
                'zip': fields[7],
                'designation': fields[8],
                'committee_type': fields[9],
                'party': fields[10],
                'filing_frequency': fields[11],
                'interest_group_category': fields[12],
                'connected_org_name': fields[13],
                'candidate_id': fields[14],
                'data_year': year,
                'election_cycle': f'{year-1}-{year}',
                'source_file': f'cm{year_suffix}.zip',
                'uploaded_at': datetime.utcnow(),
                'last_updated': datetime.utcnow()
            }

            batch.set(doc_ref, doc_data)
            batch_count += 1
            total_processed += 1

            # æäº¤æ‰¹æ¬¡
            if batch_count >= BATCH_SIZE:
                if commit_with_retry(batch):
                    uploaded += batch_count
                    print(f'  âœ“ ç¬¬ {current_line} è¡Œ | æœ¬æ¬¡ä¸Šä¼  {batch_count} æ¡ | æ€»è®¡: {uploaded} æ¡ (è·³è¿‡ {skipped})')

                    # ä¿å­˜è¿›åº¦
                    progress['committees_last_line'] = current_line
                    progress['committees_uploaded'] = uploaded
                    progress['committees_skipped'] = skipped
                    progress['last_updated'] = datetime.utcnow().isoformat()
                    save_progress(progress)

                    # æ­£å¸¸å»¶è¿Ÿ
                    time.sleep(MIN_DELAY + random.uniform(0, 2))
                    batch = db.batch()
                    batch_count = 0
                else:
                    # å¤±è´¥ï¼Œä¿å­˜è¿›åº¦å¹¶é€€å‡º
                    print(f'  ğŸ’¾ ä¿å­˜è¿›åº¦: ç¬¬ {current_line} è¡Œï¼Œå·²ä¸Šä¼  {uploaded} æ¡')
                    progress['committees_last_line'] = current_line
                    progress['committees_uploaded'] = uploaded
                    progress['committees_skipped'] = skipped
                    save_progress(progress)
                    return uploaded

    # æäº¤å‰©ä½™è®°å½•
    if batch_count > 0:
        if commit_with_retry(batch):
            uploaded += batch_count
            print(f'  âœ“ æœ€åæ‰¹æ¬¡ä¸Šä¼  {batch_count} æ¡')

    # ä¿å­˜æœ€ç»ˆè¿›åº¦
    progress['committees_last_line'] = current_line
    progress['committees_uploaded'] = uploaded
    progress['committees_skipped'] = skipped
    progress['committees_completed'] = True
    progress['last_updated'] = datetime.utcnow().isoformat()
    save_progress(progress)

    print(f'âœ… æˆåŠŸä¸Šä¼  {uploaded} æ¡æ–°è®°å½•ï¼Œè·³è¿‡ {skipped} æ¡å·²å­˜åœ¨è®°å½•')
    print(f'   å¤„ç†å®Œæˆåˆ°ç¬¬ {current_line} è¡Œ')
    return uploaded

def upload_candidates_incremental(year, year_suffix, progress):
    """å¢é‡ä¸Šä¼ å€™é€‰äººæ•°æ®"""
    collection_name = 'fec_raw_candidates'
    file_path = DATA_DIR / 'candidates' / 'cn.txt'

    if not file_path.exists():
        print(f'âš ï¸  æ–‡ä»¶ä¸å­˜åœ¨: {file_path}')
        return 0

    print(f'\nğŸ“¤ å¢é‡ä¸Šä¼ å€™é€‰äººæ•°æ® ({year})...')

    start_line = progress.get('candidates_last_line', 0)
    uploaded = progress.get('candidates_uploaded', 0)

    if start_line > 0:
        print(f'  ğŸ“ ä»ç¬¬ {start_line} è¡Œç»§ç»­ï¼ˆå·²ä¸Šä¼  {uploaded} æ¡ï¼‰')

    batch = db.batch()
    batch_count = 0
    current_line = 0

    with open(file_path, 'r', encoding='latin-1') as f:
        for line_num, line in enumerate(f, 1):
            if line_num <= start_line:
                continue

            current_line = line_num
            fields = line.strip().split('|')
            if len(fields) < 15:
                continue

            candidate_id = fields[0]
            if not candidate_id:
                continue

            doc_id = f'{candidate_id}_{year}'
            doc_ref = db.collection(collection_name).document(doc_id)

            doc_data = {
                'candidate_id': fields[0],
                'candidate_name': fields[1],
                'party_affiliation': fields[2],
                'election_year': int(fields[3]) if fields[3] else year,
                'office_sought': fields[4],
                'state': fields[5],
                'district': fields[6],
                'incumbent_challenger_status': fields[7],
                'candidate_status': fields[8],
                'principal_committee_id': fields[9],
                'street_1': fields[10],
                'street_2': fields[11],
                'city': fields[12],
                'state_full': fields[13],
                'zip': fields[14],
                'data_year': year,
                'election_cycle': f'{year-1}-{year}',
                'source_file': f'cn{year_suffix}.zip',
                'uploaded_at': datetime.utcnow(),
                'last_updated': datetime.utcnow()
            }

            batch.set(doc_ref, doc_data)
            batch_count += 1

            if batch_count >= BATCH_SIZE:
                if commit_with_retry(batch):
                    uploaded += batch_count
                    print(f'  âœ“ ç¬¬ {current_line} è¡Œ | å·²ä¸Šä¼  {uploaded} æ¡å€™é€‰äººè®°å½•')

                    progress['candidates_last_line'] = current_line
                    progress['candidates_uploaded'] = uploaded
                    progress['last_updated'] = datetime.utcnow().isoformat()
                    save_progress(progress)

                    time.sleep(MIN_DELAY + random.uniform(0, 2))
                    batch = db.batch()
                    batch_count = 0
                else:
                    progress['candidates_last_line'] = current_line
                    progress['candidates_uploaded'] = uploaded
                    save_progress(progress)
                    return uploaded

    if batch_count > 0:
        if commit_with_retry(batch):
            uploaded += batch_count

    progress['candidates_last_line'] = current_line
    progress['candidates_uploaded'] = uploaded
    progress['candidates_completed'] = True
    progress['last_updated'] = datetime.utcnow().isoformat()
    save_progress(progress)

    print(f'âœ… æˆåŠŸä¸Šä¼  {uploaded} æ¡å€™é€‰äººè®°å½•')
    return uploaded

def upload_contributions_incremental(year, year_suffix, progress):
    """å¢é‡ä¸Šä¼ ææ¬¾æ•°æ®"""
    collection_name = 'fec_raw_contributions_pac_to_candidate'
    file_path = DATA_DIR / 'contributions' / 'itpas2.txt'

    if not file_path.exists():
        # å°è¯•pas2.txt
        file_path = DATA_DIR / 'contributions' / 'pas2.txt'
        if not file_path.exists():
            print(f'âš ï¸  æ–‡ä»¶ä¸å­˜åœ¨: contributions/itpas2.txt æˆ– pas2.txt')
            return 0

    print(f'\nğŸ“¤ å¢é‡ä¸Šä¼ ææ¬¾æ•°æ® ({year})...')

    start_line = progress.get('contributions_last_line', 0)
    uploaded = progress.get('contributions_uploaded', 0)

    if start_line > 0:
        print(f'  ğŸ“ ä»ç¬¬ {start_line} è¡Œç»§ç»­ï¼ˆå·²ä¸Šä¼  {uploaded} æ¡ï¼‰')

    batch = db.batch()
    batch_count = 0
    current_line = 0

    with open(file_path, 'r', encoding='latin-1') as f:
        for line_num, line in enumerate(f, 1):
            if line_num <= start_line:
                continue

            current_line = line_num
            fields = line.strip().split('|')
            if len(fields) < 17:
                continue

            committee_id = fields[0]
            candidate_id = fields[16]
            amount_str = fields[14]

            if not committee_id or not candidate_id:
                continue

            try:
                amount = float(amount_str) if amount_str else 0
                amount_cents = int(amount * 100)
            except (ValueError, TypeError):
                continue

            # åˆ›å»ºå”¯ä¸€ID: committee_candidate_linenumber
            doc_id = f'{committee_id}_{candidate_id}_{line_num}'
            doc_ref = db.collection(collection_name).document(doc_id)

            doc_data = {
                'committee_id': committee_id,
                'amendment_indicator': fields[1] if len(fields) > 1 else '',
                'report_type': fields[2] if len(fields) > 2 else '',
                'election_type': fields[3] if len(fields) > 3 else '',
                'fec_record_number': fields[4] if len(fields) > 4 else '',
                'image_number': fields[5] if len(fields) > 5 else '',
                'transaction_type': fields[6] if len(fields) > 6 else '',
                'entity_type': fields[7] if len(fields) > 7 else '',
                'name': fields[8] if len(fields) > 8 else '',
                'city': fields[9] if len(fields) > 9 else '',
                'state': fields[10] if len(fields) > 10 else '',
                'zip': fields[11] if len(fields) > 11 else '',
                'employer': fields[12] if len(fields) > 12 else '',
                'occupation': fields[13] if len(fields) > 13 else '',
                'transaction_date': fields[14] if len(fields) > 14 else '',
                'transaction_amount': amount_cents,
                'other_id': fields[15] if len(fields) > 15 else '',
                'candidate_id': candidate_id,
                'transaction_pgi': fields[17] if len(fields) > 17 else '',
                'data_year': year,
                'election_cycle': f'{year-1}-{year}',
                'source_file': f'pas2{year_suffix}.zip',
                'uploaded_at': datetime.utcnow(),
                'last_updated': datetime.utcnow()
            }

            batch.set(doc_ref, doc_data)
            batch_count += 1

            if batch_count >= BATCH_SIZE:
                if commit_with_retry(batch):
                    uploaded += batch_count
                    print(f'  âœ“ ç¬¬ {current_line} è¡Œ | å·²ä¸Šä¼  {uploaded} æ¡ææ¬¾è®°å½•')

                    progress['contributions_last_line'] = current_line
                    progress['contributions_uploaded'] = uploaded
                    progress['last_updated'] = datetime.utcnow().isoformat()
                    save_progress(progress)

                    time.sleep(MIN_DELAY + random.uniform(0, 2))
                    batch = db.batch()
                    batch_count = 0
                else:
                    progress['contributions_last_line'] = current_line
                    progress['contributions_uploaded'] = uploaded
                    save_progress(progress)
                    return uploaded

    if batch_count > 0:
        if commit_with_retry(batch):
            uploaded += batch_count

    progress['contributions_last_line'] = current_line
    progress['contributions_uploaded'] = uploaded
    progress['contributions_completed'] = True
    progress['last_updated'] = datetime.utcnow().isoformat()
    save_progress(progress)

    print(f'âœ… æˆåŠŸä¸Šä¼  {uploaded} æ¡ææ¬¾è®°å½•')
    return uploaded

def main():
    """ä¸»å‡½æ•°"""
    print('\n' + '='*70)
    print('ğŸš€ FECæ•°æ®å¢é‡ä¸Šä¼ ï¼ˆå¸¦è‡ªåŠ¨é‡è¯•ï¼‰')
    print('='*70)

    # åŠ è½½è¿›åº¦
    progress = load_progress()
    if progress.get('last_updated'):
        print(f'\nğŸ“ å‘ç°ä¹‹å‰çš„è¿›åº¦ï¼ˆæœ€åæ›´æ–°: {progress["last_updated"]}ï¼‰')
        print(f'   Committees: {progress.get("committees_uploaded", 0)} æ¡å·²ä¸Šä¼ ')
        print(f'   Candidates: {progress.get("candidates_uploaded", 0)} æ¡å·²ä¸Šä¼ ')
        print(f'   Contributions: {progress.get("contributions_uploaded", 0)} æ¡å·²ä¸Šä¼ ')

    init_firestore()

    if not DATA_DIR.exists():
        print(f'\nâŒ æ•°æ®ç›®å½•ä¸å­˜åœ¨: {DATA_DIR}')
        sys.exit(1)

    year, year_suffix = 2024, '24'

    print(f'\nå¤„ç† {year} å¹´æ•°æ®')
    print('='*70)

    # ä¸Šä¼ å§”å‘˜ä¼šæ•°æ®
    if not progress.get('committees_completed'):
        committees_count = upload_committees_incremental(year, year_suffix, progress)
        print(f'\nâœ“ å§”å‘˜ä¼šæ•°æ®: å·²ä¸Šä¼  {committees_count} æ¡')
    else:
        print(f'\nâœ“ å§”å‘˜ä¼šæ•°æ®å·²å®Œæˆï¼ˆ{progress.get("committees_uploaded", 0)} æ¡ï¼‰')

    # ä¸Šä¼ å€™é€‰äººæ•°æ®
    if not progress.get('candidates_completed'):
        candidates_count = upload_candidates_incremental(year, year_suffix, progress)
        print(f'\nâœ“ å€™é€‰äººæ•°æ®: å·²ä¸Šä¼  {candidates_count} æ¡')
    else:
        print(f'\nâœ“ å€™é€‰äººæ•°æ®å·²å®Œæˆï¼ˆ{progress.get("candidates_uploaded", 0)} æ¡ï¼‰')

    # ä¸Šä¼ ææ¬¾æ•°æ®
    if not progress.get('contributions_completed'):
        contributions_count = upload_contributions_incremental(year, year_suffix, progress)
        print(f'\nâœ“ ææ¬¾æ•°æ®: å·²ä¸Šä¼  {contributions_count} æ¡')
    else:
        print(f'\nâœ“ ææ¬¾æ•°æ®å·²å®Œæˆï¼ˆ{progress.get("contributions_uploaded", 0)} æ¡ï¼‰')

    print('\n' + '='*70)
    print('âœ… ä¸Šä¼ å®Œæˆï¼')
    print('='*70)
    print('\nğŸ“Š æœ€ç»ˆç»Ÿè®¡:')
    print(f'  Committees: {progress.get("committees_uploaded", 0)} æ¡')
    print(f'  Candidates: {progress.get("candidates_uploaded", 0)} æ¡')
    print(f'  Contributions: {progress.get("contributions_uploaded", 0)} æ¡')
    print(f'\nğŸ’¡ è¿›åº¦æ–‡ä»¶: {PROGRESS_FILE}')
    print()

if __name__ == '__main__':
    try:
        main()
    except KeyboardInterrupt:
        print('\n\nâš ï¸  ç”¨æˆ·ä¸­æ–­ï¼Œè¿›åº¦å·²ä¿å­˜')
        print(f'   å¯ä»¥é‡æ–°è¿è¡Œæ­¤è„šæœ¬ç»§ç»­ä¸Šä¼ ')
        sys.exit(0)
    except Exception as e:
        print(f'\nâŒ é”™è¯¯: {e}')
        import traceback
        traceback.print_exc()
        sys.exit(1)
