#!/usr/bin/env python3
"""
FEC PAC Transfers Collection Script

ÁõÆÊ†á: ‰ªé fec_raw_committees Âíå fec_raw_transfers Êî∂ÈõÜ‰ºÅ‰∏öPACÊçêÊ¨æÊï∞ÊçÆ
ËæìÂá∫: fec_company_pac_transfers_summary/{ticker}

ÈáçË¶ÅÂéüÂàô:
1. Êï∞ÊçÆ‰øùÂ≠òÂà∞Áã¨Á´ãÁöÑ fec_company_pac_transfers_summary collection
2. ÊûÅÂÖ∂Ë∞®ÊÖéÔºå‰∏çÊ±°Êüì fec_company_name_variants Âíå fec_company_index
3. ‰ΩøÁî®Âè™ËØªÊ®°ÂºèÔºå‰∏ç‰øÆÊîπ‰ªª‰ΩïÁé∞Êúâcollection
4. Êñ∞ÂèëÁé∞ÁöÑname variants‰øùÂ≠òÂà∞ fec_pac_discovered_variants (‰∏¥Êó∂collection)

ËøêË°åÊñπÂºè:
    # ÊµãËØïÊ®°Âºè (5‰∏™ÂÖ¨Âè∏)
    python3 12-collect-pac-transfers.py --test

    # Áîü‰∫ßÊ®°Âºè (ÊâÄÊúâSP500)
    python3 12-collect-pac-transfers.py --production

    # ÊâÄÊúâÂèëÁé∞ÁöÑÂÖ¨Âè∏Ê®°Âºè
    python3 12-collect-pac-transfers.py --all-discovered
    python3 12-collect-pac-transfers.py --all-discovered --start 0 --end 100

Êï∞ÊçÆÊµÅ:
    fec_raw_committees (connected_org_name) ‚Üí ÊâæÂà∞ÂÖ¨Âè∏ÁöÑPAC
           ‚Üì
    fec_raw_transfers (committee_id) ‚Üí Ëé∑ÂèñPACÁöÑËΩ¨Ë¥¶ËÆ∞ÂΩï
           ‚Üì
    ÊåâpartyÂàÜÁªÑÁªüËÆ° ‚Üí fec_company_pac_transfers_summary
"""

import os
import sys
import json
import argparse
import time
from datetime import datetime
from typing import Dict, List, Optional, Tuple
from collections import defaultdict

# Ê∑ªÂä†È°πÁõÆÊ†πÁõÆÂΩïÂà∞PythonË∑ØÂæÑ
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, os.path.abspath(os.path.join(SCRIPT_DIR, '../../..')))

# ÂØºÂÖ•Firebase Admin
import firebase_admin
from firebase_admin import credentials, firestore
from google.api_core.exceptions import Unauthenticated

# ÂàùÂßãÂåñFirebase
if not firebase_admin._apps:
    cred = credentials.ApplicationDefault()
    firebase_admin.initialize_app(cred, {
        'projectId': 'stanseproject'
    })

db = firestore.client()


def refresh_firestore_client():
    """Âà∑Êñ∞FirestoreÂÆ¢Êà∑Á´ØÂíåtoken"""
    global db
    print('  üîÑ Âà∑Êñ∞FirestoreËøûÊé•Âíåtoken...')

    try:
        # ÈáçÊñ∞Ëé∑ÂèñFirestoreÂÆ¢Êà∑Á´Ø
        # Firebase Admin SDK‰ºöËá™Âä®Âà∑Êñ∞ADC token
        db = firestore.client()
        print('  ‚úÖ TokenÂ∑≤Âà∑Êñ∞')
        return True
    except Exception as e:
        print(f'  ‚ùåÂà∑Êñ∞Â§±Ë¥•: {e}')
        return False

# Êó•ÂøóÁõÆÂΩï
LOGS_DIR = os.path.join(SCRIPT_DIR, '../../../logs/fec-data')

# ============================================================================
# SP500 DATA - Import from unified data source
# ============================================================================
import sys
from pathlib import Path
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from data.sp500Companies import SP500_TICKERS

# ÊµãËØïÂÖ¨Âè∏ (Â∑≤Áü•ÊúâPACÁöÑÂÖ¨Âè∏)
TEST_TICKERS = ['MSFT', 'META', 'JPM', 'V', 'KO']

# TickerÂà∞ÂÖ¨Âè∏ÂêçÁß∞Êò†Â∞Ñ (Áî®‰∫éÂßîÂëò‰ºöÊêúÁ¥¢)
TICKER_TO_COMPANY_NAME = {
    'AAPL': 'APPLE INC',
    'MSFT': 'MICROSOFT CORPORATION',
    'GOOGL': 'ALPHABET INC',
    'AMZN': 'AMAZON.COM INC',
    'NVDA': 'NVIDIA CORPORATION',
    'META': 'META PLATFORMS INC',
    'TSLA': 'TESLA INC',
    'AVGO': 'BROADCOM INC',
    'ORCL': 'ORACLE CORPORATION',
    'CRM': 'SALESFORCE INC',
    'AMD': 'ADVANCED MICRO DEVICES INC',
    'INTC': 'INTEL CORPORATION',
    'IBM': 'INTERNATIONAL BUSINESS MACHINES CORPORATION',
    'CSCO': 'CISCO SYSTEMS INC',
    'ADBE': 'ADOBE INC',
    'JPM': 'JPMORGAN CHASE & CO',
    'V': 'VISA INC',
    'MA': 'MASTERCARD INCORPORATED',
    'BAC': 'BANK OF AMERICA CORPORATION',
    'WFC': 'WELLS FARGO & COMPANY',
    'GS': 'GOLDMAN SACHS GROUP INC',
    'MS': 'MORGAN STANLEY',
    'BLK': 'BLACKROCK INC',
    'C': 'CITIGROUP INC',
    'UNH': 'UNITEDHEALTH GROUP INCORPORATED',
    'JNJ': 'JOHNSON & JOHNSON',
    'LLY': 'ELI LILLY AND COMPANY',
    'PFE': 'PFIZER INC',
    'MRK': 'MERCK & CO INC',
    'ABBV': 'ABBVIE INC',
    'TMO': 'THERMO FISHER SCIENTIFIC INC',
    'ABT': 'ABBOTT LABORATORIES',
    'CVS': 'CVS HEALTH CORPORATION',
    'BMY': 'BRISTOL-MYERS SQUIBB COMPANY',
    'WMT': 'WALMART INC',
    'PG': 'PROCTER & GAMBLE COMPANY',
    'KO': 'COCA-COLA COMPANY',
    'PEP': 'PEPSICO INC',
    'COST': 'COSTCO WHOLESALE CORPORATION',
    'HD': 'HOME DEPOT INC',
    'MCD': 'MCDONALD\'S CORPORATION',
    'NKE': 'NIKE INC',
    'SBUX': 'STARBUCKS CORPORATION',
    'TGT': 'TARGET CORPORATION',
    'LOW': 'LOWE\'S COMPANIES INC',
    'DIS': 'WALT DISNEY COMPANY',
    'XOM': 'EXXON MOBIL CORPORATION',
    'CVX': 'CHEVRON CORPORATION',
    'COP': 'CONOCOPHILLIPS',
    'SLB': 'SCHLUMBERGER LIMITED',
    'EOG': 'EOG RESOURCES INC',
    'OXY': 'OCCIDENTAL PETROLEUM CORPORATION',
    'PSX': 'PHILLIPS 66',
    'VLO': 'VALERO ENERGY CORPORATION',
    'GE': 'GENERAL ELECTRIC COMPANY',
    'CAT': 'CATERPILLAR INC',
    'RTX': 'RAYTHEON TECHNOLOGIES CORPORATION',
    'HON': 'HONEYWELL INTERNATIONAL INC',
    'UPS': 'UNITED PARCEL SERVICE INC',
    'BA': 'BOEING COMPANY',
    'LMT': 'LOCKHEED MARTIN CORPORATION',
    'DE': 'DEERE & COMPANY',
    'NOC': 'NORTHROP GRUMMAN CORPORATION',
    'GD': 'GENERAL DYNAMICS CORPORATION',
    'NFLX': 'NETFLIX INC',
    'CMCSA': 'COMCAST CORPORATION',
    'T': 'AT&T INC',
    'VZ': 'VERIZON COMMUNICATIONS INC',
    'TMUS': 'T-MOBILE US INC',
    'NEE': 'NEXTERA ENERGY INC',
    'DUK': 'DUKE ENERGY CORPORATION',
    'SO': 'SOUTHERN COMPANY',
    'D': 'DOMINION ENERGY INC',
    'LIN': 'LINDE PLC',
    'APD': 'AIR PRODUCTS AND CHEMICALS INC',
    'SHW': 'SHERWIN-WILLIAMS COMPANY',
    'FCX': 'FREEPORT-MCMORAN INC',
    'NEM': 'NEWMONT CORPORATION',
    'PLD': 'PROLOGIS INC',
    'AMT': 'AMERICAN TOWER CORPORATION',
    'CCI': 'CROWN CASTLE INTERNATIONAL CORP',
    'EQIX': 'EQUINIX INC',
    'SPG': 'SIMON PROPERTY GROUP INC',
}


class PACTransfersCollector:
    """PAC Transfers Êï∞ÊçÆÊî∂ÈõÜÂô®"""

    def __init__(self, dry_run: bool = False, data_year: int = 2024):
        """
        ÂàùÂßãÂåñÊî∂ÈõÜÂô®

        Args:
            dry_run: Â¶ÇÊûú‰∏∫TrueÔºåÂè™ÊâìÂç∞Êó•Âøó‰∏çÂÜôÂÖ•Firebase
            data_year: Êï∞ÊçÆÂπ¥‰ªΩ (ÈªòËÆ§2024)
        """
        self.db = db
        self.dry_run = dry_run
        self.data_year = data_year
        self.discovered_variants = []  # Êñ∞ÂèëÁé∞ÁöÑname variants
        self.discovered_companies = {}  # Áî®‰∫é --all-discovered Ê®°Âºè

        print(f"‚úÖ Firebase initialized (project: stanseproject)")
        print(f"üìÖ Data year: {data_year}")
        if dry_run:
            print(f"‚ö†Ô∏è  DRY RUN MODE - No data will be written to Firebase")

    def load_discovered_companies(self):
        """Âä†ËΩΩdiscovered companies JSON"""
        json_file = os.path.join(LOGS_DIR, f'discovered_pac_companies_{self.data_year}.json')

        if not os.path.exists(json_file):
            print(f"‚ùå Discovery file not found: {json_file}")
            print(f"   Please run 13-discover-all-pac-companies.py --scan first")
            sys.exit(1)

        with open(json_file, 'r', encoding='utf-8') as f:
            report = json.load(f)

        self.discovered_companies = report['companies']

        print(f"üìÇ Loaded {len(self.discovered_companies)} discovered companies")
        print(f"   New companies: {report['new_companies']}")
        print(f"   Existing companies: {report['existing_companies']}")
        print()

    def normalize_company_name(self, name: str) -> str:
        """ËßÑËåÉÂåñÂÖ¨Âè∏ÂêçÁß∞"""
        if not name:
            return ""
        return name.upper().strip()

    def find_pac_committees(self, ticker: str) -> List[Dict]:
        """
        Âú® fec_raw_committees ‰∏≠Êü•ÊâæËØ•ÂÖ¨Âè∏ÁöÑPACÂßîÂëò‰ºö

        Á≠ñÁï•:
        1. ‰ΩøÁî® TICKER_TO_COMPANY_NAME Êò†Â∞ÑËé∑ÂèñÂÖ¨Âè∏Ê†áÂáÜÂêçÁß∞
        2. Âú® connected_org_name ‰∏≠ÊêúÁ¥¢
        3. Âè™ÈÄâÊã©Á±ªÂûã‰∏∫ 'Q' (PAC) ÁöÑÂßîÂëò‰ºö
        """
        if ticker not in TICKER_TO_COMPANY_NAME:
            return []

        company_name = TICKER_TO_COMPANY_NAME[ticker]
        normalized_name = self.normalize_company_name(company_name)

        # ÁîüÊàêÊêúÁ¥¢Âèò‰Ωì
        search_terms = [
            normalized_name,
            normalized_name.replace(' INC', ''),
            normalized_name.replace(' INCORPORATED', ''),
            normalized_name.replace(' CORPORATION', ''),
            normalized_name.replace(' CORP', ''),
            normalized_name.replace(' & CO', ''),
            normalized_name.replace(',', ''),
        ]

        # ÂéªÈáç
        search_terms = list(set([t for t in search_terms if t]))

        committee_ref = self.db.collection('fec_raw_committees')
        found_committees = []

        for term in search_terms:
            try:
                docs = list(committee_ref.where(
                    filter=firestore.FieldFilter('connected_org_name', '>=', term)
                ).where(
                    filter=firestore.FieldFilter('connected_org_name', '<=', term + '\uf8ff')
                ).limit(10).stream())

                for doc in docs:
                    data = doc.to_dict()

                    # Âè™ÈÄâÊã© PAC (Á±ªÂûã Q)
                    if data.get('committee_type') == 'Q':
                        cmte_id = data.get('committee_id', '')
                        if cmte_id and cmte_id not in [c['committee_id'] for c in found_committees]:
                            found_committees.append({
                                'committee_id': cmte_id,
                                'committee_name': data.get('committee_name', ''),
                                'connected_org_name': data.get('connected_org_name', ''),
                                'committee_type': data.get('committee_type', ''),
                                'year': data.get('year')
                            })

            except Exception as e:
                # ÈùôÈªòÂ§±Ë¥•ÔºåÁªßÁª≠‰∏ã‰∏Ä‰∏™ÊêúÁ¥¢term
                continue

        return found_committees

    def get_committee_candidate_id(self, committee_id: str) -> Optional[str]:
        """
        ‰ªé fec_raw_committees Ëé∑ÂèñÂßîÂëò‰ºöÂÖ≥ËÅîÁöÑÂÄôÈÄâ‰∫∫ID

        Args:
            committee_id: ÂßîÂëò‰ºöID (Â¶Ç C00326801)

        Returns:
            candidate_id Êàñ None
        """
        if not committee_id:
            return None

        try:
            # Êü•ËØ¢ËØ•committee_idÁöÑÊâÄÊúâËÆ∞ÂΩïÔºàÂèØËÉΩÊúâÂ§ö‰∏™Âπ¥‰ªΩÔºâ
            committee_ref = self.db.collection('fec_raw_committees')
            docs = list(committee_ref.where(
                filter=firestore.FieldFilter('committee_id', '==', committee_id)
            ).limit(1).stream())

            if docs:
                data = docs[0].to_dict()
                return data.get('candidate_id', '')

        except Exception:
            pass

        return None

    def get_candidate_party(self, candidate_id: str) -> Optional[str]:
        """
        ‰ªé fec_raw_candidates Ëé∑ÂèñÂÄôÈÄâ‰∫∫ÊîøÂÖö

        Returns:
            ÂéüÂßãparty code (DEM, REP, IND, LIB, GRE, UNKÁ≠â) Êàñ None
        """
        if not candidate_id:
            return None

        try:
            # Êü•ËØ¢ËØ•candidate_idÁöÑËÆ∞ÂΩï
            candidate_ref = self.db.collection('fec_raw_candidates')
            docs = list(candidate_ref.where(
                filter=firestore.FieldFilter('candidate_id', '==', candidate_id)
            ).limit(1).stream())

            if docs:
                data = docs[0].to_dict()
                party = data.get('party_affiliation', '').strip().upper()

                # ËøîÂõûÂéüÂßãparty code,‰øùÊåÅ‰∏éfec_company_party_summary‰∏ÄËá¥
                # Â∏∏ËßÅÁöÑcodes: DEM, REP, IND, LIB, GRE, UNK, NNE, PNPÁ≠â
                return party if party else 'UNK'

        except Exception:
            pass

        return None

    def get_pac_transfers_by_party(self, committee_id: str) -> Dict:
        """
        Êü•ËØ¢ËØ•PACÂú® fec_raw_transfers ‰∏≠ÁöÑÊåâÊîøÂÖöÂàÜÁªÑÁöÑÊçêÊ¨æ

        Á≠ñÁï•:
        1. Êü•ËØ¢ÊâÄÊúâ committee_id == committee_id ÁöÑtransfers
        2. ÂØπ‰∫éÊØè‰∏™transferÔºåÊü•ËØ¢recipientÁöÑÊîøÂÖö
        3. ÊåâÊîøÂÖöÂàÜÁªÑÁªüËÆ° (‰ΩøÁî®‰∏éfec_company_party_summaryÁõ∏ÂêåÁöÑÁªìÊûÑ)

        Returns:
            {
                'party_totals': {
                    'DEM': {'total_amount': float, 'contribution_count': int},
                    'REP': {'total_amount': float, 'contribution_count': int},
                    ...ÂÖ∂‰ªñparty codes
                },
                'total_usd': float,
                'total_count': int
            }
        """
        transfer_ref = self.db.collection('fec_raw_transfers')

        # ‰ΩøÁî®defaultdictÂä®ÊÄÅÊî∂ÈõÜÊâÄÊúâparty codes
        from collections import defaultdict
        party_totals = defaultdict(lambda: {'total_amount': 0.0, 'contribution_count': 0})

        try:
            # Êü•ËØ¢ËØ•ÂßîÂëò‰ºöÁöÑÊâÄÊúâËΩ¨Ë¥¶ËÆ∞ÂΩï
            # Ê≥®ÊÑè: ËøôÈáåÂèØËÉΩËøîÂõûÂæàÂ§örecordsÔºåÈúÄË¶ÅÂàÜÊâπÊü•ËØ¢
            docs = list(transfer_ref.where(
                filter=firestore.FieldFilter('committee_id', '==', committee_id)
            ).limit(5000).stream())  # ÈôêÂà∂5000Êù°ÔºåÈÅøÂÖçÊü•ËØ¢ËøáÂ§ß

            for doc in docs:
                data = doc.to_dict()
                amount = data.get('transaction_amount', 0)

                if amount and amount > 0:
                    # Ëé∑ÂèñÊî∂Ê¨æÊñπcommittee_id
                    receiver_committee_id = data.get('receiver_committee_id', '')

                    # ‰ªécommitteeËé∑Âèñcandidate_id
                    candidate_id = self.get_committee_candidate_id(receiver_committee_id)

                    # Êü•ËØ¢ÂÄôÈÄâ‰∫∫ÊîøÂÖö
                    party = self.get_candidate_party(candidate_id) if candidate_id else None

                    if party is None:
                        # Â¶ÇÊûúÊâæ‰∏çÂà∞candidateÔºåÂΩí‰∏∫UNK (Unknown)
                        party = 'UNK'

                    # Âä®ÊÄÅÊ∑ªÂä†Âà∞party_totals
                    party_totals[party]['total_amount'] += amount
                    party_totals[party]['contribution_count'] += 1

        except Unauthenticated as e:
            print(f"      ‚ö†Ô∏è  TokenËøáÊúüÔºåÊ≠£Âú®Âà∑Êñ∞Âπ∂ÈáçËØï...")
            if refresh_firestore_client():
                # ÈáçÊñ∞Êü•ËØ¢
                try:
                    transfer_ref = self.db.collection('fec_raw_transfers')
                    docs = list(transfer_ref.where(
                        filter=firestore.FieldFilter('committee_id', '==', committee_id)
                    ).limit(5000).stream())

                    for doc in docs:
                        data = doc.to_dict()
                        amount = data.get('transaction_amount', 0)

                        if amount and amount > 0:
                            receiver_committee_id = data.get('receiver_committee_id', '')
                            candidate_id = self.get_committee_candidate_id(receiver_committee_id)
                            party = self.get_candidate_party(candidate_id) if candidate_id else None

                            if party is None:
                                party = 'UNK'

                            party_totals[party]['total_amount'] += amount
                            party_totals[party]['contribution_count'] += 1

                except Exception as retry_e:
                    print(f"      ‚ùå ÈáçËØïÂ§±Ë¥•: {str(retry_e)}")
            else:
                print(f"      ‚ùå TokenÂà∑Êñ∞Â§±Ë¥•")
        except Exception as e:
            print(f"      ‚ö†Ô∏è  Error querying transfers: {str(e)}")

        # ËÆ°ÁÆóÊÄªËÆ°
        total_usd = sum(p['total_amount'] for p in party_totals.values())
        total_count = sum(p['contribution_count'] for p in party_totals.values())

        # ËΩ¨Êç¢defaultdict‰∏∫ÊôÆÈÄödict
        result = {
            'party_totals': dict(party_totals),
            'total_usd': total_usd,
            'total_count': total_count
        }

        return result

    def collect_pac_transfers_for_ticker(self, ticker: str) -> Optional[Dict]:
        """
        Êî∂ÈõÜÂçï‰∏™tickerÁöÑPAC transferÊï∞ÊçÆ

        Returns:
            {
                'company_name': str,
                'normalized_name': str,
                'data_year': int,
                'party_totals': Dict[str, Dict],
                'total_contributed': float,
                'committees': List[Dict],  # PACÁâπÊúâÂ≠óÊÆµ
                'data_source': 'pac_transfers',  # PACÁâπÊúâÂ≠óÊÆµ
                'created_at': timestamp,
                'last_updated': timestamp
            }
        """
        # Step 1: Êü•ÊâæPACÂßîÂëò‰ºö
        committees = self.find_pac_committees(ticker)

        if not committees:
            return None

        print(f"    ‚úÖ Found {len(committees)} PAC committee(s)")

        # Step 2: Êî∂ÈõÜÊØè‰∏™ÂßîÂëò‰ºöÁöÑtransfers (‰ΩøÁî®defaultdictÂä®ÊÄÅÊî∂ÈõÜÊâÄÊúâparties)
        from collections import defaultdict
        all_party_totals = defaultdict(lambda: {'total_amount': 0.0, 'contribution_count': 0})

        for committee in committees:
            cmte_id = committee['committee_id']
            print(f"      Querying transfers for {cmte_id}...", end='')

            transfers = self.get_pac_transfers_by_party(cmte_id)

            # ÂêàÂπ∂Âà∞ÊÄªËÆ° - Âä®ÊÄÅÂêàÂπ∂ÊâÄÊúâparties
            for party, values in transfers['party_totals'].items():
                all_party_totals[party]['total_amount'] += values['total_amount']
                all_party_totals[party]['contribution_count'] += values['contribution_count']

            committee['transfer_totals'] = transfers['party_totals']
            committee['transfer_total_usd'] = transfers['total_usd']
            committee['transfer_count'] = transfers['total_count']

            print(f" ${transfers['total_usd']:,.0f} ({transfers['total_count']} txns)")

        # Step 3: ÊûÑÂª∫ÁªìÊûú (‰∏éfec_company_party_summaryÁªìÊûÑÂÆåÂÖ®‰∏ÄËá¥)
        company_name = TICKER_TO_COMPANY_NAME.get(ticker, ticker)
        normalized_name = self.normalize_company_name(company_name).lower().strip()

        # ÁßªÈô§Â∏∏ËßÅÁöÑÁ¨¶Âè∑ÂíåÂêéÁºÄ (‰∏éfec_company_party_summary‰øùÊåÅ‰∏ÄËá¥)
        # ÁßªÈô§ "&", ",", "." Á≠âÁ¨¶Âè∑
        normalized_name = normalized_name.replace('&', '').replace(',', '').replace('.', '')

        # ÁßªÈô§Â∏∏ËßÅÂêéÁºÄ
        for suffix in [' inc', ' incorporated', ' corporation', ' corp', ' company', ' co', ' ltd']:
            if normalized_name.endswith(suffix):
                normalized_name = normalized_name[:-len(suffix)].strip()

        # Ê∏ÖÁêÜÂ§ö‰ΩôÁ©∫Ê†º
        normalized_name = ' '.join(normalized_name.split())

        total_contributed = sum(p['total_amount'] for p in all_party_totals.values())

        result = {
            'company_name': company_name,
            'normalized_name': normalized_name,
            'data_year': self.data_year,
            'party_totals': dict(all_party_totals),  # ËΩ¨Êç¢‰∏∫ÊôÆÈÄödict
            'total_contributed': total_contributed,

            # PACÁâπÊúâÂ≠óÊÆµ
            'committees': committees,
            'data_source': 'pac_transfers',

            'created_at': firestore.SERVER_TIMESTAMP,
            'last_updated': firestore.SERVER_TIMESTAMP
        }

        return result

    def sanitize_doc_id(self, doc_id: str) -> str:
        """
        Ê∏ÖÁêÜdocument ID‰∏≠ÁöÑÈùûÊ≥ïÂ≠óÁ¨¶

        Firestore document IDs‰∏çÂÖÅËÆ∏ÂåÖÂê´: /
        """
        # ÊõøÊç¢ / ‰∏∫ -
        doc_id = doc_id.replace('/', '-')

        # ÁßªÈô§ÂÖ∂‰ªñÂèØËÉΩÁöÑÈùûÊ≥ïÂ≠óÁ¨¶
        doc_id = doc_id.replace('\\', '-')

        return doc_id

    def save_to_firebase(self, data: Dict):
        """
        ‰øùÂ≠òÂà∞ fec_company_pac_transfers_summary collection

        Document IDÊ†ºÂºè: {normalized_company_name}_{year}
        ‰æãÂ¶Ç: "microsoft_2024", "jpmorgan chase_2024"

        Ê≥®ÊÑè: ‰∏ç‰øÆÊîπ fec_company_name_variants Êàñ fec_company_index
        """
        # ÊûÑÂª∫document ID: {normalized_name}_{year}
        raw_doc_id = f"{data['normalized_name']}_{data['data_year']}"
        doc_id = self.sanitize_doc_id(raw_doc_id)

        if self.dry_run:
            print(f"    [DRY RUN] Would save to fec_company_pac_transfers_summary/{doc_id}")
            return

        try:
            doc_ref = self.db.collection('fec_company_pac_transfers_summary').document(doc_id)
            doc_ref.set(data, merge=True)
            print(f"    ‚úÖ Saved to fec_company_pac_transfers_summary/{doc_id}")
        except Unauthenticated as e:
            print(f"    ‚ö†Ô∏è  TokenËøáÊúüÔºåÊ≠£Âú®Âà∑Êñ∞Âπ∂ÈáçËØï...")
            if refresh_firestore_client():
                # TokenÂà∑Êñ∞ÂêéÔºåÁî®Êñ∞ÁöÑdbÂÆ¢Êà∑Á´ØÈáçÊñ∞Â∞ùËØï
                try:
                    doc_ref = self.db.collection('fec_company_pac_transfers_summary').document(doc_id)
                    doc_ref.set(data, merge=True)
                    print(f"    ‚úÖ Saved to fec_company_pac_transfers_summary/{doc_id}")
                except Exception as retry_e:
                    print(f"    ‚ùå ÈáçËØïÂ§±Ë¥•: {str(retry_e)}")
            else:
                print(f"    ‚ùå TokenÂà∑Êñ∞Â§±Ë¥•")
        except Exception as e:
            print(f"    ‚ùå Error saving to Firebase: {str(e)}")

    def collect_pac_transfers_for_company(self, company_info: Dict) -> Optional[Dict]:
        """
        Êî∂ÈõÜÂçï‰∏™discovered companyÁöÑPAC transferÊï∞ÊçÆ

        Args:
            company_info: discovered companies JSON‰∏≠ÁöÑÂÖ¨Âè∏‰ø°ÊÅØ

        Returns:
            ‰∏écollect_pac_transfers_for_tickerÁõ∏ÂêåÁöÑÊ†ºÂºè
        """
        normalized_name = company_info['normalized_name']
        original_name = company_info['original_name']
        committees = company_info['committees']

        if not committees:
            return None

        print(f"    ‚úÖ Found {len(committees)} PAC committee(s)")

        # Êî∂ÈõÜÊØè‰∏™ÂßîÂëò‰ºöÁöÑtransfers
        all_party_totals = defaultdict(lambda: {'total_amount': 0.0, 'contribution_count': 0})
        committees_with_data = []

        for committee in committees:
            cmte_id = committee['committee_id']
            print(f"      Querying {cmte_id}...", end='')

            transfers = self.get_pac_transfers_by_party(cmte_id)

            # ÂêàÂπ∂Âà∞ÊÄªËÆ°
            for party, values in transfers['party_totals'].items():
                all_party_totals[party]['total_amount'] += values['total_amount']
                all_party_totals[party]['contribution_count'] += values['contribution_count']

            # Ê∑ªÂä†transfer‰ø°ÊÅØÂà∞committee
            committee_data = {
                'committee_id': cmte_id,
                'committee_name': committee.get('committee_name', ''),
                'connected_org_name': committee.get('connected_org_name', ''),
                'transfer_totals': transfers['party_totals'],
                'transfer_total_usd': transfers['total_usd'],
                'transfer_count': transfers['total_count']
            }
            committees_with_data.append(committee_data)

            print(f" ${transfers['total_usd']:,.0f} ({transfers['total_count']} txns)")

        total_contributed = sum(p['total_amount'] for p in all_party_totals.values())

        result = {
            'company_name': original_name,
            'normalized_name': normalized_name,
            'data_year': self.data_year,
            'party_totals': dict(all_party_totals),
            'total_contributed': total_contributed,

            # PACÁâπÊúâÂ≠óÊÆµ
            'committees': committees_with_data,
            'data_source': 'pac_transfers',

            'created_at': firestore.SERVER_TIMESTAMP,
            'last_updated': firestore.SERVER_TIMESTAMP
        }

        return result

    def run(self, tickers: List[str]):
        """ËøêË°åÂÆåÊï¥ÁöÑÊï∞ÊçÆÊî∂ÈõÜÊµÅÁ®ã"""
        start_time = time.time()

        print(f"\n{'='*70}")
        print(f"üîÑ FEC PAC Transfers Collection")
        print(f"{'='*70}")
        print(f"üì¶ Total companies to process: {len(tickers)}")
        print(f"üïí Started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"{'='*70}\n")

        success_count = 0
        no_pac_count = 0
        no_transfers_count = 0
        error_count = 0
        failed_tickers = []

        for i, ticker in enumerate(tickers, 1):
            try:
                print(f"[{i}/{len(tickers)}] {ticker}")

                pac_data = self.collect_pac_transfers_for_ticker(ticker)

                if pac_data:
                    if pac_data['total_contributed'] > 0:
                        self.save_to_firebase(pac_data)
                        success_count += 1
                        print(f"    üí∞ Total: ${pac_data['total_contributed']:,.0f}")
                    else:
                        print(f"    ‚ö†Ô∏è  PAC found but no transfers")
                        no_transfers_count += 1
                else:
                    print(f"    ‚ö†Ô∏è  No PAC found")
                    no_pac_count += 1

            except Exception as e:
                print(f"    ‚ùå Error: {str(e)}")
                import traceback
                traceback.print_exc()
                error_count += 1
                failed_tickers.append(ticker)

        execution_time = time.time() - start_time

        # ÊâìÂç∞Ê±áÊÄª
        print(f"\n{'='*70}")
        print(f"‚úÖ PAC Transfers Collection Complete")
        print(f"{'='*70}")
        print(f"‚úÖ Success (with transfers): {success_count}/{len(tickers)}")
        print(f"‚ö†Ô∏è  PAC found but no transfers: {no_transfers_count}/{len(tickers)}")
        print(f"‚ö†Ô∏è  No PAC found: {no_pac_count}/{len(tickers)}")
        print(f"‚ùå Errors: {error_count}/{len(tickers)}")
        print(f"üïí Finished at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"‚è±Ô∏è  Execution time: {execution_time:.1f} seconds")
        print(f"{'='*70}\n")

        if failed_tickers:
            print(f"Failed tickers: {', '.join(failed_tickers)}")

    def run_all_discovered(self, start_index: int = 0, end_index: Optional[int] = None):
        """
        ËøêË°åÊâÄÊúâdiscovered companiesÁöÑÊî∂ÈõÜÊµÅÁ®ã

        Args:
            start_index: Ëµ∑ÂßãÁ¥¢Âºï (0-based)
            end_index: ÁªìÊùüÁ¥¢Âºï (‰∏çÂåÖÂê´), NoneË°®Á§∫Â§ÑÁêÜÂà∞ÊúÄÂêé
        """
        start_time = time.time()

        # ÂáÜÂ§áÂÖ¨Âè∏ÂàóË°®
        all_companies = list(self.discovered_companies.items())

        if end_index is None:
            end_index = len(all_companies)

        companies_to_process = all_companies[start_index:end_index]

        print(f"\n{'='*70}")
        print(f"üîÑ All Discovered Companies PAC Transfers Collection")
        print(f"{'='*70}")
        print(f"üì¶ Total companies in discovery: {len(all_companies)}")
        print(f"üì¶ Processing range: {start_index} to {end_index}")
        print(f"üì¶ Companies to process: {len(companies_to_process)}")
        print(f"üïí Started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"{'='*70}\n")

        success_count = 0
        no_transfers_count = 0
        error_count = 0
        failed_companies = []

        for i, (normalized_name, company_info) in enumerate(companies_to_process, 1):
            try:
                absolute_index = start_index + i
                print(f"[{absolute_index}/{len(all_companies)}] {company_info['original_name']}")

                pac_data = self.collect_pac_transfers_for_company(company_info)

                if pac_data:
                    if pac_data['total_contributed'] > 0:
                        self.save_to_firebase(pac_data)
                        success_count += 1
                        print(f"    üí∞ Total: ${pac_data['total_contributed']:,.0f}")
                    else:
                        print(f"    ‚ö†Ô∏è  PAC found but no transfers")
                        no_transfers_count += 1
                else:
                    print(f"    ‚ö†Ô∏è  No committees found")
                    no_transfers_count += 1

            except Exception as e:
                print(f"    ‚ùå Error: {str(e)}")
                import traceback
                traceback.print_exc()
                error_count += 1
                failed_companies.append(company_info['original_name'])

        execution_time = time.time() - start_time

        # ÊâìÂç∞Ê±áÊÄª
        print(f"\n{'='*70}")
        print(f"‚úÖ PAC Transfers Collection Complete")
        print(f"{'='*70}")
        print(f"‚úÖ Success (with transfers): {success_count}/{len(companies_to_process)}")
        print(f"‚ö†Ô∏è  No transfers: {no_transfers_count}/{len(companies_to_process)}")
        print(f"‚ùå Errors: {error_count}/{len(companies_to_process)}")
        print(f"üïí Finished at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"‚è±Ô∏è  Execution time: {execution_time:.1f} seconds")
        print(f"{'='*70}\n")

        if failed_companies:
            print(f"Failed companies ({len(failed_companies)}):")
            for company in failed_companies[:20]:  # Âè™ÊòæÁ§∫Ââç20‰∏™
                print(f"  ‚Ä¢ {company}")
            if len(failed_companies) > 20:
                print(f"  ... and {len(failed_companies) - 20} more")


def main():
    parser = argparse.ArgumentParser(description='Collect FEC PAC Transfers data')
    parser.add_argument('--test', action='store_true', help='Test mode (5 companies)')
    parser.add_argument('--production', action='store_true', help='Production mode (all SP500)')
    parser.add_argument('--all-discovered', action='store_true', help='Process all discovered companies')
    parser.add_argument('--start', type=int, help='Start index (for --all-discovered)')
    parser.add_argument('--end', type=int, help='End index (for --all-discovered)')
    parser.add_argument('--dry-run', action='store_true', help='Dry run mode (no writes)')

    args = parser.parse_args()

    collector = PACTransfersCollector(dry_run=args.dry_run)

    if args.test:
        tickers = TEST_TICKERS
        print(f"üß™ TEST MODE: Processing {len(tickers)} companies")
        collector.run(tickers)
    elif args.production:
        tickers = SP500_TICKERS
        print(f"üöÄ PRODUCTION MODE: Processing {len(tickers)} companies")
        collector.run(tickers)
    elif args.all_discovered:
        # Âä†ËΩΩdiscovered companies
        collector.load_discovered_companies()

        start = args.start or 0
        end = args.end

        if start or end:
            print(f"üöÄ ALL DISCOVERED MODE: Processing companies {start} to {end or 'end'}")
        else:
            print(f"üöÄ ALL DISCOVERED MODE: Processing all {len(collector.discovered_companies)} companies")

        collector.run_all_discovered(start_index=start, end_index=end)
    else:
        print("‚ùå Please specify --test, --production, or --all-discovered")
        print("   Examples:")
        print("     python3 12-collect-pac-transfers.py --test")
        print("     python3 12-collect-pac-transfers.py --production")
        print("     python3 12-collect-pac-transfers.py --all-discovered")
        print("     python3 12-collect-pac-transfers.py --all-discovered --start 0 --end 100")
        sys.exit(1)


if __name__ == "__main__":
    main()
