#!/usr/bin/env python3
"""
åˆå¹¶ fec_company_party_summary å’Œ fec_company_pac_transfers_summary
åˆ›å»ºç»Ÿä¸€çš„ fec_company_consolidated collection

è¿™ä¸ªè„šæœ¬ä¼š:
1. ä»ä¸¤ä¸ªæºcollectionè¯»å–æ•°æ®
2. æŒ‰ (normalized_name, data_year) åˆå¹¶æ•°æ®
3. ä¿æŒä¸æ—§schemaå®Œå…¨å…¼å®¹çš„æ•°æ®æ ¼å¼
4. æ·»åŠ å…ƒæ•°æ®å­—æ®µæ ‡è¯†æ•°æ®æ¥æº
5. å†™å…¥åˆ° fec_company_consolidated collection

Document ID format: {normalized_name}_{year}
Example: jpmorgan chase_2024
"""

import sys
import os
from collections import defaultdict
from typing import Dict, List, Optional
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, os.path.abspath(os.path.join(SCRIPT_DIR, '../../..')))

import firebase_admin
from firebase_admin import credentials, firestore
from google.api_core.exceptions import Unauthenticated

# åˆå§‹åŒ–Firebase
if not firebase_admin._apps:
    cred = credentials.ApplicationDefault()
    firebase_admin.initialize_app(cred, {
        'projectId': 'stanseproject'
    })

db = firestore.client()


def refresh_firestore_client():
    """åˆ·æ–°Firestoreå®¢æˆ·ç«¯å’Œtoken"""
    global db
    print('  ğŸ”„ åˆ·æ–°Firestoreè¿æ¥å’Œtoken...')

    try:
        db = firestore.client()
        print('  âœ… Tokenå·²åˆ·æ–°')
        return True
    except Exception as e:
        print(f'  âŒåˆ·æ–°å¤±è´¥: {e}')
        return False


class ConsolidatedBuilder:
    def __init__(self, data_year: int = 2024, dry_run: bool = False):
        self.db = db
        self.data_year = data_year
        self.dry_run = dry_run

        print(f'=' * 70)
        print(f'ğŸ“Š FEC Consolidated Summary Builder')
        print(f'=' * 70)
        print(f'Data year: {data_year}')
        print(f'Dry run: {dry_run}')
        print()

    def merge_party_totals(self,
                          party_totals1: Dict,
                          party_totals2: Dict) -> Dict:
        """
        åˆå¹¶ä¸¤ä¸ªparty_totalså­—å…¸

        party_totalsæ ¼å¼:
        {
            "DEM": {
                "total_amount": 12345,
                "contribution_count": 10
            },
            "REP": { ... }
        }
        """
        merged = defaultdict(lambda: {
            'total_amount': 0,
            'contribution_count': 0
        })

        # æ·»åŠ ç¬¬ä¸€ä¸ªæ¥æºçš„æ•°æ®
        for party, data in (party_totals1 or {}).items():
            merged[party]['total_amount'] += data.get('total_amount', 0)
            merged[party]['contribution_count'] += data.get('contribution_count', 0)

        # æ·»åŠ ç¬¬äºŒä¸ªæ¥æºçš„æ•°æ®
        for party, data in (party_totals2 or {}).items():
            merged[party]['total_amount'] += data.get('total_amount', 0)
            merged[party]['contribution_count'] += data.get('contribution_count', 0)

        # è½¬æ¢ä¸ºæ™®é€šdict
        return dict(merged)

    def get_company_linkage_data(self, normalized_name: str) -> Optional[Dict]:
        """
        ä» fec_company_party_summary è·å–å…¬å¸çš„linkageæ•°æ®
        """
        try:
            doc_id = f"{normalized_name}_{self.data_year}"
            doc_ref = self.db.collection('fec_company_party_summary').document(doc_id)
            doc_snap = doc_ref.get()

            if doc_snap.exists:
                return doc_snap.to_dict()
            return None

        except Exception as e:
            print(f'  âš ï¸  Error fetching linkage data for {normalized_name}: {e}')
            return None

    def get_company_pac_data(self, normalized_name: str) -> Optional[Dict]:
        """
        ä» fec_company_pac_transfers_summary è·å–å…¬å¸çš„PACæ•°æ®
        Note: PAC collection sanitizes '/' to '-' in document IDs
        """
        try:
            # Sanitize document ID (replace / with -)
            sanitized_name = normalized_name.replace('/', '-')
            doc_id = f"{sanitized_name}_{self.data_year}"
            doc_ref = self.db.collection('fec_company_pac_transfers_summary').document(doc_id)
            doc_snap = doc_ref.get()

            if doc_snap.exists:
                return doc_snap.to_dict()
            return None

        except Exception as e:
            print(f'  âš ï¸  Error fetching PAC data for {normalized_name}: {e}')
            return None

    def build_consolidated_record(self,
                                  normalized_name: str,
                                  linkage_data: Optional[Dict],
                                  pac_data: Optional[Dict]) -> Dict:
        """
        æ„å»ºconsolidatedè®°å½•

        è¿”å›æ ¼å¼å®Œå…¨å…¼å®¹ fec_company_party_summary çš„schema:
        {
            "normalized_name": str,
            "company_name": str,
            "data_year": int,
            "total_contributed": int,  # cents
            "party_totals": {
                "DEM": {"total_amount": int, "contribution_count": int},
                "REP": {...}
            },
            "created_at": timestamp,
            "last_updated": timestamp,

            # é¢å¤–çš„å…ƒæ•°æ®å­—æ®µ
            "data_sources": ["linkage", "pac_transfers"],  # æ ‡è¯†æ•°æ®æ¥æº
            "linkage_total": int,        # linkageè´¡çŒ®çš„é‡‘é¢
            "pac_transfer_total": int,   # PAC transferè´¡çŒ®çš„é‡‘é¢
            "has_linkage_data": bool,
            "has_pac_data": bool,
            "pac_committees": [],        # PACå§”å‘˜ä¼šåˆ—è¡¨(æ¥è‡ªpac_transfers)
        }
        """
        # è·å–display name (ä¼˜å…ˆä½¿ç”¨linkageçš„company_name)
        company_name = None
        if linkage_data:
            company_name = linkage_data.get('company_name')
        if not company_name and pac_data:
            company_name = pac_data.get('company_name')
        if not company_name:
            company_name = normalized_name.upper()

        # åˆå¹¶party_totals
        linkage_party_totals = linkage_data.get('party_totals', {}) if linkage_data else {}
        pac_party_totals = pac_data.get('party_totals', {}) if pac_data else {}
        merged_party_totals = self.merge_party_totals(linkage_party_totals, pac_party_totals)

        # è®¡ç®—æ€»é‡‘é¢
        linkage_total = linkage_data.get('total_contributed', 0) if linkage_data else 0
        pac_total = pac_data.get('total_contributed', 0) if pac_data else 0
        total_contributed = linkage_total + pac_total

        # æ„å»ºæ•°æ®æ¥æºåˆ—è¡¨
        data_sources = []
        if linkage_data:
            data_sources.append('linkage')
        if pac_data:
            data_sources.append('pac_transfers')

        # è·å–PACå§”å‘˜ä¼šä¿¡æ¯
        pac_committees = []
        if pac_data and 'committees' in pac_data:
            pac_committees = pac_data['committees']

        # æ„å»ºconsolidatedè®°å½•
        now = firestore.SERVER_TIMESTAMP

        consolidated = {
            # åŸºæœ¬å­—æ®µ (å…¼å®¹æ—§schema)
            'normalized_name': normalized_name,
            'company_name': company_name,
            'data_year': self.data_year,
            'total_contributed': total_contributed,
            'party_totals': merged_party_totals,
            'created_at': linkage_data.get('created_at') if linkage_data else now,
            'last_updated': now,

            # å…ƒæ•°æ®å­—æ®µ (æ–°å¢)
            'data_sources': data_sources,
            'linkage_total': linkage_total,
            'pac_transfer_total': pac_total,
            'has_linkage_data': bool(linkage_data),
            'has_pac_data': bool(pac_data),
            'pac_committees': pac_committees,
        }

        return consolidated

    def save_consolidated_record(self, normalized_name: str, data: Dict):
        """ä¿å­˜consolidatedè®°å½•åˆ°Firestore
        Note: Sanitize '/' to '-' in document IDs for Firestore compatibility
        """
        # Sanitize document ID (replace / with -)
        sanitized_name = normalized_name.replace('/', '-')
        doc_id = f"{sanitized_name}_{self.data_year}"

        if self.dry_run:
            print(f'    [DRY RUN] Would save to fec_company_consolidated/{doc_id}')
            print(f'    Total: ${data["total_contributed"] / 100:.2f}')
            print(f'    Sources: {data["data_sources"]}')
            return

        try:
            doc_ref = self.db.collection('fec_company_consolidated').document(doc_id)
            doc_ref.set(data, merge=False)  # å®Œå…¨è¦†ç›–ï¼Œä¸merge
            print(f'    âœ… Saved to fec_company_consolidated/{doc_id}')

        except Unauthenticated as e:
            print(f'    âš ï¸  Tokenè¿‡æœŸï¼Œæ­£åœ¨åˆ·æ–°å¹¶é‡è¯•...')
            if refresh_firestore_client():
                try:
                    doc_ref = self.db.collection('fec_company_consolidated').document(doc_id)
                    doc_ref.set(data, merge=False)
                    print(f'    âœ… Saved to fec_company_consolidated/{doc_id}')
                except Exception as retry_e:
                    print(f'    âŒ é‡è¯•å¤±è´¥: {str(retry_e)}')
            else:
                print(f'    âŒ Tokenåˆ·æ–°å¤±è´¥')

        except Exception as e:
            print(f'    âŒ Error saving: {str(e)}')

    def collect_all_companies(self) -> List[str]:
        """
        æ”¶é›†æ‰€æœ‰éœ€è¦å¤„ç†çš„å…¬å¸åç§°
        ä»ä¸¤ä¸ªæºcollectionä¸­è·å–æ‰€æœ‰normalized_name
        """
        print('ğŸ“‚ Collecting all companies from both sources...')

        all_companies = set()

        # 1. ä» fec_company_party_summary æ”¶é›†
        print('  Scanning fec_company_party_summary...')
        try:
            query = self.db.collection('fec_company_party_summary').where(
                filter=firestore.FieldFilter('data_year', '==', self.data_year)
            )
            docs = list(query.stream())

            for doc in docs:
                data = doc.to_dict()
                normalized_name = data.get('normalized_name')
                if normalized_name:
                    all_companies.add(normalized_name)

            print(f'    Found {len(docs)} records')

        except Exception as e:
            print(f'    âš ï¸  Error: {e}')

        # 2. ä» fec_company_pac_transfers_summary æ”¶é›†
        print('  Scanning fec_company_pac_transfers_summary...')
        try:
            query = self.db.collection('fec_company_pac_transfers_summary').where(
                filter=firestore.FieldFilter('data_year', '==', self.data_year)
            )
            docs = list(query.stream())

            for doc in docs:
                data = doc.to_dict()
                normalized_name = data.get('normalized_name')
                if normalized_name:
                    all_companies.add(normalized_name)

            print(f'    Found {len(docs)} records')

        except Exception as e:
            print(f'    âš ï¸  Error: {e}')

        companies_list = sorted(all_companies)
        print(f'\nğŸ“Š Total unique companies to process: {len(companies_list)}\n')

        return companies_list

    def build_all_consolidated(self):
        """æ„å»ºæ‰€æœ‰å…¬å¸çš„consolidatedè®°å½•"""
        print('=' * 70)
        print(f'ğŸš€ Building Consolidated Summary for {self.data_year}')
        print('=' * 70)
        print()

        # æ”¶é›†æ‰€æœ‰éœ€è¦å¤„ç†çš„å…¬å¸
        all_companies = self.collect_all_companies()

        if not all_companies:
            print('âš ï¸  No companies found to process')
            return

        print(f'Processing {len(all_companies)} companies...\n')

        success_count = 0
        error_count = 0

        for i, normalized_name in enumerate(all_companies, 1):
            print(f'[{i}/{len(all_companies)}] {normalized_name}')

            try:
                # 1. è·å–ä¸¤ä¸ªæ¥æºçš„æ•°æ®
                linkage_data = self.get_company_linkage_data(normalized_name)
                pac_data = self.get_company_pac_data(normalized_name)

                # 2. æ„å»ºconsolidatedè®°å½•
                consolidated = self.build_consolidated_record(
                    normalized_name,
                    linkage_data,
                    pac_data
                )

                # 3. ä¿å­˜
                self.save_consolidated_record(normalized_name, consolidated)

                # æ‰“å°summary
                sources = consolidated['data_sources']
                total_usd = consolidated['total_contributed'] / 100.0
                print(f'    ğŸ’° Total: ${total_usd:,.2f} (sources: {", ".join(sources)})')

                success_count += 1

            except Exception as e:
                print(f'    âŒ Error: {str(e)}')
                error_count += 1

        # æœ€ç»ˆæŠ¥å‘Š
        print()
        print('=' * 70)
        print('ğŸ“‹ Summary')
        print('=' * 70)
        print(f'âœ… Success: {success_count}/{len(all_companies)}')
        print(f'âŒ Errors: {error_count}/{len(all_companies)}')
        print()


def main():
    import argparse

    parser = argparse.ArgumentParser(description='æ„å»ºFEC consolidated summary')
    parser.add_argument('--year', type=int, default=2024, help='æ•°æ®å¹´ä»½ (default: 2024)')
    parser.add_argument('--dry-run', action='store_true', help='Dry run (ä¸å®é™…å†™å…¥æ•°æ®)')

    args = parser.parse_args()

    builder = ConsolidatedBuilder(
        data_year=args.year,
        dry_run=args.dry_run
    )

    builder.build_all_consolidated()


if __name__ == '__main__':
    main()
