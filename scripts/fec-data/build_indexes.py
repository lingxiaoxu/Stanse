#!/usr/bin/env python3
"""
æ„å»ºFECç´¢å¼•å’Œæ±‡æ€»è¡¨
- fec_company_index: ä»committeesæå–å…¬å¸ç´¢å¼•
- fec_company_party_summary: æŒ‰å¹´ä»½æ±‡æ€»æ¯ä¸ªå…¬å¸çš„æ”¿å…šææ¬¾
"""

import sys
import os
import re
import time
import random
import subprocess
from pathlib import Path
from datetime import datetime
from collections import defaultdict

try:
    import firebase_admin
    from firebase_admin import credentials, firestore
    from google.api_core.exceptions import ResourceExhausted, DeadlineExceeded
except ImportError:
    print('âŒ Firebaseåº“æœªå®‰è£…')
    sys.exit(1)

# é…ç½®
PROJECT_ID = 'stanseproject'
BATCH_SIZE = 50
MIN_DELAY = 3.0
MAX_DELAY = 300.0
INITIAL_RETRY_DELAY = 30.0

db = None

def init_firestore():
    """åˆå§‹åŒ–Firestore"""
    global db
    print('\nğŸ”§ åˆå§‹åŒ–Firestoreè¿æ¥...')

    try:
        if not firebase_admin._apps:
            access_token = os.environ.get('GCLOUD_ACCESS_TOKEN')

            if not access_token:
                print('  â„¹ï¸  ä»gcloudè·å–access token...')
                result = subprocess.run(
                    ['gcloud', 'auth', 'print-access-token'],
                    capture_output=True, text=True, check=True
                )
                access_token = result.stdout.strip()
            else:
                print('  âœ“ ä½¿ç”¨ç¯å¢ƒå˜é‡ä¸­çš„access token')

            from google.oauth2 import credentials as oauth_creds
            cred = oauth_creds.Credentials(access_token)
            firebase_admin.initialize_app(cred, options={'projectId': PROJECT_ID})

        db = firestore.client()
        print(f'âœ… Firestoreå·²è¿æ¥ (é¡¹ç›®: {PROJECT_ID})')
        return db
    except Exception as e:
        print(f'âŒ å¤±è´¥: {e}')
        sys.exit(1)

def commit_with_retry(batch, retry_count=0, max_retries=10):
    """æäº¤æ‰¹æ¬¡ï¼Œå¸¦æŒ‡æ•°é€€é¿é‡è¯•"""
    try:
        batch.commit()
        return True
    except (ResourceExhausted, DeadlineExceeded) as e:
        if retry_count >= max_retries:
            print(f'  âŒ è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•° ({max_retries})')
            return False

        delay = min(
            INITIAL_RETRY_DELAY * (2 ** retry_count) + random.uniform(0, 5),
            MAX_DELAY
        )

        print(f'  âš ï¸  é…é¢é™åˆ¶ï¼Œç­‰å¾… {delay:.1f} ç§’åé‡è¯•ï¼ˆç¬¬ {retry_count + 1}/{max_retries} æ¬¡ï¼‰...')
        time.sleep(delay)

        return commit_with_retry(batch, retry_count + 1, max_retries)
    except Exception as e:
        print(f'  âŒ æœªçŸ¥é”™è¯¯: {e}')
        return False

def normalize_company_name(name):
    """æ ‡å‡†åŒ–å…¬å¸åç§°ç”¨äºç´¢å¼•"""
    if not name:
        return ''
    normalized = name.lower()
    suffixes = ['corporation', 'corp', 'inc', 'incorporated', 'company', 'co',
                'llc', 'lp', 'ltd', 'limited', 'political action committee', 'pac']
    for suffix in suffixes:
        normalized = re.sub(rf'\b{suffix}\b\.?', '', normalized)
    normalized = re.sub(r'[^\w\s]', '', normalized)
    normalized = re.sub(r'\s+', ' ', normalized).strip()
    return normalized

def build_company_index():
    """ä»committeesæ„å»ºcompany_index"""
    print(f'\n{"="*70}')
    print('ğŸ—ï¸  æ­¥éª¤1: æ„å»ºCompany Index')
    print(f'{"="*70}')

    # ä»fec_raw_committeesæå–æ‰€æœ‰å”¯ä¸€å…¬å¸
    companies = {}

    print('  ğŸ“– è¯»å–committeesæ•°æ®...')
    committees_ref = db.collection('fec_raw_committees')

    # åˆ†é¡µè¯»å–ä»¥é¿å…å†…å­˜é—®é¢˜
    page_size = 1000
    last_doc = None
    total_processed = 0

    while True:
        query = committees_ref.order_by('__name__').limit(page_size)
        if last_doc:
            query = query.start_after(last_doc)

        docs = list(query.stream())
        if not docs:
            break

        for doc in docs:
            data = doc.to_dict()
            connected_org = data.get('connected_org_name', '').strip()
            committee_id = data.get('committee_id')
            year = data.get('data_year')

            if connected_org and committee_id:
                normalized = normalize_company_name(connected_org)

                if normalized not in companies:
                    companies[normalized] = {
                        'company_name': connected_org,
                        'normalized_name': normalized,
                        'committee_ids': [],
                        'search_keywords': set()
                    }

                # é¿å…é‡å¤
                if not any(c['committee_id'] == committee_id and c['year'] == year
                          for c in companies[normalized]['committee_ids']):
                    companies[normalized]['committee_ids'].append({
                        'committee_id': committee_id,
                        'year': year
                    })

                # ç”Ÿæˆæœç´¢å…³é”®è¯
                words = normalized.split()
                companies[normalized]['search_keywords'].update(words)

            total_processed += 1

        last_doc = docs[-1]
        print(f'  å¤„ç† {total_processed} æ¡committees...')

    print(f'  âœ… æå–åˆ° {len(companies)} ä¸ªå”¯ä¸€å…¬å¸')

    # ä¸Šä¼ åˆ°fec_company_index
    print('  ğŸ“¤ ä¸Šä¼ åˆ°fec_company_index...')
    batch = db.batch()
    batch_count = 0
    uploaded = 0

    for normalized_name, company_data in companies.items():
        doc_ref = db.collection('fec_company_index').document(normalized_name)

        doc_data = {
            'company_name': company_data['company_name'],
            'normalized_name': normalized_name,
            'committee_ids': company_data['committee_ids'],
            'search_keywords': list(company_data['search_keywords']),
            'created_at': datetime.utcnow(),
            'last_updated': datetime.utcnow()
        }

        batch.set(doc_ref, doc_data)
        batch_count += 1

        if batch_count >= BATCH_SIZE:
            if commit_with_retry(batch):
                uploaded += batch_count
                print(f'  âœ“ å·²ä¸Šä¼  {uploaded}/{len(companies)} ä¸ªå…¬å¸ç´¢å¼•')
                time.sleep(MIN_DELAY)
                batch = db.batch()
                batch_count = 0
            else:
                print(f'  âŒ ä¸Šä¼ å¤±è´¥ï¼Œå·²å®Œæˆ {uploaded} ä¸ª')
                return uploaded

    if batch_count > 0:
        if commit_with_retry(batch):
            uploaded += batch_count

    print(f'âœ… Company Indexæ„å»ºå®Œæˆ: {uploaded} ä¸ªå…¬å¸')
    return uploaded

def build_company_summaries():
    """æ„å»ºcompany_party_summary"""
    print(f'\n{"="*70}')
    print('ğŸ—ï¸  æ­¥éª¤2: æ„å»ºCompany Party Summaries')
    print(f'{"="*70}')

    # ä»company_indexè·å–æ‰€æœ‰å…¬å¸
    print('  ğŸ“– è¯»å–company_index...')
    companies_ref = db.collection('fec_company_index')
    companies = list(companies_ref.stream())

    print(f'  æ‰¾åˆ° {len(companies)} ä¸ªå…¬å¸')

    uploaded = 0
    skipped = 0

    for idx, company_doc in enumerate(companies, 1):
        company_data = company_doc.to_dict()
        normalized_name = company_data['normalized_name']
        committee_ids = [c['committee_id'] for c in company_data['committee_ids']]

        print(f'\n  [{idx}/{len(companies)}] å¤„ç†: {company_data["company_name"]}')
        print(f'    PACs: {len(committee_ids)} ä¸ª')

        # æŒ‰å¹´ä»½æ±‡æ€»
        years_data = defaultdict(lambda: defaultdict(lambda: {'total_amount': 0, 'contribution_count': 0}))

        # è·å–è¯¥å…¬å¸æ‰€æœ‰PACçš„ææ¬¾
        contributions_ref = db.collection('fec_raw_contributions_pac_to_candidate')

        for committee_id in committee_ids:
            query = contributions_ref.where('committee_id', '==', committee_id)
            contributions = list(query.stream())

            for contrib_doc in contributions:
                contrib_data = contrib_doc.to_dict()
                year = contrib_data.get('data_year')
                candidate_id = contrib_data.get('candidate_id')
                amount = contrib_data.get('transaction_amount', 0)

                if not year or not candidate_id:
                    continue

                # æŸ¥æ‰¾å€™é€‰äººçš„æ”¿å…š
                cand_ref = db.collection('fec_raw_candidates').document(f'{candidate_id}_{year}')
                cand_doc = cand_ref.get()

                if cand_doc.exists:
                    cand_data = cand_doc.to_dict()
                    party = cand_data.get('party_affiliation', 'Unknown').strip()

                    if not party:
                        party = 'Unknown'

                    years_data[year][party]['total_amount'] += amount
                    years_data[year][party]['contribution_count'] += 1

        if not years_data:
            print(f'    âš ï¸  æ— ææ¬¾æ•°æ®ï¼Œè·³è¿‡')
            skipped += 1
            continue

        # ä¸ºæ¯ä¸ªå¹´ä»½åˆ›å»ºæ±‡æ€»æ–‡æ¡£
        batch = db.batch()
        batch_count = 0

        for year, party_data in years_data.items():
            doc_id = f'{normalized_name}_{year}'
            doc_ref = db.collection('fec_company_party_summary').document(doc_id)

            total_contributed = sum(p['total_amount'] for p in party_data.values())

            doc_data = {
                'company_name': company_data['company_name'],
                'normalized_name': normalized_name,
                'data_year': year,
                'party_totals': dict(party_data),
                'total_contributed': total_contributed,
                'created_at': datetime.utcnow(),
                'last_updated': datetime.utcnow()
            }

            batch.set(doc_ref, doc_data)
            batch_count += 1

        if batch_count > 0:
            if commit_with_retry(batch):
                uploaded += batch_count
                print(f'    âœ“ ä¸Šä¼  {batch_count} ä¸ªå¹´ä»½çš„æ±‡æ€»')
                time.sleep(MIN_DELAY)
            else:
                print(f'    âŒ ä¸Šä¼ å¤±è´¥')

    print(f'\nâœ… Company Summariesæ„å»ºå®Œæˆ:')
    print(f'   ä¸Šä¼ : {uploaded} ä¸ªæ±‡æ€»')
    print(f'   è·³è¿‡: {skipped} ä¸ªå…¬å¸ï¼ˆæ— æ•°æ®ï¼‰')
    return uploaded

def main():
    """ä¸»å‡½æ•°"""
    print('\n' + '='*70)
    print('ğŸš€ FECç´¢å¼•å’Œæ±‡æ€»è¡¨æ„å»º')
    print('='*70)

    init_firestore()

    # æ­¥éª¤1: æ„å»ºå…¬å¸ç´¢å¼•
    company_count = build_company_index()

    # æ­¥éª¤2: æ„å»ºå…¬å¸æ±‡æ€»
    summary_count = build_company_summaries()

    print('\n' + '='*70)
    print('âœ… æ„å»ºå®Œæˆï¼')
    print('='*70)
    print(f'\nğŸ“Š ç»Ÿè®¡:')
    print(f'  Company Index: {company_count} ä¸ªå…¬å¸')
    print(f'  Company Summaries: {summary_count} ä¸ªæ±‡æ€»')
    print()

if __name__ == '__main__':
    try:
        main()
    except KeyboardInterrupt:
        print('\n\nâš ï¸  ç”¨æˆ·ä¸­æ–­')
        sys.exit(0)
    except Exception as e:
        print(f'\nâŒ é”™è¯¯: {e}')
        import traceback
        traceback.print_exc()
        sys.exit(1)
