#!/usr/bin/env python3
"""
Portfolio Return Backfill - å›å¡«å†å²Portfolio Returnsæ•°æ®

åŠŸèƒ½ï¼š
1. ä»enhanced_company_rankings/{stanceType}/historyè¯»å–æ‰€æœ‰å†å²å¿«ç…§
2. å¯¹æ¯ä¸ªå†å²å¿«ç…§ï¼Œä½¿ç”¨Polygon APIè·å–è¯¥æ—¶é—´ç‚¹çš„è‚¡ç¥¨ä»·æ ¼
3. è®¡ç®—Portfolio Returnï¼ˆ100%åŒ¹é…å‰ç«¯è®¡ç®—æ–¹æ³•ï¼‰
4. ä¿å­˜åˆ°enhanced_persona_index_longshort_fund/{stanceType}/snapshots/{timestamp}

è®¡ç®—æ–¹æ³• (100%åŒ¹é…å‰ç«¯FeedView.tsx):
- supportStocks (å‰5): Long positions
- opposeStocks (å5): Short positions
- longReturn = supportStocks.reduce((sum, s) => sum + (s.change || 0), 0) / 5
- shortReturn = opposeStocks.reduce((sum, s) => sum - (s.change || 0), 0) / 5
- portfolioReturn = (longReturn + shortReturn) / 2

Polygon APIå†å²æ•°æ®:
- ä½¿ç”¨ /v2/aggs/ticker/{ticker}/range/1/day/{from}/{to} è·å–å†å²æ—¥çº¿æ•°æ®
- è®¡ç®—å½“æ—¥æ¶¨è·Œå¹… = (close - prevClose) / prevClose * 100

é¡¹ç›®é…ç½®:
- Google Cloud Project (Secrets): gen-lang-client-0960644135
- Firebase Project (Firestore): stanseproject

ä½¿ç”¨æ–¹æ³•ï¼š
    # å›å¡«æ‰€æœ‰personaçš„æ‰€æœ‰å†å²æ•°æ®
    python3 07-backfill-portfolio-returns.py

    # åªå›å¡«ç‰¹å®špersona
    python3 07-backfill-portfolio-returns.py --persona progressive-globalist

    # æµ‹è¯•æ¨¡å¼ï¼ˆåªå¤„ç†å‰3æ¡å†å²è®°å½•ï¼‰
    python3 07-backfill-portfolio-returns.py --test

    # è·³è¿‡å·²å­˜åœ¨çš„è®°å½•
    python3 07-backfill-portfolio-returns.py --skip-existing

ä½œè€…: Claude Code
æ—¥æœŸ: 2026-02-07
"""

import os
import sys
import time
import requests
import subprocess
from datetime import datetime, timezone, timedelta
from typing import Dict, List, Optional, Any, Tuple
from concurrent.futures import ThreadPoolExecutor, as_completed

import firebase_admin
from firebase_admin import credentials, firestore

# ============================================================
# é…ç½®
# ============================================================

# 8ç§æ”¿æ²»ç«‹åœºç±»å‹
STANCE_TYPES = [
    'progressive-globalist',
    'progressive-nationalist',
    'socialist-libertarian',
    'socialist-nationalist',
    'capitalist-globalist',
    'capitalist-nationalist',
    'conservative-globalist',
    'conservative-nationalist'
]

# Polygon API rate limit: 5 requests per minute for free tier
# We'll add delays to respect this
POLYGON_RATE_LIMIT_DELAY = 0.5  # seconds between requests

def get_polygon_api_key() -> Optional[str]:
    """ä»ç¯å¢ƒå˜é‡æˆ–Google Secret Managerè·å–Polygon API key

    å®‰å…¨è¦æ±‚: API keyç»ä¸èƒ½hardcodeï¼Œå¿…é¡»ä»Secret Managerè·å–
    """
    # é¦–å…ˆå°è¯•ç¯å¢ƒå˜é‡ (Cloud Run Jobä¼šè‡ªåŠ¨æ³¨å…¥secret)
    api_key = os.environ.get('POLYGON_API_KEY')
    if api_key:
        return api_key

    # å¦‚æœç¯å¢ƒå˜é‡ä¸å­˜åœ¨ï¼Œå°è¯•ä»Secret Managerè·å– (æœ¬åœ°è¿è¡Œæ—¶)
    try:
        result = subprocess.run(
            [
                'gcloud', 'secrets', 'versions', 'access', 'latest',
                '--secret=polygon-api-key',
                '--project=gen-lang-client-0960644135'
            ],
            capture_output=True,
            text=True,
            timeout=10
        )
        if result.returncode == 0:
            return result.stdout.strip()
        else:
            print(f"âš ï¸  gcloud command failed: {result.stderr}")
            return None
    except Exception as e:
        print(f"âš ï¸  Failed to get API key from Secret Manager: {e}")
        return None


# ============================================================
# ä¸»ç±»
# ============================================================

class PortfolioReturnBackfiller:
    """Portfolio Return Backfiller - å›å¡«å†å²æ•°æ®"""

    def __init__(self, test_mode: bool = False, skip_existing: bool = False):
        """åˆå§‹åŒ–"""
        # åˆå§‹åŒ– Firebase
        if not firebase_admin._apps:
            cred = credentials.ApplicationDefault()
            firebase_admin.initialize_app(cred, {
                'projectId': 'stanseproject'
            })

        self.db = firestore.client()
        self.test_mode = test_mode
        self.skip_existing = skip_existing

        # è·å– Polygon API key (å¿…é¡»ä»Secret Managerè·å–)
        self.polygon_api_key = get_polygon_api_key()
        if self.polygon_api_key:
            print(f"âœ… Polygon API key loaded from Secret Manager")
        else:
            print(f"âŒ No Polygon API key - cannot proceed with backfill")
            sys.exit(1)

        print(f"âœ… Firebase initialized (project: stanseproject)")

        if test_mode:
            print(f"ğŸ§ª Test mode: will only process first 3 history records per persona")
        if skip_existing:
            print(f"â­ï¸  Skip existing: will skip records that already exist")

        # Cache for daily stock data to reduce API calls
        self._price_cache: Dict[str, Dict[str, Any]] = {}

    def parse_history_timestamp(self, timestamp_id: str) -> Tuple[str, str]:
        """è§£æhistoryæ–‡æ¡£IDä¸­çš„æ—¥æœŸå’Œæ—¶é—´

        æ ¼å¼: YYYYMMdd_HHMMSS (ä¾‹å¦‚: 20260127_020522)
        è¿”å›: (date_str 'YYYY-MM-DD', time_str 'HH:MM')
        """
        try:
            # è§£ææ ¼å¼ YYYYMMdd_HHMMSS
            date_part = timestamp_id[:8]  # YYYYMMdd
            time_part = timestamp_id[9:15] if len(timestamp_id) > 9 else "000000"  # HHMMSS

            year = date_part[:4]
            month = date_part[4:6]
            day = date_part[6:8]

            hour = time_part[:2]
            minute = time_part[2:4]

            date_str = f"{year}-{month}-{day}"
            time_str = f"{hour}:{minute}"

            return date_str, time_str
        except Exception as e:
            print(f"    âš ï¸  Failed to parse timestamp {timestamp_id}: {e}")
            return "unknown", "unknown"

    def fetch_historical_daily_data(self, symbol: str, date_str: str) -> Optional[Dict[str, Any]]:
        """ä»Polygonè·å–å†å²æ—¥çº¿æ•°æ®

        ä½¿ç”¨Polygon Aggregates APIè·å–æŒ‡å®šæ—¥æœŸçš„OHLCVæ•°æ®
        è®¡ç®—å½“æ—¥æ¶¨è·Œå¹… = (close - prevClose) / prevClose * 100

        100%åŒ¹é…å‰ç«¯è®¡ç®—æ–¹æ³•:
        - price = Math.round(currentPrice * 100) / 100
        - change = Math.round(todaysChangePercent * 100) / 100
        """
        cache_key = f"{symbol}_{date_str}"

        # æ£€æŸ¥ç¼“å­˜
        if cache_key in self._price_cache:
            return self._price_cache[cache_key]

        try:
            # è®¡ç®—æ—¥æœŸèŒƒå›´ï¼ˆéœ€è¦å‰ä¸€å¤©æ¥è®¡ç®—æ¶¨è·Œå¹…ï¼‰
            target_date = datetime.strptime(date_str, '%Y-%m-%d')
            from_date = (target_date - timedelta(days=5)).strftime('%Y-%m-%d')  # å¤šå–å‡ å¤©ä»¥é˜²èŠ‚å‡æ—¥
            to_date = date_str

            # Polygon Aggregates API
            url = f"https://api.polygon.io/v2/aggs/ticker/{symbol}/range/1/day/{from_date}/{to_date}"
            params = {
                'apiKey': self.polygon_api_key,
                'adjusted': 'true',
                'sort': 'asc'
            }

            # Rate limiting
            time.sleep(POLYGON_RATE_LIMIT_DELAY)

            response = requests.get(url, params=params, timeout=15)

            if response.ok:
                data = response.json()
                results = data.get('results', [])

                if len(results) >= 2:
                    # æ‰¾åˆ°ç›®æ ‡æ—¥æœŸçš„æ•°æ®
                    target_ts = target_date.timestamp() * 1000

                    prev_close = None
                    current_data = None

                    for i, bar in enumerate(results):
                        bar_date = datetime.fromtimestamp(bar['t'] / 1000).strftime('%Y-%m-%d')
                        if bar_date == date_str:
                            current_data = bar
                            if i > 0:
                                prev_close = results[i-1]['c']
                            break
                        prev_close = bar['c']

                    if current_data and prev_close:
                        current_price = current_data['c']
                        change_percent = ((current_price - prev_close) / prev_close) * 100

                        result = {
                            'symbol': symbol,
                            'price': round(current_price * 100) / 100,  # 100%åŒ¹é…å‰ç«¯
                            'change': round(change_percent * 100) / 100,  # 100%åŒ¹é…å‰ç«¯
                            'source': 'polygon_historical'
                        }

                        self._price_cache[cache_key] = result
                        return result
                    elif current_data:
                        # æ²¡æœ‰å‰ä¸€å¤©æ•°æ®ï¼Œä½¿ç”¨å½“å¤©å¼€ç›˜ä»·è®¡ç®—
                        current_price = current_data['c']
                        open_price = current_data['o']
                        change_percent = ((current_price - open_price) / open_price) * 100 if open_price else 0

                        result = {
                            'symbol': symbol,
                            'price': round(current_price * 100) / 100,
                            'change': round(change_percent * 100) / 100,
                            'source': 'polygon_historical_intraday'
                        }

                        self._price_cache[cache_key] = result
                        return result

                elif len(results) == 1:
                    # åªæœ‰ä¸€å¤©æ•°æ®
                    bar = results[0]
                    current_price = bar['c']
                    open_price = bar['o']
                    change_percent = ((current_price - open_price) / open_price) * 100 if open_price else 0

                    result = {
                        'symbol': symbol,
                        'price': round(current_price * 100) / 100,
                        'change': round(change_percent * 100) / 100,
                        'source': 'polygon_historical_single'
                    }

                    self._price_cache[cache_key] = result
                    return result

            print(f"      âš ï¸  No data for {symbol} on {date_str}")
            return None

        except Exception as e:
            print(f"      âš ï¸  Error fetching {symbol} for {date_str}: {e}")
            return None

    def calculate_portfolio_return(
        self,
        support_stocks: List[Dict],
        oppose_stocks: List[Dict]
    ) -> Dict[str, float]:
        """
        è®¡ç®—Portfolio Return - 100%åŒ¹é…å‰ç«¯FeedView.tsx

        å‰ç«¯ä»£ç  (lines 1148-1152):
        const supportStocks = marketStocks.slice(0, 5);
        const opposeStocks = marketStocks.slice(5, 10);
        const longReturn = supportStocks.reduce((sum, s) => sum + (s.change || 0), 0) / 5;
        const shortReturn = opposeStocks.reduce((sum, s) => sum - (s.change || 0), 0) / 5;
        const portfolioReturn = (longReturn + shortReturn) / 2;
        """
        # Long positions: support stocks
        long_return = sum(s.get('change', 0) for s in support_stocks) / 5

        # Short positions: oppose stocks (æ³¨æ„è¿™é‡Œæ˜¯å‡å·ï¼Œå’Œå‰ç«¯ä¸€è‡´)
        short_return = sum(-s.get('change', 0) for s in oppose_stocks) / 5

        # Portfolio return: å¹³å‡
        portfolio_return = (long_return + short_return) / 2

        return {
            'longReturn': round(long_return * 100) / 100,
            'shortReturn': round(short_return * 100) / 100,
            'portfolioReturn': round(portfolio_return * 100) / 100
        }

    def get_history_records(self, stance_type: str) -> List[Dict[str, Any]]:
        """è·å–enhanced_company_rankingsçš„æ‰€æœ‰å†å²è®°å½•"""
        try:
            history_ref = (self.db
                .collection('enhanced_company_rankings')
                .document(stance_type)
                .collection('history')
                .order_by('__name__'))  # æŒ‰æ–‡æ¡£IDæ’åº

            docs = history_ref.stream()

            records = []
            for doc in docs:
                data = doc.to_dict()
                data['_history_id'] = doc.id
                records.append(data)

            return records

        except Exception as e:
            print(f"  âŒ Error fetching history for {stance_type}: {e}")
            return []

    def check_snapshot_exists(self, stance_type: str, snapshot_id: str) -> bool:
        """æ£€æŸ¥snapshotæ˜¯å¦å·²å­˜åœ¨"""
        try:
            doc_ref = (self.db
                .collection('enhanced_persona_index_longshort_fund')
                .document(stance_type)
                .collection('snapshots')
                .document(snapshot_id))

            return doc_ref.get().exists
        except:
            return False

    def process_history_record(
        self,
        stance_type: str,
        history_record: Dict[str, Any]
    ) -> Optional[Dict[str, Any]]:
        """å¤„ç†å•æ¡å†å²è®°å½•ï¼Œç”Ÿæˆportfolio return snapshot"""

        history_id = history_record.get('_history_id', 'unknown')

        # è§£ææ—¶é—´æˆ³
        market_date, market_time = self.parse_history_timestamp(history_id)

        if market_date == "unknown":
            print(f"    â­ï¸  Skipping {history_id}: invalid timestamp")
            return None

        # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
        if self.skip_existing and self.check_snapshot_exists(stance_type, history_id):
            print(f"    â­ï¸  Skipping {history_id}: already exists")
            return None

        print(f"    ğŸ“… Processing {history_id} ({market_date} {market_time})...")

        # è·å–supportå’Œopposeå…¬å¸
        support_companies = history_record.get('supportCompanies', [])[:5]
        oppose_companies = history_record.get('opposeCompanies', [])[:5]

        if len(support_companies) < 5 or len(oppose_companies) < 5:
            print(f"    âš ï¸  Skipping {history_id}: not enough companies")
            return None

        # è·å–å†å²è‚¡ä»·
        long_positions = []
        for company in support_companies:
            symbol = company.get('symbol', '')
            price_data = self.fetch_historical_daily_data(symbol, market_date)

            if price_data:
                long_positions.append({
                    'symbol': symbol,
                    'name': company.get('name', symbol),
                    'price': price_data['price'],
                    'change': price_data['change'],
                    'weight': 0.2  # Equal weighted (1/5)
                })
            else:
                # å¦‚æœè·å–ä¸åˆ°ä»·æ ¼ï¼Œä½¿ç”¨0
                long_positions.append({
                    'symbol': symbol,
                    'name': company.get('name', symbol),
                    'price': 0,
                    'change': 0,
                    'weight': 0.2
                })

        short_positions = []
        for company in oppose_companies:
            symbol = company.get('symbol', '')
            price_data = self.fetch_historical_daily_data(symbol, market_date)

            if price_data:
                short_positions.append({
                    'symbol': symbol,
                    'name': company.get('name', symbol),
                    'price': price_data['price'],
                    'change': price_data['change'],
                    'weight': 0.2
                })
            else:
                short_positions.append({
                    'symbol': symbol,
                    'name': company.get('name', symbol),
                    'price': 0,
                    'change': 0,
                    'weight': 0.2
                })

        # è®¡ç®—portfolio return
        returns = self.calculate_portfolio_return(long_positions, short_positions)

        # æ„å»ºsnapshotæ•°æ®
        # ä½¿ç”¨history_idä½œä¸ºåŸå§‹æ—¶é—´æˆ³æ¥æ„å»ºISOæ—¶é—´
        try:
            # ä»history_idæ„å»ºdatetime
            dt = datetime.strptime(history_id, '%Y%m%d_%H%M%S')
            timestamp_iso = dt.replace(tzinfo=timezone.utc).isoformat()
        except:
            timestamp_iso = datetime.now(timezone.utc).isoformat()

        snapshot = {
            'stanceType': stance_type,
            'portfolioReturn': returns['portfolioReturn'],
            'longReturn': returns['longReturn'],
            'shortReturn': returns['shortReturn'],
            'timestamp': timestamp_iso,
            'marketDate': market_date,
            'marketTime': market_time,
            'positions': {
                'long': long_positions,
                'short': short_positions
            },
            'rankingUpdatedAt': history_record.get('updatedAt'),
            'backfilled': True,  # æ ‡è®°ä¸ºå›å¡«æ•°æ®
            'backfilledAt': datetime.now(timezone.utc).isoformat()
        }

        print(f"      âœ… {market_date}: Portfolio {returns['portfolioReturn']:+.2f}% (L:{returns['longReturn']:+.2f}%, S:{returns['shortReturn']:+.2f}%)")

        return snapshot

    def save_snapshot(self, stance_type: str, snapshot: Dict[str, Any], history_id: str):
        """ä¿å­˜snapshotåˆ°Firebase

        ä½¿ç”¨åŸå§‹çš„history_idä½œä¸ºsnapshot IDï¼Œä¿æŒæ—¶é—´æˆ³ä¸€è‡´
        """
        COLLECTION_NAME = 'enhanced_persona_index_longshort_fund'

        try:
            # ä¿å­˜åˆ°snapshots subcollection (ä½¿ç”¨åŸå§‹history_idä½œä¸ºæ–‡æ¡£ID)
            snapshot_ref = (self.db
                .collection(COLLECTION_NAME)
                .document(stance_type)
                .collection('snapshots')
                .document(history_id))
            snapshot_ref.set(snapshot)

        except Exception as e:
            print(f"      âŒ Error saving snapshot: {e}")
            raise

    def backfill_persona(self, stance_type: str) -> Dict[str, int]:
        """å›å¡«å•ä¸ªpersonaçš„æ‰€æœ‰å†å²æ•°æ®"""

        print(f"\nğŸ“Š Backfilling: {stance_type}")
        print(f"{'='*60}")

        # è·å–æ‰€æœ‰å†å²è®°å½•
        history_records = self.get_history_records(stance_type)

        if not history_records:
            print(f"  âš ï¸  No history records found")
            return {'total': 0, 'processed': 0, 'skipped': 0, 'failed': 0}

        print(f"  ğŸ“¦ Found {len(history_records)} history records")

        # æµ‹è¯•æ¨¡å¼åªå¤„ç†å‰3æ¡
        if self.test_mode:
            history_records = history_records[:3]
            print(f"  ğŸ§ª Test mode: processing only {len(history_records)} records")

        stats = {'total': len(history_records), 'processed': 0, 'skipped': 0, 'failed': 0}

        for record in history_records:
            history_id = record.get('_history_id', 'unknown')

            try:
                snapshot = self.process_history_record(stance_type, record)

                if snapshot:
                    self.save_snapshot(stance_type, snapshot, history_id)
                    stats['processed'] += 1
                else:
                    stats['skipped'] += 1

            except Exception as e:
                print(f"    âŒ Failed to process {history_id}: {e}")
                stats['failed'] += 1

        print(f"\n  ğŸ“ˆ Results: {stats['processed']} processed, {stats['skipped']} skipped, {stats['failed']} failed")

        return stats

    def run(self, specific_persona: Optional[str] = None):
        """è¿è¡Œå®Œæ•´çš„backfillæµç¨‹"""
        start_time = time.time()

        print(f"\n{'#'*60}")
        print(f"# PORTFOLIO RETURN BACKFILL")
        print(f"# Started: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"{'#'*60}\n")

        # ç¡®å®šè¦å¤„ç†çš„personaåˆ—è¡¨
        if specific_persona:
            if specific_persona not in STANCE_TYPES:
                raise ValueError(f"Invalid persona: {specific_persona}")
            personas = [specific_persona]
        else:
            personas = STANCE_TYPES

        print(f"ğŸ“‹ Will backfill {len(personas)} persona(s):")
        for p in personas:
            print(f"  - {p}")

        # ä¸ºæ¯ä¸ªpersonaæ‰§è¡Œbackfill
        all_stats = {}
        for persona in personas:
            try:
                stats = self.backfill_persona(persona)
                all_stats[persona] = stats
            except Exception as e:
                print(f"\nâŒ Failed for {persona}: {e}")
                all_stats[persona] = {'total': 0, 'processed': 0, 'skipped': 0, 'failed': 0, 'error': str(e)}

        # æ‰“å°æ€»ç»“
        duration = time.time() - start_time

        print(f"\n{'='*60}")
        print(f"âœ… Backfill Complete")
        print(f"{'='*60}")
        print(f"Duration: {duration:.1f}s ({duration/60:.1f} minutes)")
        print(f"\nğŸ“Š Summary:")

        total_processed = 0
        total_skipped = 0
        total_failed = 0

        for persona, stats in all_stats.items():
            if 'error' in stats:
                print(f"  âŒ {persona}: ERROR - {stats['error']}")
            else:
                print(f"  âœ… {persona}: {stats['processed']}/{stats['total']} processed, {stats['skipped']} skipped, {stats['failed']} failed")
                total_processed += stats['processed']
                total_skipped += stats['skipped']
                total_failed += stats['failed']

        print(f"\nğŸ“ˆ Total: {total_processed} processed, {total_skipped} skipped, {total_failed} failed")
        print(f"{'='*60}\n")

        return all_stats


# ============================================================
# ä¸»å‡½æ•°
# ============================================================

def main():
    """ä¸»å‡½æ•°"""
    import argparse

    parser = argparse.ArgumentParser(description='Backfill portfolio returns from enhanced_company_rankings history')
    parser.add_argument(
        '--persona',
        type=str,
        choices=STANCE_TYPES,
        help='Backfill specific persona only'
    )
    parser.add_argument(
        '--test',
        action='store_true',
        help='Test mode: only process first 3 history records per persona'
    )
    parser.add_argument(
        '--skip-existing',
        action='store_true',
        help='Skip records that already exist in enhanced_persona_index_longshort_fund'
    )

    args = parser.parse_args()

    # åˆ›å»ºbackfiller
    backfiller = PortfolioReturnBackfiller(
        test_mode=args.test,
        skip_existing=args.skip_existing
    )

    # è¿è¡Œbackfill
    backfiller.run(specific_persona=args.persona)


if __name__ == "__main__":
    main()
